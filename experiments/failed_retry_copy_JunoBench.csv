notebook_path,timestamp,error_type,error_message,clean_error_name,clean_error_message
/junobench_env/pandas_6/pandas_6_extension.ipynb,2026-01-14T15:43:56.449464,CellExecutionError,"An error occurred while executing the following cell:
------------------
df[['Order ID','Quantity Ordered']]=df[['Order ID','Quantity Ordered']].astype(int)
df['Price Each']=df['Price Each'].astype(float)
df['Order Date']=pd.to_datetime(df['Order Date'])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m<ipython-input-10-32da7d19cfe0>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mdf[0m[0;34m[[0m[0;34m[[0m[0;34m'Order ID'[0m[0;34m,[0m[0;34m'Quantity Ordered'[0m[0;34m][0m[0;34m][0m[0;34m=[0m[0mdf[0m[0;34m[[0m[0;34m[[0m[0;34m'Order ID'[0m[0;34m,[0m[0;34m'Quantity Ordered'[0m[0;34m][0m[0;34m][0m[0;34m.[0m[0mastype[0m[0;34m([0m[0mint[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0mdf[0m[0;34m[[0m[0;34m'Price Each'[0m[0;34m][0m[0;34m=[0m[0mdf[0m[0;34m[[0m[0;34m'Price Each'[0m[0;34m][0m[0;34m.[0m[0mastype[0m[0;34m([0m[0mfloat[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0mdf[0m[0;34m[[0m[0;34m'Order Date'[0m[0;34m][0m[0;34m=[0m[0mpd[0m[0;34m.[0m[0mto_datetime[0m[0;34m([0m[0mdf[0m[0;34m[[0m[0;34m'Order Date'[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py[0m in [0;36m__getitem__[0;34m(self, key)[0m
[1;32m   1070[0m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_get_rows_with_mask[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1071[0m [0;34m[0m[0m
[0;32m-> 1072[0;31m         [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_get_with[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1073[0m [0;34m[0m[0m
[1;32m   1074[0m     [0;32mdef[0m [0m_get_with[0m[0;34m([0m[0mself[0m[0;34m,[0m [0mkey[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py[0m in [0;36m_get_with[0;34m(self, key)[0m
[1;32m   1111[0m [0;34m[0m[0m
[1;32m   1112[0m         [0;31m# handle the dup indexing case GH#4246[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1113[0;31m         [0;32mreturn[0m [0mself[0m[0;34m.[0m[0mloc[0m[0;34m[[0m[0mkey[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1114[0m [0;34m[0m[0m
[1;32m   1115[0m     [0;32mdef[0m [0m_get_values_tuple[0m[0;34m([0m[0mself[0m[0;34m,[0m [0mkey[0m[0;34m:[0m [0mtuple[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py[0m in [0;36m__getitem__[0;34m(self, key)[0m
[1;32m   1151[0m [0;34m[0m[0m
[1;32m   1152[0m             [0mmaybe_callable[0m [0;34m=[0m [0mcom[0m[0;34m.[0m[0mapply_if_callable[0m[0;34m([0m[0mkey[0m[0;34m,[0m [0mself[0m[0;34m.[0m[0mobj[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1153[0;31m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_getitem_axis[0m[0;34m([0m[0mmaybe_callable[0m[0;34m,[0m [0maxis[0m[0;34m=[0m[0maxis[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1154[0m [0;34m[0m[0m
[1;32m   1155[0m     [0;32mdef[0m [0m_is_scalar_access[0m[0;34m([0m[0mself[0m[0;34m,[0m [0mkey[0m[0;34m:[0m [0mtuple[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py[0m in [0;36m_getitem_axis[0;34m(self, key, axis)[0m
[1;32m   1380[0m                     [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m""Cannot index with multidimensional key""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1381[0m [0;34m[0m[0m
[0;32m-> 1382[0;31m                 [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_getitem_iterable[0m[0;34m([0m[0mkey[0m[0;34m,[0m [0maxis[0m[0;34m=[0m[0maxis[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1383[0m [0;34m[0m[0m
[1;32m   1384[0m             [0;31m# nested tuple slicing[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py[0m in [0;36m_getitem_iterable[0;34m(self, key, axis)[0m
[1;32m   1320[0m [0;34m[0m[0m
[1;32m   1321[0m         [0;31m# A collection of keys[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1322[0;31m         [0mkeyarr[0m[0;34m,[0m [0mindexer[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_get_listlike_indexer[0m[0;34m([0m[0mkey[0m[0;34m,[0m [0maxis[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1323[0m         return self.obj._reindex_with_indexers(
[1;32m   1324[0m             [0;34m{[0m[0maxis[0m[0;34m:[0m [0;34m[[0m[0mkeyarr[0m[0;34m,[0m [0mindexer[0m[0;34m][0m[0;34m}[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mTrue[0m[0;34m,[0m [0mallow_dups[0m[0;34m=[0m[0;32mTrue[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py[0m in [0;36m_get_listlike_indexer[0;34m(self, key, axis)[0m
[1;32m   1518[0m         [0maxis_name[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mobj[0m[0;34m.[0m[0m_get_axis_name[0m[0;34m([0m[0maxis[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1519[0m [0;34m[0m[0m
[0;32m-> 1520[0;31m         [0mkeyarr[0m[0;34m,[0m [0mindexer[0m [0;34m=[0m [0max[0m[0;34m.[0m[0m_get_indexer_strict[0m[0;34m([0m[0mkey[0m[0;34m,[0m [0maxis_name[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1521[0m [0;34m[0m[0m
[1;32m   1522[0m         [0;32mreturn[0m [0mkeyarr[0m[0;34m,[0m [0mindexer[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36m_get_indexer_strict[0;34m(self, key, axis_name)[0m
[1;32m   6113[0m             [0mkeyarr[0m[0;34m,[0m [0mindexer[0m[0;34m,[0m [0mnew_indexer[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_reindex_non_unique[0m[0;34m([0m[0mkeyarr[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   6114[0m [0;34m[0m[0m
[0;32m-> 6115[0;31m         [0mself[0m[0;34m.[0m[0m_raise_if_missing[0m[0;34m([0m[0mkeyarr[0m[0;34m,[0m [0mindexer[0m[0;34m,[0m [0maxis_name[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   6116[0m [0;34m[0m[0m
[1;32m   6117[0m         [0mkeyarr[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mtake[0m[0;34m([0m[0mindexer[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36m_raise_if_missing[0;34m(self, key, indexer, axis_name)[0m
[1;32m   6174[0m                 [0;32mif[0m [0muse_interval_msg[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   6175[0m                     [0mkey[0m [0;34m=[0m [0mlist[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 6176[0;31m                 [0;32mraise[0m [0mKeyError[0m[0;34m([0m[0;34mf""None of [{key}] are in the [{axis_name}]""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   6177[0m [0;34m[0m[0m
[1;32m   6178[0m             [0mnot_found[0m [0;34m=[0m [0mlist[0m[0;34m([0m[0mensure_index[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[[0m[0mmissing_mask[0m[0;34m.[0m[0mnonzero[0m[0;34m([0m[0;34m)[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m][0m[0;34m.[0m[0munique[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mKeyError[0m: ""None of [Index(['Order ID', 'Quantity Ordered'], dtype='object')] are in the [index]""
KeyError: ""None of [Index(['Order ID', 'Quantity Ordered'], dtype='object')] are in the [index]""
",KeyError,"None of [Index(['Order ID', 'Quantity Ordered'], dtype='object')] are in the [index]"
/junobench_env/pandas_1/pandas_1_extension.ipynb,2026-01-14T15:48:04.013501,DeadKernelError,Kernel died,,
/junobench_env/sklearn_10/sklearn_10_extension.ipynb,2026-01-14T15:56:35.444530,CellExecutionError,"An error occurred while executing the following cell:
------------------
#correlation map
f,ax=plt.subplots(figsize=(12,12))
corr=df.corr()

sns.heatmap(corr, annot=True, linewidths=.5, fmt='.2f', 
            mask= np.zeros_like(corr,dtype=np.bool), 
            cmap=sns.diverging_palette(100,200,as_cmap=True), 
            square=True, ax=ax)

plt.show()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAttributeError[0m                            Traceback (most recent call last)
[0;32m<ipython-input-10-1ad1a7ea7f49>[0m in [0;36m<cell line: 5>[0;34m()[0m
[1;32m      4[0m [0;34m[0m[0m
[1;32m      5[0m sns.heatmap(corr, annot=True, linewidths=.5, fmt='.2f', 
[0;32m----> 6[0;31m             [0mmask[0m[0;34m=[0m [0mnp[0m[0;34m.[0m[0mzeros_like[0m[0;34m([0m[0mcorr[0m[0;34m,[0m[0mdtype[0m[0;34m=[0m[0mnp[0m[0;34m.[0m[0mbool[0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      7[0m             [0mcmap[0m[0;34m=[0m[0msns[0m[0;34m.[0m[0mdiverging_palette[0m[0;34m([0m[0;36m100[0m[0;34m,[0m[0;36m200[0m[0;34m,[0m[0mas_cmap[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m      8[0m             square=True, ax=ax)

[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py[0m in [0;36m__getattr__[0;34m(attr)[0m
[1;32m    322[0m [0;34m[0m[0m
[1;32m    323[0m         [0;32mif[0m [0mattr[0m [0;32min[0m [0m__former_attrs__[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 324[0;31m             [0;32mraise[0m [0mAttributeError[0m[0;34m([0m[0m__former_attrs__[0m[0;34m[[0m[0mattr[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    325[0m [0;34m[0m[0m
[1;32m    326[0m         [0;32mif[0m [0mattr[0m [0;34m==[0m [0;34m'testing'[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mAttributeError[0m: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
AttributeError: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
",AttributeError,module 'numpy' has no attribute 'bool'.
/junobench_env/pandas_8/pandas_8_extension.ipynb,2026-01-14T15:57:05.522537,CellExecutionError,"An error occurred while executing the following cell:
------------------
# df[""MSRP""]=pd.to_numeric(df[""MSRP""]) 
code: df[""MSRP""] = df[""MSRP""].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False) 
df[""MSRP""] = pd.to_numeric(df[""MSRP""])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32mlib.pyx[0m in [0;36mpandas._libs.lib.maybe_convert_numeric[0;34m()[0m

[0;31mValueError[0m: Unable to parse string ""$36,945 ""

During handling of the above exception, another exception occurred:

[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-9-3087a4dda274>[0m in [0;36m<cell line: 3>[0;34m()[0m
[1;32m      1[0m [0;31m# df[""MSRP""]=pd.to_numeric(df[""MSRP""])[0m[0;34m[0m[0;34m[0m[0m
[1;32m      2[0m [0mcode[0m[0;34m:[0m [0mdf[0m[0;34m[[0m[0;34m""MSRP""[0m[0;34m][0m [0;34m=[0m [0mdf[0m[0;34m[[0m[0;34m""MSRP""[0m[0;34m][0m[0;34m.[0m[0mastype[0m[0;34m([0m[0mstr[0m[0;34m)[0m[0;34m.[0m[0mstr[0m[0;34m.[0m[0mreplace[0m[0;34m([0m[0;34m'$'[0m[0;34m,[0m [0;34m''[0m[0;34m,[0m [0mregex[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m.[0m[0mstr[0m[0;34m.[0m[0mreplace[0m[0;34m([0m[0;34m','[0m[0;34m,[0m [0;34m''[0m[0;34m,[0m [0mregex[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 3[0;31m [0mdf[0m[0;34m[[0m[0;34m""MSRP""[0m[0;34m][0m [0;34m=[0m [0mpd[0m[0;34m.[0m[0mto_numeric[0m[0;34m([0m[0mdf[0m[0;34m[[0m[0;34m""MSRP""[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/numeric.py[0m in [0;36mto_numeric[0;34m(arg, errors, downcast, dtype_backend)[0m
[1;32m    220[0m         [0mcoerce_numeric[0m [0;34m=[0m [0merrors[0m [0;32mnot[0m [0;32min[0m [0;34m([0m[0;34m""ignore""[0m[0;34m,[0m [0;34m""raise""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    221[0m         [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 222[0;31m             values, new_mask = lib.maybe_convert_numeric(  # type: ignore[call-overload]  # noqa: E501
[0m[1;32m    223[0m                 [0mvalues[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    224[0m                 [0mset[0m[0;34m([0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32mlib.pyx[0m in [0;36mpandas._libs.lib.maybe_convert_numeric[0;34m()[0m

[0;31mValueError[0m: Unable to parse string ""$36,945 "" at position 0
ValueError: Unable to parse string ""$36,945 "" at position 0
",ValueError,"Unable to parse string ""$36,945 "" at position 0"
/junobench_env/torch_11/torch_11_extension.ipynb,2026-01-14T15:58:51.012140,CellExecutionError,"An error occurred while executing the following cell:
------------------
tokens , max_len = tokenize(sentences)
vocab , int2text , text2int = build_vocab(tokens)
X,Y = build_input(tokens , word2index,text2int)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m<ipython-input-11-0a12095c959f>[0m in [0;36m<cell line: 3>[0;34m()[0m
[1;32m      1[0m [0mtokens[0m [0;34m,[0m [0mmax_len[0m [0;34m=[0m [0mtokenize[0m[0;34m([0m[0msentences[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      2[0m [0mvocab[0m [0;34m,[0m [0mint2text[0m [0;34m,[0m [0mtext2int[0m [0;34m=[0m [0mbuild_vocab[0m[0;34m([0m[0mtokens[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 3[0;31m [0mX[0m[0;34m,[0m[0mY[0m [0;34m=[0m [0mbuild_input[0m[0;34m([0m[0mtokens[0m [0;34m,[0m [0mword2index[0m[0;34m,[0m[0mtext2int[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m<ipython-input-9-d3d8c91761e9>[0m in [0;36mbuild_input[0;34m(sentences, word2index, text2int)[0m
[1;32m     27[0m [0;34m[0m[0m
[1;32m     28[0m         [0;32mfor[0m [0mtoken[0m [0;32min[0m [0mtokens[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 29[0;31m             [0mcurx[0m[0;34m.[0m[0mappend[0m[0;34m([0m[0mword2index[0m[0;34m.[0m[0mget[0m[0;34m([0m[0mtoken[0m[0;34m,[0m [0mword2index[0m[0;34m[[0m[0;34m'_unk_'[0m[0;34m][0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     30[0m             [0mcury[0m[0;34m.[0m[0mappend[0m[0;34m([0m[0mtext2int[0m[0;34m.[0m[0mget[0m[0;34m([0m[0mtoken[0m[0;34m,[0m [0munk_idx[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     31[0m [0;34m[0m[0m

[0;31mKeyError[0m: '_unk_'
KeyError: '_unk_'
",KeyError,'_unk_'
/junobench_env/sklearn_11/sklearn_11_extension.ipynb,2026-01-14T15:59:04.362724,CellExecutionError,"An error occurred while executing the following cell:
------------------

plt.scatter(x,y)
plt.xlabel(""number_people"")
plt.ylabel('temperature')
plt.show()

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-6-320c3223192f>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mplt[0m[0;34m.[0m[0mscatter[0m[0;34m([0m[0mx[0m[0;34m,[0m[0my[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0mplt[0m[0;34m.[0m[0mxlabel[0m[0;34m([0m[0;34m""number_people""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0mplt[0m[0;34m.[0m[0mylabel[0m[0;34m([0m[0;34m'temperature'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0mplt[0m[0;34m.[0m[0mshow[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mNameError[0m: name 'x' is not defined
NameError: name 'x' is not defined
",NameError,name 'x' is not defined
/junobench_env/pandas_7/pandas_7_extension.ipynb,2026-01-14T15:59:21.456867,CellExecutionError,"An error occurred while executing the following cell:
------------------
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# Create subplots with shared x-axis and subplot titles
fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=('Pearson Correlation', 'Spearman Correlation'))

# Compute Pearson correlation
pearson_corr = game_df.corr('pearson')
pearson_rows = pearson_corr.index
pearson_cols = pearson_corr.columns
pearson_vals = pearson_corr.values

# Add Pearson correlation heatmap with information cards
fig.add_trace(go.Heatmap(x=pearson_cols, y=pearson_rows, z=pearson_vals, name='Pearson', showscale=False, xgap=1, ygap=1, colorscale='Viridis'),
              row=1, col=1)

# Compute Spearman correlation
spearman_corr = game_df.corr('spearman')
spearman_rows = spearman_corr.index
spearman_cols = spearman_corr.columns
spearman_vals = spearman_corr.values

# Add Spearman correlation heatmap with information cards
fig.add_trace(go.Heatmap(x=spearman_cols, y=spearman_rows, z=spearman_vals, xgap=1, ygap=1, colorscale='Viridis'),
              row=2, col=1)

fig.update_layout(hoverlabel=dict(bgcolor=""white"", font_size=16, font_family=""Rockwell""))
fig.update_layout(height=700, width=900, title_text=""Correlations"")
fig.show()

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-6-9a8a2b7d8bec>[0m in [0;36m<cell line: 8>[0;34m()[0m
[1;32m      6[0m [0;34m[0m[0m
[1;32m      7[0m [0;31m# Compute Pearson correlation[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 8[0;31m [0mpearson_corr[0m [0;34m=[0m [0mgame_df[0m[0;34m.[0m[0mcorr[0m[0;34m([0m[0;34m'pearson'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      9[0m [0mpearson_rows[0m [0;34m=[0m [0mpearson_corr[0m[0;34m.[0m[0mindex[0m[0;34m[0m[0;34m[0m[0m
[1;32m     10[0m [0mpearson_cols[0m [0;34m=[0m [0mpearson_corr[0m[0;34m.[0m[0mcolumns[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36mcorr[0;34m(self, method, min_periods, numeric_only)[0m
[1;32m  10702[0m         [0mcols[0m [0;34m=[0m [0mdata[0m[0;34m.[0m[0mcolumns[0m[0;34m[0m[0;34m[0m[0m
[1;32m  10703[0m         [0midx[0m [0;34m=[0m [0mcols[0m[0;34m.[0m[0mcopy[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m> 10704[0;31m         [0mmat[0m [0;34m=[0m [0mdata[0m[0;34m.[0m[0mto_numpy[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mfloat[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mnp[0m[0;34m.[0m[0mnan[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m  10705[0m [0;34m[0m[0m
[1;32m  10706[0m         [0;32mif[0m [0mmethod[0m [0;34m==[0m [0;34m""pearson""[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36mto_numpy[0;34m(self, dtype, copy, na_value)[0m
[1;32m   1887[0m         [0;32mif[0m [0mdtype[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1888[0m             [0mdtype[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mdtype[0m[0;34m([0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1889[0;31m         [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_mgr[0m[0;34m.[0m[0mas_array[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0mcopy[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mna_value[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1890[0m         [0;32mif[0m [0mresult[0m[0;34m.[0m[0mdtype[0m [0;32mis[0m [0;32mnot[0m [0mdtype[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1891[0m             [0mresult[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0marray[0m[0;34m([0m[0mresult[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py[0m in [0;36mas_array[0;34m(self, dtype, copy, na_value)[0m
[1;32m   1654[0m                 [0marr[0m[0;34m.[0m[0mflags[0m[0;34m.[0m[0mwriteable[0m [0;34m=[0m [0;32mFalse[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1655[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1656[0;31m             [0marr[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_interleave[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mna_value[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1657[0m             [0;31m# The underlying data was copied within _interleave, so no need[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1658[0m             [0;31m# to further copy if copy=True or setting na_value[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py[0m in [0;36m_interleave[0;34m(self, dtype, na_value)[0m
[1;32m   1713[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1714[0m                 [0marr[0m [0;34m=[0m [0mblk[0m[0;34m.[0m[0mget_values[0m[0;34m([0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1715[0;31m             [0mresult[0m[0;34m[[0m[0mrl[0m[0;34m.[0m[0mindexer[0m[0;34m][0m [0;34m=[0m [0marr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1716[0m             [0mitemmask[0m[0;34m[[0m[0mrl[0m[0;34m.[0m[0mindexer[0m[0;34m][0m [0;34m=[0m [0;36m1[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1717[0m [0;34m[0m[0m

[0;31mValueError[0m: could not convert string to float: 'D/Generation HD'
ValueError: could not convert string to float: 'D/Generation HD'
",ValueError,could not convert string to float: 'D/Generation HD'
/junobench_env/numpy_9/numpy_9_extension.ipynb,2026-01-14T15:59:41.776840,CellExecutionError,"An error occurred while executing the following cell:
------------------
##### OLD model for finding survival in days ( regression) based ############

# -*- coding: utf-8 -*-
""""""
Created on Wed Jan 19 10:30:33 2022

@author: MIDL
""""""
################## keras data generator ###########################

from sklearn.model_selection import train_test_split
import os
import tensorflow as tf
import numpy as np

# lists of directories with studies
# train_and_val_directories = [f.path for f in os.scandir('C:/Users/marya/Downloads/Brats 2020 adjusted') if f.is_dir()]
case_path1 = '../input/combine-all-2109'
case_path2 = '../input/adjustedmask2019'  
case_path3 = '../input/adjusted-survival-2019'
case_path4 = '../input/adjustedlabels2019'


# case_main = 'C:/Users/MIDL/Downloads/3d_model_december/Brats 2020 adjusted'

train_directory1 = [f.path for f in os.scandir(case_path1) ]
# train_directory2 = [f.path for f in os.scandir(case_path2) ]

def pathListIntoIds(dirList):
    x = []
    for i in range(0,len(dirList)):
#         print(dirList[i][dirList[i].rfind('/')+1:])
        x.append(dirList[i][dirList[i].rfind('\\')+1:]) #for local system
        # x.append(dirList[i][dirList[i].rfind('/')+1:]) #for KAGGLE
    return x

train_and_test_ids1 = pathListIntoIds(train_directory1); 

    
train_test_ids, val_ids = train_test_split(train_and_test_ids1,test_size=0.1) 
train_ids, test_ids = train_test_split(train_test_ids,test_size=0.22) 


# train_and_test_ids2 = pathListIntoIds(train_directory2);

# masks_test_ids, masks_val_ids = train_test_split(train_and_test_ids,test_size=0.3) 
#train_ids, test_ids = train_test_split(train_test_ids,test_size=0.5) 


------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mFileNotFoundError[0m                         Traceback (most recent call last)
[0;32m<ipython-input-1-9232de8f7400>[0m in [0;36m<cell line: 26>[0;34m()[0m
[1;32m     24[0m [0;31m# case_main = 'C:/Users/MIDL/Downloads/3d_model_december/Brats 2020 adjusted'[0m[0;34m[0m[0;34m[0m[0m
[1;32m     25[0m [0;34m[0m[0m
[0;32m---> 26[0;31m [0mtrain_directory1[0m [0;34m=[0m [0;34m[[0m[0mf[0m[0;34m.[0m[0mpath[0m [0;32mfor[0m [0mf[0m [0;32min[0m [0mos[0m[0;34m.[0m[0mscandir[0m[0;34m([0m[0mcase_path1[0m[0;34m)[0m [0;34m][0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     27[0m [0;31m# train_directory2 = [f.path for f in os.scandir(case_path2) ][0m[0;34m[0m[0;34m[0m[0m
[1;32m     28[0m [0;34m[0m[0m

[0;31mFileNotFoundError[0m: [Errno 2] No such file or directory: '../input/combine-all-2109'
FileNotFoundError: [Errno 2] No such file or directory: '../input/combine-all-2109'
",FileNotFoundError,[Errno 2] No such file or directory: '../input/combine-all-2109'
/junobench_env/sklearn_4/sklearn_4_extension.ipynb,2026-01-14T16:28:32.924069,CellTimeoutError,"A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
%%time
ml_support_obj.plot_learning_curves(finalized_pipeline)
-------------------
",,
/junobench_env/numpy_7/numpy_7_extension.ipynb,2026-01-14T16:31:36.855604,CellExecutionError,"An error occurred while executing the following cell:
------------------
from keras.regularizers import l2
from keras.optimizers import SGD
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from keras.utils import to_categorical
from keras.callbacks import Callback
from keras import Model
from keras.models import load_model
import numpy as np
import os
import matplotlib.pyplot as plt


class History(Callback):
    def __init__(self, model, validation_images, validation_labels):
        self.model_ = model
        self.validation_images = validation_images
        self.validation_labels = validation_labels
        self.accuracy = [0]
        self.loss = [5]
        self.val_accuracy = [0]
        self.val_loss = [5]

    def on_batch_end(self, batch, logs={}):
        scores = self.model_.evaluate(
            self.validation_images,
            self.validation_labels,
            verbose=0
        )
        print('\n', scores, '\n')
        self.loss.append(logs.get('loss'))
        self.accuracy.append(logs.get('accuracy'))
        self.val_loss.append(scores[0])
        self.val_accuracy.append(scores[1])


def train(model, train_images, train_labels, validation_images, validation_labels, batch_size, num_epochs, learning_rate, verbose):
    opt = SGD(learning_rate)
    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])         # compile model

    history = History(model, validation_images, validation_labels)                              # train model
    model.fit(
        train_images,
        train_labels,
        batch_size=batch_size,
        epochs=num_epochs,
        callbacks=[history]
    )

    if verbose:
        plot_learning_curve(history.loss)
        plot_accuracy_curve(history.accuracy, history.val_accuracy)


def evaluate(model):
    scores = model.evaluate(X_test, test_labels, verbose=1)            # evaluate model
    print('Test loss:', scores[0])
    print('Test accuracy:', scores[1])


# def predict(model, image_idx):
#     layer_names = ['conv1', 'conv2', 'conv3', 'conv4']          # names of layers from which we will take the output
#     num_features = 4                                            # number of feature maps to display per layer

#     dataset = load_cifar()
#     #dataset['test_images'] = np.moveaxis(dataset['test_images'], 1, 3)
#     image = test_images[image_idx]
#     image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
#     pred = np.argmax(model.predict(image))

#     plot_sample(dataset['test_images'][image_idx], classes[dataset['test_labels'][image_idx]], classes[pred])

#     # extracting the output and appending to outputs
#     feature_maps = []
#     for name in layer_names:
#         tmp_model = Model(inputs=model.input, outputs=model.get_layer(name).output)
#         feature_maps.append(tmp_model.predict(image))

#     fig, ax = plt.subplots(nrows=len(feature_maps), ncols=num_features, figsize=(20, 20))
#     for i in range(len(feature_maps)):
#         for z in range(num_features):
#             ax[i][z].imshow(feature_maps[i][0, :, :, z])
#             ax[i][z].set_title(layer_names[i])
#             ax[i][z].set_xticks([])
#             ax[i][z].set_yticks([])
#     plt.savefig('feature_maps.png')

def predict(model, image_idx, test_images, test_labels, classes): 
    image = test_images[image_idx] 
    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2])) 
    pred = np.argmax(model.predict(image))
    plot_sample(test_images[image_idx], classes[test_labels[image_idx].item()], classes[pred]) 


def plot_weights(model):
    for layer in model.layers:
        if 'conv' in layer.name:
            weights, _ = layer.get_weights()
            plot_histogram(layer.name, np.reshape(weights, -1))


if __name__ == '__main__':

    classes = [                                                             # CIFAR-10 classes
        ""airplane"",
        ""automobile"",
        ""bird"",
        ""cat"",
        ""deer"",
        ""dog"",
        ""frog"",
        ""horse"",
        ""ship"",
        ""truck""
    ]

    num_epochs = 1 #10                                                        # hyper parameters
    learning_rate = 0.005
    batch_size = 2000 #100
    lam = 0.01
    verbose = 1

    print('\n--- Loading mnist dataset ---')                                # load dataset
    dataset = load_cifar()

    print('\n--- Processing the dataset ---')                               # pre process dataset
    dataset = preprocess(dataset)

    # train_images = np.moveaxis(dataset['train_images'], 1, 3)               # pre process data for keras
    # validation_images = np.moveaxis(dataset['validation_images'], 1, 3)
    # test_images = np.moveaxis(dataset['test_images'], 1, 3)
    train_labels = to_categorical(dataset['train_labels'].flatten())
    validation_labels = to_categorical(dataset['validation_labels'])
    test_labels = to_categorical(dataset['test_labels'])

    if os.path.isfile('model.h5'):                                          # load model
        print('\n--- Loading model ---')
        model = load_model('model.h5')
    else:                                                                   # build model
        print('\n--- Building model ---')
        model = Sequential()
        model.add(Conv2D(32, 3, name='conv1', activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(lam), input_shape=(32, 32, 3)))
        model.add(Conv2D(32, 3, name='conv2', activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(lam)))
        model.add(MaxPooling2D(2, name='pool1'))
        model.add(Conv2D(64, 3, name='conv3', activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(lam)))
        model.add(Conv2D(64, 3, name='conv4', activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(lam)))
        model.add(MaxPooling2D(2, name='pool2'))
        model.add(Flatten())
        model.add(Dense(256, name='fullyconnected', activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(lam)))
        model.add(Dense(10, name='dense', activation='softmax'))
        
        # train_images = np.moveaxis(train_images, -1, 1)
        # validation_images = np.moveaxis(validation_images, -1, 1)
        # test_images = np.moveaxis(test_images, -1, 1)


    train(
        model,
        X_train,
        train_labels,
        X_val,
        validation_labels,
        batch_size,
        num_epochs,
        learning_rate,
        verbose
    )

    print('\n--- Testing the model ---')                                    # test model
    evaluate(model)

    print('\n--- Predicting image from test set ---')
    image_idx = 40                                                          # index of image to predict
    predict(model, image_idx, X_test, test_labels, classes)

    print('\n--- Plotting weight distributions ---')
    plot_weights(model)

    print('\n--- Saving the model ---')                                     # save model
#     model.save('model.h5')
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-6-f4dbdd22d4e8>[0m in [0;36m<cell line: 102>[0;34m()[0m
[1;32m    172[0m     [0mprint[0m[0;34m([0m[0;34m'\n--- Predicting image from test set ---'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    173[0m     [0mimage_idx[0m [0;34m=[0m [0;36m40[0m                                                          [0;31m# index of image to predict[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 174[0;31m     [0mpredict[0m[0;34m([0m[0mmodel[0m[0;34m,[0m [0mimage_idx[0m[0;34m,[0m [0mX_test[0m[0;34m,[0m [0mtest_labels[0m[0;34m,[0m [0mclasses[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    175[0m [0;34m[0m[0m
[1;32m    176[0m     [0mprint[0m[0;34m([0m[0;34m'\n--- Plotting weight distributions ---'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m<ipython-input-6-f4dbdd22d4e8>[0m in [0;36mpredict[0;34m(model, image_idx, test_images, test_labels, classes)[0m
[1;32m     90[0m     [0mimage[0m [0;34m=[0m [0mimage[0m[0;34m.[0m[0mreshape[0m[0;34m([0m[0;34m([0m[0;36m1[0m[0;34m,[0m [0mimage[0m[0;34m.[0m[0mshape[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m,[0m [0mimage[0m[0;34m.[0m[0mshape[0m[0;34m[[0m[0;36m1[0m[0;34m][0m[0;34m,[0m [0mimage[0m[0;34m.[0m[0mshape[0m[0;34m[[0m[0;36m2[0m[0;34m][0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     91[0m     [0mpred[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0margmax[0m[0;34m([0m[0mmodel[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mimage[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 92[0;31m     [0mplot_sample[0m[0;34m([0m[0mtest_images[0m[0;34m[[0m[0mimage_idx[0m[0;34m][0m[0;34m,[0m [0mclasses[0m[0;34m[[0m[0mtest_labels[0m[0;34m[[0m[0mimage_idx[0m[0;34m][0m[0;34m.[0m[0mitem[0m[0;34m([0m[0;34m)[0m[0;34m][0m[0;34m,[0m [0mclasses[0m[0;34m[[0m[0mpred[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     93[0m [0;34m[0m[0m
[1;32m     94[0m [0;34m[0m[0m

[0;31mValueError[0m: can only convert an array of size 1 to a Python scalar
ValueError: can only convert an array of size 1 to a Python scalar
",ValueError,can only convert an array of size 1 to a Python scalar
/junobench_env/tensorflow_14/tensorflow_14_extension.ipynb,2026-01-14T16:32:10.191402,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Set the main data directory where subdirectories represent classes/labels
main_data_directory = 'data/train-data-imgs'

# Define the input size for the VGG16 model
input_size = (224, 224)

# Create a data generator for training data
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2
)

train_generator = train_datagen.flow_from_directory(
    main_data_directory,
    target_size=input_size,
    batch_size=32,
    class_mode='categorical',
    shuffle=True
)

# Load the VGG16 model without the top classification layer
base_model = VGG16(weights='imagenet', include_top=False)

# Make the layers in the base model non-trainable
for layer in base_model.layers:
    layer.trainable = False

# Compile the model with an appropriate optimizer, loss function, and metrics
base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

x = Flatten()(base_model.output) 
x = Dense(256, activation='relu')(x) 
x = Dropout(0.5)(x) 
predictions = Dense(7, activation='softmax')(x) # 7 classes 
model_for_training = Model(inputs=base_model.input, outputs=predictions) # Compile the new model 
model_for_training.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) 
# Continue training the model 
model_for_training.fit( train_generator, steps_per_epoch=len(train_generator), epochs=10, ) 
# Save the model after additional training 
model_for_training.save('data/updated_vgg16_transfer_weights.h5')

# Load the previously saved model weights
# base_model.load_weights('data/vgg_face_weights.h5')

# # Continue training the model
# base_model.fit(
#     train_generator,
#     steps_per_epoch=len(train_generator),
#     epochs=10,  # You can adjust the number of epochs
# )

# # Save the model after additional training
# base_model.save('data/updated_vgg_face_weights.h5')

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-5-1fbefc451ee9>[0m in [0;36m<cell line: 36>[0;34m()[0m
[1;32m     34[0m [0;34m[0m[0m
[1;32m     35[0m [0mx[0m [0;34m=[0m [0mFlatten[0m[0;34m([0m[0;34m)[0m[0;34m([0m[0mbase_model[0m[0;34m.[0m[0moutput[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 36[0;31m [0mx[0m [0;34m=[0m [0mDense[0m[0;34m([0m[0;36m256[0m[0;34m,[0m [0mactivation[0m[0;34m=[0m[0;34m'relu'[0m[0;34m)[0m[0;34m([0m[0mx[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     37[0m [0mx[0m [0;34m=[0m [0mDropout[0m[0;34m([0m[0;36m0.5[0m[0;34m)[0m[0;34m([0m[0mx[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     38[0m [0mpredictions[0m [0;34m=[0m [0mDense[0m[0;34m([0m[0;36m7[0m[0;34m,[0m [0mactivation[0m[0;34m=[0m[0;34m'softmax'[0m[0;34m)[0m[0;34m([0m[0mx[0m[0;34m)[0m [0;31m# 7 classes[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
[1;32m    120[0m             [0;31m# To get the full stack trace, call:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    121[0m             [0;31m# `keras.config.disable_traceback_filtering()`[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 122[0;31m             [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    123[0m         [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    124[0m             [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py[0m in [0;36m_validate_shape[0;34m(self, shape)[0m
[1;32m    184[0m         [0mshape[0m [0;34m=[0m [0mstandardize_shape[0m[0;34m([0m[0mshape[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    185[0m         [0;32mif[0m [0;32mNone[0m [0;32min[0m [0mshape[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 186[0;31m             raise ValueError(
[0m[1;32m    187[0m                 [0;34m""Shapes used to initialize variables must be ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    188[0m                 [0;34m""fully-defined (no `None` dimensions). Received: ""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: Shapes used to initialize variables must be fully-defined (no `None` dimensions). Received: shape=(None, 256) for variable path='dense/kernel'
ValueError: Shapes used to initialize variables must be fully-defined (no `None` dimensions). Received: shape=(None, 256) for variable path='dense/kernel'
",ValueError,"Shapes used to initialize variables must be fully-defined (no `None` dimensions). Received: shape=(None, 256) for variable path='dense/kernel'"
/junobench_env/tensorflow_13/tensorflow_13_extension.ipynb,2026-01-14T16:33:35.184338,CellExecutionError,"An error occurred while executing the following cell:
------------------
# def create_embedding_matrix(input_ids, glove_embeddings, bert_embeddings):
#     embedding_dim = bert_embeddings.shape[2]
# #     print(bert_embeddings.shape[1]
#     embedding_matrix = np.zeros((len(input_ids), embedding_dim))  # Exclude special tokens
#     for i, token_id in enumerate(input_ids[1:-1]):  # Exclude special tokens
#         token = tokenizer.convert_ids_to_tokens(token_id)
#         token_str = token[0]  # Convert list to string
#         glove_embedding = glove_embeddings.get(token_str)
#         if glove_embedding is not None:
#             embedding_matrix[i] = glove_embedding
#         else:
#             embedding_matrix[i] = bert_embeddings[0, i + 1, :]  # Adjust indexing and shape
#     return embedding_matrix

def create_embedding_matrix_for_sentence(input_ids, glove_embeddings, bert_embeddings, bert_tokenizer):
    target_embedding_dim = bert_embeddings.shape[2]  # 768
    num_actual_words = len(input_ids) - 2
    embedding_matrix = np.zeros((num_actual_words, target_embedding_dim))
    
    for i, token_id in enumerate(input_ids[1:-1]):  # skip [CLS] and [SEP]
        token_str = bert_tokenizer.convert_ids_to_tokens(token_id)
        glove_embedding = glove_embeddings.get(token_str)
        if glove_embedding is not None:
            if glove_embedding.shape[0] < target_embedding_dim:
                padded_glove = np.pad(glove_embedding, (0, target_embedding_dim - glove_embedding.shape[0]), 'constant')
                embedding_matrix[i] = padded_glove
            else:
                embedding_matrix[i] = glove_embedding[:target_embedding_dim]
        else:
            embedding_matrix[i] = bert_embeddings[0, i + 1, :]
    return embedding_matrix

# Example usage
embedding_matrix = create_embedding_matrix_for_sentence(input_ids, glove_embeddings, bert_embeddings)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-4-caf5086516d8>[0m in [0;36m<cell line: 34>[0;34m()[0m
[1;32m     32[0m [0;34m[0m[0m
[1;32m     33[0m [0;31m# Example usage[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 34[0;31m [0membedding_matrix[0m [0;34m=[0m [0mcreate_embedding_matrix_for_sentence[0m[0;34m([0m[0minput_ids[0m[0;34m,[0m [0mglove_embeddings[0m[0;34m,[0m [0mbert_embeddings[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;31mTypeError[0m: create_embedding_matrix_for_sentence() missing 1 required positional argument: 'bert_tokenizer'
TypeError: create_embedding_matrix_for_sentence() missing 1 required positional argument: 'bert_tokenizer'
",TypeError,create_embedding_matrix_for_sentence() missing 1 required positional argument: 'bert_tokenizer'
/junobench_env/seaborn_2/seaborn_2_extension.ipynb,2026-01-14T16:35:55.169206,CellExecutionError,"An error occurred while executing the following cell:
------------------
fig=plt.figure(figsize=[25,25])
for col,i in zip(dev_train.columns,range(1,13)):
    axes=fig.add_subplot(7,2,i)
    sns.regplot(dev_train[col],dev_train.SeriousDlqin2yrs,ax=axes)
plt.show()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-8-314ed5a9dfd5>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      2[0m [0;32mfor[0m [0mcol[0m[0;34m,[0m[0mi[0m [0;32min[0m [0mzip[0m[0;34m([0m[0mdev_train[0m[0;34m.[0m[0mcolumns[0m[0;34m,[0m[0mrange[0m[0;34m([0m[0;36m1[0m[0;34m,[0m[0;36m13[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m     [0maxes[0m[0;34m=[0m[0mfig[0m[0;34m.[0m[0madd_subplot[0m[0;34m([0m[0;36m7[0m[0;34m,[0m[0;36m2[0m[0;34m,[0m[0mi[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m     [0msns[0m[0;34m.[0m[0mregplot[0m[0;34m([0m[0mdev_train[0m[0;34m[[0m[0mcol[0m[0;34m][0m[0;34m,[0m[0mdev_train[0m[0;34m.[0m[0mSeriousDlqin2yrs[0m[0;34m,[0m[0max[0m[0;34m=[0m[0maxes[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0mplt[0m[0;34m.[0m[0mshow[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mTypeError[0m: regplot() takes from 0 to 1 positional arguments but 2 positional arguments (and 1 keyword-only argument) were given
TypeError: regplot() takes from 0 to 1 positional arguments but 2 positional arguments (and 1 keyword-only argument) were given
",TypeError,regplot() takes from 0 to 1 positional arguments but 2 positional arguments (and 1 keyword-only argument) were given
/junobench_env/NBspecific_1/NBspecific_1_extension.ipynb,2026-01-14T16:37:00.489958,CellExecutionError,"An error occurred while executing the following cell:
------------------

import nltk 
nltk.download('punkt') # For word_tokenize and sent_tokenize 
nltk.download('stopwords') # For stopwords 
nltk.download('wordnet') # For WordNetLemmatizer 
nltk.download('omw-1.4') # For WordNetLemmatizer (often needed for WordNet)

lemmatizer = WordNetLemmatizer()

def lemma_words(text):
    return "" "".join([lemmatizer.lemmatize(word) for word in text])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-27-d6ce47d93672>[0m in [0;36m<cell line: 7>[0;34m()[0m
[1;32m      5[0m [0mnltk[0m[0;34m.[0m[0mdownload[0m[0;34m([0m[0;34m'omw-1.4'[0m[0;34m)[0m [0;31m# For WordNetLemmatizer (often needed for WordNet)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m [0;34m[0m[0m
[0;32m----> 7[0;31m [0mlemmatizer[0m [0;34m=[0m [0mWordNetLemmatizer[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      8[0m [0;34m[0m[0m
[1;32m      9[0m [0;32mdef[0m [0mlemma_words[0m[0;34m([0m[0mtext[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mNameError[0m: name 'WordNetLemmatizer' is not defined
NameError: name 'WordNetLemmatizer' is not defined
",NameError,name 'WordNetLemmatizer' is not defined
/junobench_env/numpy_12/numpy_12_extension.ipynb,2026-01-14T16:37:41.330320,CellExecutionError,"An error occurred while executing the following cell:
------------------
# make predictions
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
# invert predictions
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform(trainY.reshape(-1, 1))
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform(testY.reshape(-1, 1))
# calculate root mean squared error
trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-9-9be0cf7ad6ef>[0m in [0;36m<cell line: 10>[0;34m()[0m
[1;32m      8[0m [0mtestY[0m [0;34m=[0m [0mscaler[0m[0;34m.[0m[0minverse_transform[0m[0;34m([0m[0mtestY[0m[0;34m.[0m[0mreshape[0m[0;34m([0m[0;34m-[0m[0;36m1[0m[0;34m,[0m [0;36m1[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m [0;31m# calculate root mean squared error[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 10[0;31m [0mtrainScore[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0msqrt[0m[0;34m([0m[0mmean_squared_error[0m[0;34m([0m[0mtrainY[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m,[0m [0mtrainPredict[0m[0;34m[[0m[0;34m:[0m[0;34m,[0m[0;36m0[0m[0;34m][0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     11[0m [0mprint[0m[0;34m([0m[0;34m'Train Score: %.2f RMSE'[0m [0;34m%[0m [0;34m([0m[0mtrainScore[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     12[0m [0mtestScore[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0msqrt[0m[0;34m([0m[0mmean_squared_error[0m[0;34m([0m[0mtestY[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m,[0m [0mtestPredict[0m[0;34m[[0m[0;34m:[0m[0;34m,[0m[0;36m0[0m[0;34m][0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py[0m in [0;36mmean_squared_error[0;34m(y_true, y_pred, sample_weight, multioutput, squared)[0m
[1;32m    440[0m     [0;36m0.825[0m[0;34m...[0m[0;34m[0m[0;34m[0m[0m
[1;32m    441[0m     """"""
[0;32m--> 442[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(
[0m[1;32m    443[0m         [0my_true[0m[0;34m,[0m [0my_pred[0m[0;34m,[0m [0mmultioutput[0m[0;34m[0m[0;34m[0m[0m
[1;32m    444[0m     )

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py[0m in [0;36m_check_reg_targets[0;34m(y_true, y_pred, multioutput, dtype)[0m
[1;32m     98[0m         [0mcorrect[0m [0mkeyword[0m[0;34m.[0m[0;34m[0m[0;34m[0m[0m
[1;32m     99[0m     """"""
[0;32m--> 100[0;31m     [0mcheck_consistent_length[0m[0;34m([0m[0my_true[0m[0;34m,[0m [0my_pred[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    101[0m     [0my_true[0m [0;34m=[0m [0mcheck_array[0m[0;34m([0m[0my_true[0m[0;34m,[0m [0mensure_2d[0m[0;34m=[0m[0;32mFalse[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    102[0m     [0my_pred[0m [0;34m=[0m [0mcheck_array[0m[0;34m([0m[0my_pred[0m[0;34m,[0m [0mensure_2d[0m[0;34m=[0m[0;32mFalse[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py[0m in [0;36mcheck_consistent_length[0;34m(*arrays)[0m
[1;32m    395[0m     [0muniques[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0munique[0m[0;34m([0m[0mlengths[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    396[0m     [0;32mif[0m [0mlen[0m[0;34m([0m[0muniques[0m[0;34m)[0m [0;34m>[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 397[0;31m         raise ValueError(
[0m[1;32m    398[0m             [0;34m""Found input variables with inconsistent numbers of samples: %r""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    399[0m             [0;34m%[0m [0;34m[[0m[0mint[0m[0;34m([0m[0ml[0m[0;34m)[0m [0;32mfor[0m [0ml[0m [0;32min[0m [0mlengths[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: Found input variables with inconsistent numbers of samples: [1, 95]
ValueError: Found input variables with inconsistent numbers of samples: [1, 95]
",ValueError,"Found input variables with inconsistent numbers of samples: [1, 95]"
/junobench_env/numpy_15/numpy_15_extension.ipynb,2026-01-14T16:38:01.214955,CellExecutionError,"An error occurred while executing the following cell:
------------------
#Get number of features
n_features = X_tr_arr.shape[1]
print('Number of Features', n_features)
w, b = weightInitialization(n_features)
#Gradient Descent
coeff, gradient, costs = model_predict(w, b, X_tr_arr, y_tr_arr, learning_rate=0.0001,no_iterations=4500)
#Final prediction
w = coeff[""w""]
b = coeff[""b""]
print('Optimized weights', w)
print('Optimized intercept',b)
#
final_train_pred = sigmoid_activation(np.dot(w,X_tr_arr.T)+b)
final_test_pred = sigmoid_activation(np.dot(w,X_ts_arr.T)+b)
#
m_tr =  X_tr_arr.shape[0]
m_ts =  X_ts_arr.shape[0]
#
y_tr_pred = predict(final_train_pred, m_tr)
print('Training Accuracy',accuracy_score(y_tr_pred.T, y_tr_arr))
#
y_ts_pred = predict(final_test_pred, m_ts)
print('Test Accuracy',accuracy_score(y_ts_pred.T, y_ts_arr))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-29-2e390b463717>[0m in [0;36m<cell line: 6>[0;34m()[0m
[1;32m      4[0m [0mw[0m[0;34m,[0m [0mb[0m [0;34m=[0m [0mweightInitialization[0m[0;34m([0m[0mn_features[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0;31m#Gradient Descent[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 6[0;31m [0mcoeff[0m[0;34m,[0m [0mgradient[0m[0;34m,[0m [0mcosts[0m [0;34m=[0m [0mmodel_predict[0m[0;34m([0m[0mw[0m[0;34m,[0m [0mb[0m[0;34m,[0m [0mX_tr_arr[0m[0;34m,[0m [0my_tr_arr[0m[0;34m,[0m [0mlearning_rate[0m[0;34m=[0m[0;36m0.0001[0m[0;34m,[0m[0mno_iterations[0m[0;34m=[0m[0;36m4500[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      7[0m [0;31m#Final prediction[0m[0;34m[0m[0;34m[0m[0m
[1;32m      8[0m [0mw[0m [0;34m=[0m [0mcoeff[0m[0;34m[[0m[0;34m""w""[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m<ipython-input-27-f28af5fdf927>[0m in [0;36mmodel_predict[0;34m(w, b, X, Y, learning_rate, no_iterations)[0m
[1;32m      3[0m     [0;32mfor[0m [0mi[0m [0;32min[0m [0mrange[0m[0;34m([0m[0mno_iterations[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m         [0;31m#[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 5[0;31m         [0mgrads[0m[0;34m,[0m [0mcost[0m [0;34m=[0m [0mmodel_optimize[0m[0;34m([0m[0mw[0m[0;34m,[0m[0mb[0m[0;34m,[0m[0mX[0m[0;34m,[0m[0mY[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      6[0m         [0;31m#[0m[0;34m[0m[0;34m[0m[0m
[1;32m      7[0m         [0mdw[0m [0;34m=[0m [0mgrads[0m[0;34m[[0m[0;34m""dw""[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m<ipython-input-26-c5c1f7b34b69>[0m in [0;36mmodel_optimize[0;34m(w, b, X, Y)[0m
[1;32m     12[0m     [0mm[0m [0;34m=[0m [0mX[0m[0;34m.[0m[0mshape[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[1;32m     13[0m [0;34m[0m[0m
[0;32m---> 14[0;31m     [0mfinal_result[0m [0;34m=[0m [0msigmoid[0m[0;34m([0m[0mnp[0m[0;34m.[0m[0mdot[0m[0;34m([0m[0mX[0m[0;34m,[0m [0mw[0m[0;34m)[0m [0;34m+[0m [0mb[0m[0;34m)[0m  [0;31m# (m, 1)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     15[0m [0;34m[0m[0m
[1;32m     16[0m     cost = (-1/m) * np.sum(

[0;31mValueError[0m: shapes (75,4) and (1,4) not aligned: 4 (dim 1) != 1 (dim 0)
ValueError: shapes (75,4) and (1,4) not aligned: 4 (dim 1) != 1 (dim 0)
",ValueError,"shapes (75,4) and (1,4) not aligned: 4 (dim 1) != 1 (dim 0)"
/junobench_env/NBspecific_6/NBspecific_6_extension.ipynb,2026-01-14T16:39:15.013038,CellExecutionError,"An error occurred while executing the following cell:
------------------
history = model.fit(TrainBatch
          ,validation_data=ValidationBatch,
          epochs=2, verbose=1, callbacks=[model_checkpoint_callback])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-17-8dea61041ba9>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m history = model.fit(TrainBatch
[0m[1;32m      2[0m           [0;34m,[0m[0mvalidation_data[0m[0;34m=[0m[0mValidationBatch[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m           epochs=2, verbose=1, callbacks=[model_checkpoint_callback])

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
[1;32m    120[0m             [0;31m# To get the full stack trace, call:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    121[0m             [0;31m# `keras.config.disable_traceback_filtering()`[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 122[0;31m             [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    123[0m         [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    124[0m             [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py[0m in [0;36m_standardize_batch[0;34m(self, batch)[0m
[1;32m    199[0m             [0mbatch[0m [0;34m=[0m [0mtuple[0m[0;34m([0m[0mbatch[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    200[0m         [0;32mif[0m [0;32mnot[0m [0misinstance[0m[0;34m([0m[0mbatch[0m[0;34m,[0m [0mtuple[0m[0;34m)[0m [0;32mor[0m [0mlen[0m[0;34m([0m[0mbatch[0m[0;34m)[0m [0;32mnot[0m [0;32min[0m [0;34m{[0m[0;36m1[0m[0;34m,[0m [0;36m2[0m[0;34m,[0m [0;36m3[0m[0;34m}[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 201[0;31m             raise ValueError(
[0m[1;32m    202[0m                 [0;34m""PyDataset.__getitem__() must return a tuple or a dict. ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    203[0m                 [0;34m""If a tuple, it must be ordered either ""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: PyDataset.__getitem__() must return a tuple or a dict. If a tuple, it must be ordered either (input,) or (inputs, targets) or (inputs, targets, sample_weights). Received: None... of type <class 'NoneType'>
ValueError: PyDataset.__getitem__() must return a tuple or a dict. If a tuple, it must be ordered either (input,) or (inputs, targets) or (inputs, targets, sample_weights). Received: None... of type <class 'NoneType'>
",ValueError,"PyDataset.__getitem__() must return a tuple or a dict. If a tuple, it must be ordered either (input,) or (inputs, targets) or (inputs, targets, sample_weights). Received: None... of type <class 'NoneType'>"
/junobench_env/seaborn_5/seaborn_5_extension.ipynb,2026-01-14T16:39:50.132229,CellExecutionError,"An error occurred while executing the following cell:
------------------
def batch_visualize(df,batch_size,path):
    sample_df = df_train.sample(9)
    image_names = sample_df[""image""].values
    labels = sample_df[""labels""].values
    plt.figure(figsize=(16, 12))
    
    for image_ind, (image_name, label) in enumerate(zip(image_names, labels)):
        plt.subplot(3, 3, image_ind + 1)
        image = cv2.imread(os.path.join(path, image_name))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        plt.imshow(image)
        plt.title(f""{label}"", fontsize=12)
        plt.axis(""off"")
    plt.show()
    
batch_visualize(df_train,9,train_image_path)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31merror[0m                                     Traceback (most recent call last)
[0;32m<ipython-input-7-659613e6003d>[0m in [0;36m<cell line: 16>[0;34m()[0m
[1;32m     14[0m     [0mplt[0m[0;34m.[0m[0mshow[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     15[0m [0;34m[0m[0m
[0;32m---> 16[0;31m [0mbatch_visualize[0m[0;34m([0m[0mdf_train[0m[0;34m,[0m[0;36m9[0m[0;34m,[0m[0mtrain_image_path[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m<ipython-input-7-659613e6003d>[0m in [0;36mbatch_visualize[0;34m(df, batch_size, path)[0m
[1;32m      8[0m         [0mplt[0m[0;34m.[0m[0msubplot[0m[0;34m([0m[0;36m3[0m[0;34m,[0m [0;36m3[0m[0;34m,[0m [0mimage_ind[0m [0;34m+[0m [0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m         [0mimage[0m [0;34m=[0m [0mcv2[0m[0;34m.[0m[0mimread[0m[0;34m([0m[0mos[0m[0;34m.[0m[0mpath[0m[0;34m.[0m[0mjoin[0m[0;34m([0m[0mpath[0m[0;34m,[0m [0mimage_name[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 10[0;31m         [0mimage[0m [0;34m=[0m [0mcv2[0m[0;34m.[0m[0mcvtColor[0m[0;34m([0m[0mimage[0m[0;34m,[0m [0mcv2[0m[0;34m.[0m[0mCOLOR_BGR2RGB[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     11[0m         [0mplt[0m[0;34m.[0m[0mimshow[0m[0;34m([0m[0mimage[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     12[0m         [0mplt[0m[0;34m.[0m[0mtitle[0m[0;34m([0m[0;34mf""{label}""[0m[0;34m,[0m [0mfontsize[0m[0;34m=[0m[0;36m12[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31merror[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'

error: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'

",,
/junobench_env/numpy_1/numpy_1_extension.ipynb,2026-01-14T16:40:49.877922,CellExecutionError,"An error occurred while executing the following cell:
------------------
from torchsummary import summary
g = Gen(100,3,64)
d = Discriminator(3)
print(summary(d, input_size=[1, 3, 64, 64]))
summary(g, input_size=[1, 100, 1, 1])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-16-29f5823dbee2>[0m in [0;36m<cell line: 4>[0;34m()[0m
[1;32m      2[0m [0mg[0m [0;34m=[0m [0mGen[0m[0;34m([0m[0;36m100[0m[0;34m,[0m[0;36m3[0m[0;34m,[0m[0;36m64[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0md[0m [0;34m=[0m [0mDiscriminator[0m[0;34m([0m[0;36m3[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m [0mprint[0m[0;34m([0m[0msummary[0m[0;34m([0m[0md[0m[0;34m,[0m [0minput_size[0m[0;34m=[0m[0;34m[[0m[0;36m1[0m[0;34m,[0m [0;36m3[0m[0;34m,[0m [0;36m64[0m[0;34m,[0m [0;36m64[0m[0;34m][0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0msummary[0m[0;34m([0m[0mg[0m[0;34m,[0m [0minput_size[0m[0;34m=[0m[0;34m[[0m[0;36m1[0m[0;34m,[0m [0;36m100[0m[0;34m,[0m [0;36m1[0m[0;34m,[0m [0;36m1[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py[0m in [0;36msummary[0;34m(model, input_size, batch_size, device)[0m
[1;32m     58[0m [0;34m[0m[0m
[1;32m     59[0m     [0;31m# batch_size of 2 for batchnorm[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 60[0;31m     [0mx[0m [0;34m=[0m [0;34m[[0m[0mtorch[0m[0;34m.[0m[0mrand[0m[0;34m([0m[0;36m2[0m[0;34m,[0m [0;34m*[0m[0min_size[0m[0;34m)[0m[0;34m.[0m[0mtype[0m[0;34m([0m[0mdtype[0m[0;34m)[0m [0;32mfor[0m [0min_size[0m [0;32min[0m [0minput_size[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     61[0m     [0;31m# print(type(x[0]))[0m[0;34m[0m[0;34m[0m[0m
[1;32m     62[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py[0m in [0;36m<listcomp>[0;34m(.0)[0m
[1;32m     58[0m [0;34m[0m[0m
[1;32m     59[0m     [0;31m# batch_size of 2 for batchnorm[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 60[0;31m     [0mx[0m [0;34m=[0m [0;34m[[0m[0mtorch[0m[0;34m.[0m[0mrand[0m[0;34m([0m[0;36m2[0m[0;34m,[0m [0;34m*[0m[0min_size[0m[0;34m)[0m[0;34m.[0m[0mtype[0m[0;34m([0m[0mdtype[0m[0;34m)[0m [0;32mfor[0m [0min_size[0m [0;32min[0m [0minput_size[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     61[0m     [0;31m# print(type(x[0]))[0m[0;34m[0m[0;34m[0m[0m
[1;32m     62[0m [0;34m[0m[0m

[0;31mTypeError[0m: Value after * must be an iterable, not int
TypeError: Value after * must be an iterable, not int
",TypeError,"Value after * must be an iterable, not int"
/junobench_env/numpy_6/numpy_6_extension.ipynb,2026-01-14T16:40:59.245283,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Create X_data as a pandas dataframe
X_data = pd.DataFrame(columns=['image'])

# Loop over the images and load them into X_data
for i, file_path in enumerate(train_labels):
    img = cv2.imread(file_path)
    print(i, file_path, img)
    x = np.expand_dims(img,axis=0)
    print(i, x)
    X_data.loc[i] = x[i] / 255.0

# Create train_labels as a pandas dataframe
# train_labels = pd.read_csv('/kaggle/input/dog-breeding/New folder/train')

# Merge X_data and train_labels on the 'id' column
# train_data = pd.merge(X_data, train_labels, on='id')

# Print train image and one hot encode shape & size
print('\nTrain Images shape:', X_data.shape, ' size: {:,}'.format(X_data.size))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-9-2d8c0b6b9b90>[0m in [0;36m<cell line: 5>[0;34m()[0m
[1;32m      8[0m     [0mx[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mexpand_dims[0m[0;34m([0m[0mimg[0m[0;34m,[0m[0maxis[0m[0;34m=[0m[0;36m0[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m     [0mprint[0m[0;34m([0m[0mi[0m[0;34m,[0m [0mx[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 10[0;31m     [0mX_data[0m[0;34m.[0m[0mloc[0m[0;34m[[0m[0mi[0m[0;34m][0m [0;34m=[0m [0mx[0m[0;34m[[0m[0mi[0m[0;34m][0m [0;34m/[0m [0;36m255.0[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     11[0m [0;34m[0m[0m
[1;32m     12[0m [0;31m# Create train_labels as a pandas dataframe[0m[0;34m[0m[0;34m[0m[0m

[0;31mTypeError[0m: unsupported operand type(s) for /: 'NoneType' and 'float'
TypeError: unsupported operand type(s) for /: 'NoneType' and 'float'
",TypeError,unsupported operand type(s) for /: 'NoneType' and 'float'
/junobench_env/numpy_8/numpy_8_extension.ipynb,2026-01-14T16:59:06.357490,CellTimeoutError,"A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['#была обнаружена проблема несбалансированных классов в задаче бинарной классификации. В данных было намного больше объектов с положительным классом (клиенты, вернувшие кредит вовремя) по сравнению с отрицательным классом (клиенты, не вернувшие кредит вовремя).', '#В данном проекте параметр class_weight был установлен в значение ""balanced"". Это значение автоматически вычисляет веса классов, основываясь на их соотношении в данных, и присваивает больший вес редкому классу. ', ""param_grid = {'criterion' : ['gini'],"", ""             'class_weight' : ['balanced_subsample','balanced',None],"", ""             'max_features' : ['sqrt', 'log2']}""]
...
[""grid_cv = RandomizedSearchCV(rf2,param_grid, cv=5,  scoring = 'roc_auc')"", '', 'grid_cv.fit(X_train, y_train)', '', 'y_pred = grid_cv.predict_proba(X_val)']
-------------------
",,
/junobench_env/sklearn_2/sklearn_2_extension.ipynb,2026-01-14T17:21:37.137364,CellTimeoutError,"A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# RandomForestRegressor için optimize edilecek hiperparametreleri tanımlayın', '# param_grid = {', ""#     'max_depth': [20, 25, 30],"", ""#     'n_estimators': [100, 150],"", ""#     'min_samples_split': [1, 2],""]
...
['rmse = sqrt(mse)', '', 'print(""R2 score  :"", r2)', 'print(""MSE score  :"", mse)', 'print(""RMSE: "", rmse)']
-------------------
",,
/junobench_env/seaborn_4/seaborn_4_extension.ipynb,2026-01-14T17:22:02.205478,CellExecutionError,"An error occurred while executing the following cell:
------------------
from sklearn.linear_model import LinearRegression
model = LinearRegression(normalize=True)
train(model, X, y)
coef = pd.Series(model.coef_, X.columns).sort_values()
coef.plot(kind='bar', title='Model Coefficients')
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-13-35f65edbe23f>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;32mfrom[0m [0msklearn[0m[0;34m.[0m[0mlinear_model[0m [0;32mimport[0m [0mLinearRegression[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mmodel[0m [0;34m=[0m [0mLinearRegression[0m[0;34m([0m[0mnormalize[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      3[0m [0mtrain[0m[0;34m([0m[0mmodel[0m[0;34m,[0m [0mX[0m[0;34m,[0m [0my[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0mcoef[0m [0;34m=[0m [0mpd[0m[0;34m.[0m[0mSeries[0m[0;34m([0m[0mmodel[0m[0;34m.[0m[0mcoef_[0m[0;34m,[0m [0mX[0m[0;34m.[0m[0mcolumns[0m[0;34m)[0m[0;34m.[0m[0msort_values[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0mcoef[0m[0;34m.[0m[0mplot[0m[0;34m([0m[0mkind[0m[0;34m=[0m[0;34m'bar'[0m[0;34m,[0m [0mtitle[0m[0;34m=[0m[0;34m'Model Coefficients'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mTypeError[0m: LinearRegression.__init__() got an unexpected keyword argument 'normalize'
TypeError: LinearRegression.__init__() got an unexpected keyword argument 'normalize'
",TypeError,LinearRegression.__init__() got an unexpected keyword argument 'normalize'
/junobench_env/numpy_14/numpy_14_extension.ipynb,2026-01-14T17:26:02.506571,CellExecutionError,"An error occurred while executing the following cell:
------------------
y_true_classes = np.argmax(test_generator.classes, axis=1)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAxisError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-22-0fa97c5658e1>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0my_true_classes[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0margmax[0m[0;34m([0m[0mtest_generator[0m[0;34m.[0m[0mclasses[0m[0;34m,[0m [0maxis[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py[0m in [0;36margmax[0;34m(a, axis, out, keepdims)[0m
[1;32m   1227[0m     """"""
[1;32m   1228[0m     [0mkwds[0m [0;34m=[0m [0;34m{[0m[0;34m'keepdims'[0m[0;34m:[0m [0mkeepdims[0m[0;34m}[0m [0;32mif[0m [0mkeepdims[0m [0;32mis[0m [0;32mnot[0m [0mnp[0m[0;34m.[0m[0m_NoValue[0m [0;32melse[0m [0;34m{[0m[0;34m}[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1229[0;31m     [0;32mreturn[0m [0m_wrapfunc[0m[0;34m([0m[0ma[0m[0;34m,[0m [0;34m'argmax'[0m[0;34m,[0m [0maxis[0m[0;34m=[0m[0maxis[0m[0;34m,[0m [0mout[0m[0;34m=[0m[0mout[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1230[0m [0;34m[0m[0m
[1;32m   1231[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py[0m in [0;36m_wrapfunc[0;34m(obj, method, *args, **kwds)[0m
[1;32m     57[0m [0;34m[0m[0m
[1;32m     58[0m     [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 59[0;31m         [0;32mreturn[0m [0mbound[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     60[0m     [0;32mexcept[0m [0mTypeError[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     61[0m         [0;31m# A TypeError occurs if the object does have such a method in its[0m[0;34m[0m[0;34m[0m[0m

[0;31mAxisError[0m: axis 1 is out of bounds for array of dimension 1
AxisError: axis 1 is out of bounds for array of dimension 1
",AxisError,axis 1 is out of bounds for array of dimension 1
/junobench_env/statsmodels_2/statsmodels_2_extension.ipynb,2026-01-14T17:36:29.751006,CellTimeoutError,"A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['import pandas as pd', 'import numpy as np', 'from statsmodels.tsa.statespace.sarimax import SARIMAX', 'from sklearn.metrics import mean_squared_error', 'from statsmodels.tools.eval_measures import rmse']
...
['    bestp, bestd, bestq, bestP, bestD, bestQ, bests = best_params', '    print(f""Best Parameters: p={bestp}, d={bestd}, q={bestq}, P={bestP}, D={bestD}, Q={bestQ}, s={bests}"")', '    print(f""Best RMSE: {best_rmse}"")', 'else:', '    print(""No valid model found during grid search."")']
-------------------
",,
/junobench_env/numpy_13/numpy_13_extension.ipynb,2026-01-14T17:36:50.981688,CellExecutionError,"An error occurred while executing the following cell:
------------------
df[""Chord Type""] = df[""Chord Type""].replace(""Major"", 1)
df[""Chord Type""] = df[""Chord Type""].replace(""Minor"", 0)

#columns = [3::]
#columns.extend([""Interval 4_1"", ""Interval 5_1"", ""Interval 6_1""])
train_X, val_X, train_y, val_y = train_test_split(dfarray, df[""Chord Type""], test_size=0.2, random_state=0)

train_X
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-31-7528e0b1edf5>[0m in [0;36m<cell line: 6>[0;34m()[0m
[1;32m      4[0m [0;31m#columns = [3::][0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0;31m#columns.extend([""Interval 4_1"", ""Interval 5_1"", ""Interval 6_1""])[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 6[0;31m [0mtrain_X[0m[0;34m,[0m [0mval_X[0m[0;34m,[0m [0mtrain_y[0m[0;34m,[0m [0mval_y[0m [0;34m=[0m [0mtrain_test_split[0m[0;34m([0m[0mdfarray[0m[0;34m,[0m [0mdf[0m[0;34m[[0m[0;34m""Chord Type""[0m[0;34m][0m[0;34m,[0m [0mtest_size[0m[0;34m=[0m[0;36m0.2[0m[0;34m,[0m [0mrandom_state[0m[0;34m=[0m[0;36m0[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      7[0m [0;34m[0m[0m
[1;32m      8[0m [0mtrain_X[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py[0m in [0;36mtrain_test_split[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)[0m
[1;32m   2560[0m [0;34m[0m[0m
[1;32m   2561[0m     [0mn_samples[0m [0;34m=[0m [0m_num_samples[0m[0;34m([0m[0marrays[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 2562[0;31m     n_train, n_test = _validate_shuffle_split(
[0m[1;32m   2563[0m         [0mn_samples[0m[0;34m,[0m [0mtest_size[0m[0;34m,[0m [0mtrain_size[0m[0;34m,[0m [0mdefault_test_size[0m[0;34m=[0m[0;36m0.25[0m[0;34m[0m[0;34m[0m[0m
[1;32m   2564[0m     )

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py[0m in [0;36m_validate_shuffle_split[0;34m(n_samples, test_size, train_size, default_test_size)[0m
[1;32m   2234[0m [0;34m[0m[0m
[1;32m   2235[0m     [0;32mif[0m [0mn_train[0m [0;34m==[0m [0;36m0[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 2236[0;31m         raise ValueError(
[0m[1;32m   2237[0m             [0;34m""With n_samples={}, test_size={} and train_size={}, the ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m   2238[0m             [0;34m""resulting train set will be empty. Adjust any of the ""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
ValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
",ValueError,"With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
/junobench_env/seaborn_3/seaborn_3_extension.ipynb,2026-01-14T17:36:59.950891,CellExecutionError,"An error occurred while executing the following cell:
------------------
corr = df[num_cols].corr()
corr

# Korelasyonların gösterilmesi
sns.set(rc={'figure.figsize': (12, 12)})
sns.heatmap(corr, cmap=""RdBu"")
plt.show(block=True)



def high_correlated_cols(dataframe, plot=False, corr_th=0.70):
    corr = dataframe.corr()
    cor_matrix = corr.abs()
    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))
    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]
    if plot:
        import seaborn as sns
        import matplotlib.pyplot as plt
        sns.set(rc={'figure.figsize': (15, 15)})
        sns.heatmap(corr, cmap=""RdBu"")
        plt.show(block=True)
    return drop_list

high_correlated_cols(df, plot=True)

df.shape
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAttributeError[0m                            Traceback (most recent call last)
[0;32m<ipython-input-9-4971d8791244>[0m in [0;36m<cell line: 24>[0;34m()[0m
[1;32m     22[0m     [0;32mreturn[0m [0mdrop_list[0m[0;34m[0m[0;34m[0m[0m
[1;32m     23[0m [0;34m[0m[0m
[0;32m---> 24[0;31m [0mhigh_correlated_cols[0m[0;34m([0m[0mdf[0m[0;34m,[0m [0mplot[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     25[0m [0;34m[0m[0m
[1;32m     26[0m [0mdf[0m[0;34m.[0m[0mshape[0m[0;34m[0m[0;34m[0m[0m

[0;32m<ipython-input-9-4971d8791244>[0m in [0;36mhigh_correlated_cols[0;34m(dataframe, plot, corr_th)[0m
[1;32m     12[0m     [0mcorr[0m [0;34m=[0m [0mdataframe[0m[0;34m.[0m[0mcorr[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     13[0m     [0mcor_matrix[0m [0;34m=[0m [0mcorr[0m[0;34m.[0m[0mabs[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 14[0;31m     [0mupper_triangle_matrix[0m [0;34m=[0m [0mcor_matrix[0m[0;34m.[0m[0mwhere[0m[0;34m([0m[0mnp[0m[0;34m.[0m[0mtriu[0m[0;34m([0m[0mnp[0m[0;34m.[0m[0mones[0m[0;34m([0m[0mcor_matrix[0m[0;34m.[0m[0mshape[0m[0;34m)[0m[0;34m,[0m [0mk[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m.[0m[0mastype[0m[0;34m([0m[0mnp[0m[0;34m.[0m[0mbool[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     15[0m     [0mdrop_list[0m [0;34m=[0m [0;34m[[0m[0mcol[0m [0;32mfor[0m [0mcol[0m [0;32min[0m [0mupper_triangle_matrix[0m[0;34m.[0m[0mcolumns[0m [0;32mif[0m [0many[0m[0;34m([0m[0mupper_triangle_matrix[0m[0;34m[[0m[0mcol[0m[0;34m][0m [0;34m>[0m [0mcorr_th[0m[0;34m)[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[1;32m     16[0m     [0;32mif[0m [0mplot[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py[0m in [0;36m__getattr__[0;34m(attr)[0m
[1;32m    322[0m [0;34m[0m[0m
[1;32m    323[0m         [0;32mif[0m [0mattr[0m [0;32min[0m [0m__former_attrs__[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 324[0;31m             [0;32mraise[0m [0mAttributeError[0m[0;34m([0m[0m__former_attrs__[0m[0;34m[[0m[0mattr[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    325[0m [0;34m[0m[0m
[1;32m    326[0m         [0;32mif[0m [0mattr[0m [0;34m==[0m [0;34m'testing'[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mAttributeError[0m: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
AttributeError: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
",AttributeError,module 'numpy' has no attribute 'bool'.
/junobench_env/tensorflow_12/tensorflow_12_extension.ipynb,2026-01-14T17:37:30.606640,CellExecutionError,"An error occurred while executing the following cell:
------------------
# history = model.fit(train_images, train_labels, batch_size = 16, epochs=2, validation_data=(val_images, val_labels), verbose = 1)
model.compile(optimizer=Adam(0.0001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])
history = model.fit(
    train_images, train_labels,
    batch_size=16,
    epochs=20,
    validation_data=(val_images, val_labels),
    verbose=1
)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mInvalidArgumentError[0m                      Traceback (most recent call last)
[0;32m<ipython-input-11-9ce01cfc5385>[0m in [0;36m<cell line: 3>[0;34m()[0m
[1;32m      1[0m [0;31m# history = model.fit(train_images, train_labels, batch_size = 16, epochs=2, validation_data=(val_images, val_labels), verbose = 1)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      2[0m [0mmodel[0m[0;34m.[0m[0mcompile[0m[0;34m([0m[0moptimizer[0m[0;34m=[0m[0mAdam[0m[0;34m([0m[0;36m0.0001[0m[0;34m)[0m[0;34m,[0m [0mloss[0m[0;34m=[0m[0mtf[0m[0;34m.[0m[0mkeras[0m[0;34m.[0m[0mlosses[0m[0;34m.[0m[0mSparseCategoricalCrossentropy[0m[0;34m([0m[0mfrom_logits[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m,[0m [0mmetrics[0m[0;34m=[0m[0;34m[[0m[0;34m'accuracy'[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 3[0;31m history = model.fit(
[0m[1;32m      4[0m     [0mtrain_images[0m[0;34m,[0m [0mtrain_labels[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m     [0mbatch_size[0m[0;34m=[0m[0;36m16[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
[1;32m    120[0m             [0;31m# To get the full stack trace, call:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    121[0m             [0;31m# `keras.config.disable_traceback_filtering()`[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 122[0;31m             [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    123[0m         [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    124[0m             [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     51[0m   [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     52[0m     [0mctx[0m[0;34m.[0m[0mensure_initialized[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 53[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
[0m[1;32m     54[0m                                         inputs, attrs, num_outputs)
[1;32m     55[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mInvalidArgumentError[0m: Graph execution error:

Detected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):
  File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main

  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 16, in <module>

  File ""/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 992, in launch_instance

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 619, in start

  File ""/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 195, in start

  File ""/usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever

  File ""/usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once

  File ""/usr/lib/python3.10/asyncio/events.py"", line 80, in _run

  File ""/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py"", line 685, in <lambda>

  File ""/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py"", line 738, in _run_callback

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 825, in inner

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 786, in run

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 377, in dispatch_queue

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 250, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 748, in __init__

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 786, in run

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 361, in process_one

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 261, in dispatch_shell

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 539, in execute_request

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 302, in do_execute

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 539, in run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 2975, in run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3030, in _run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 78, in _pseudo_sync_runner

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3257, in run_cell_async

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3473, in run_ast_nodes

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code

  File ""<ipython-input-11-9ce01cfc5385>"", line 3, in <cell line: 3>

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 318, in fit

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 121, in one_step_on_iterator

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 108, in one_step_on_data

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 54, in train_step

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py"", line 357, in _compute_loss

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py"", line 325, in compute_loss

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py"", line 609, in __call__

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py"", line 645, in call

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py"", line 43, in __call__

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py"", line 27, in call

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py"", line 1853, in sparse_categorical_crossentropy

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py"", line 1567, in sparse_categorical_crossentropy

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py"", line 645, in sparse_categorical_crossentropy

Received a label value of 4 which is outside the valid range of [0, 4).  Label values: 2 2 1 1 2 1 1 1 2 3 1 1 3 1 1 4
	 [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11104]
InvalidArgumentError: Graph execution error:

Detected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):
  File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main

  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py"", line 16, in <module>

  File ""/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py"", line 992, in launch_instance

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py"", line 619, in start

  File ""/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py"", line 195, in start

  File ""/usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever

  File ""/usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once

  File ""/usr/lib/python3.10/asyncio/events.py"", line 80, in _run

  File ""/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py"", line 685, in <lambda>

  File ""/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py"", line 738, in _run_callback

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 825, in inner

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 786, in run

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 377, in dispatch_queue

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 250, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 748, in __init__

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 786, in run

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 361, in process_one

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 261, in dispatch_shell

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py"", line 539, in execute_request

  File ""/usr/local/lib/python3.10/dist-packages/tornado/gen.py"", line 234, in wrapper

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py"", line 302, in do_execute

  File ""/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py"", line 539, in run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 2975, in run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3030, in _run_cell

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py"", line 78, in _pseudo_sync_runner

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3257, in run_cell_async

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3473, in run_ast_nodes

  File ""/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py"", line 3553, in run_code

  File ""<ipython-input-11-9ce01cfc5385>"", line 3, in <cell line: 3>

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"", line 117, in error_handler

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 318, in fit

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 121, in one_step_on_iterator

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 108, in one_step_on_data

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py"", line 54, in train_step

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py"", line 357, in _compute_loss

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py"", line 325, in compute_loss

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py"", line 609, in __call__

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/trainers/compile_utils.py"", line 645, in call

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py"", line 43, in __call__

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py"", line 27, in call

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py"", line 1853, in sparse_categorical_crossentropy

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py"", line 1567, in sparse_categorical_crossentropy

  File ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py"", line 645, in sparse_categorical_crossentropy

Received a label value of 4 which is outside the valid range of [0, 4).  Label values: 2 2 1 1 2 1 1 1 2 3 1 1 3 1 1 4
	 [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11104]
",InvalidArgumentError,Graph execution error:
/junobench_env/tensorflow_2/tensorflow_2_extension.ipynb,2026-01-14T17:38:12.325447,CellExecutionError,"An error occurred while executing the following cell:
------------------
def prepare_model():
    model = Sequential()
    model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(100, 100, 3)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dense(256, activation='relu'))
    model.add(Dense(2, activation='softmax'))
    model.compile(loss=""categorical_crossentropy"",optimizer=""adam"",metrics=['accuracy'])
    return model
model = prepare_model()
model.fit_generator(train_generator,
                    validation_data = valid_generator,
#                     steps_per_epoch = train_generator.n//train_generator.batch_size,
#                     validation_steps = valid_generator.n//valid_generator.batch_size,
                    epochs=5)
model.evaluate(test_generator)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAttributeError[0m                            Traceback (most recent call last)
[0;32m<ipython-input-8-8c089253bbc3>[0m in [0;36m<cell line: 12>[0;34m()[0m
[1;32m     10[0m     [0;32mreturn[0m [0mmodel[0m[0;34m[0m[0;34m[0m[0m
[1;32m     11[0m [0mmodel[0m [0;34m=[0m [0mprepare_model[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 12[0;31m model.fit_generator(train_generator,
[0m[1;32m     13[0m                     [0mvalidation_data[0m [0;34m=[0m [0mvalid_generator[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m     14[0m [0;31m#                     steps_per_epoch = train_generator.n//train_generator.batch_size,[0m[0;34m[0m[0;34m[0m[0m

[0;31mAttributeError[0m: 'Sequential' object has no attribute 'fit_generator'
AttributeError: 'Sequential' object has no attribute 'fit_generator'
",AttributeError,'Sequential' object has no attribute 'fit_generator'
/junobench_env/NBspecific_19/NBspecific_19_extension.ipynb,2026-01-14T17:38:22.655985,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Extract zip file into folder containing image files
import py7zr

# with py7zr.SevenZipFile('/kaggle/input/cifar-10/test.7z', mode='r') as archive:
#     archive.extractall(path='/kaggle/working/test_data_folder')

# with py7zr.SevenZipFile('/kaggle/input/cifar-10/train.7z', mode='r') as archive:
#     archive.extractall(path='/kaggle/working/train_data_folder')
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mImportError[0m                               Traceback (most recent call last)
[0;32m<ipython-input-3-2c014ed901a8>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;31m# Extract zip file into folder containing image files[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0;32mimport[0m [0mpy7zr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      3[0m [0;34m[0m[0m
[1;32m      4[0m [0;31m# with py7zr.SevenZipFile('/kaggle/input/cifar-10/test.7z', mode='r') as archive:[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0;31m#     archive.extractall(path='/kaggle/working/test_data_folder')[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/py7zr/__init__.py[0m in [0;36m<module>[0;34m[0m
[1;32m     44[0m     [0mPRESET_EXTREME[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m     45[0m )
[0;32m---> 46[0;31m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0mpy7zr[0m [0;32mimport[0m [0mArchiveInfo[0m[0;34m,[0m [0mFileInfo[0m[0;34m,[0m [0mSevenZipFile[0m[0;34m,[0m [0mis_7zfile[0m[0;34m,[0m [0mpack_7zarchive[0m[0;34m,[0m [0munpack_7zarchive[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     47[0m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0mversion[0m [0;32mimport[0m [0m__version__[0m[0;34m[0m[0;34m[0m[0m
[1;32m     48[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/py7zr/py7zr.py[0m in [0;36m<module>[0;34m[0m
[1;32m     48[0m [0;32mimport[0m [0mmultivolumefile[0m[0;34m[0m[0;34m[0m[0m
[1;32m     49[0m [0;34m[0m[0m
[0;32m---> 50[0;31m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0marchiveinfo[0m [0;32mimport[0m [0mFolder[0m[0;34m,[0m [0mHeader[0m[0;34m,[0m [0mSignatureHeader[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     51[0m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0mcallbacks[0m [0;32mimport[0m [0mExtractCallback[0m[0;34m[0m[0;34m[0m[0m
[1;32m     52[0m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0mcompressor[0m [0;32mimport[0m [0mSupportedMethods[0m[0;34m,[0m [0mget_methods_names[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/py7zr/archiveinfo.py[0m in [0;36m<module>[0;34m[0m
[1;32m     34[0m [0;32mfrom[0m [0mtyping[0m [0;32mimport[0m [0mAny[0m[0;34m,[0m [0mBinaryIO[0m[0;34m,[0m [0mOptional[0m[0;34m,[0m [0mUnion[0m[0;34m[0m[0;34m[0m[0m
[1;32m     35[0m [0;34m[0m[0m
[0;32m---> 36[0;31m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0mcompressor[0m [0;32mimport[0m [0mSevenZipCompressor[0m[0;34m,[0m [0mSevenZipDecompressor[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     37[0m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0mexceptions[0m [0;32mimport[0m [0mBad7zFile[0m[0;34m[0m[0;34m[0m[0m
[1;32m     38[0m [0;32mfrom[0m [0mpy7zr[0m[0;34m.[0m[0mhelpers[0m [0;32mimport[0m [0mArchiveTimestamp[0m[0;34m,[0m [0mcalculate_crc32[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/py7zr/compressor.py[0m in [0;36m<module>[0;34m[0m
[1;32m     77[0m     [0;32mfrom[0m [0mcompression[0m [0;32mimport[0m [0mzstd[0m[0;34m[0m[0;34m[0m[0m
[1;32m     78[0m [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 79[0;31m     [0;32mfrom[0m [0mbackports[0m [0;32mimport[0m [0mzstd[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     80[0m [0;34m[0m[0m
[1;32m     81[0m [0;34m[0m[0m

[0;31mImportError[0m: cannot import name 'zstd' from 'backports' (/usr/local/lib/python3.10/dist-packages/setuptools/_vendor/backports/__init__.py)
ImportError: cannot import name 'zstd' from 'backports' (/usr/local/lib/python3.10/dist-packages/setuptools/_vendor/backports/__init__.py)
",ImportError,cannot import name 'zstd' from 'backports' (/usr/local/lib/python3.10/dist-packages/setuptools/_vendor/backports/__init__.py)
/junobench_env/NBspecific_10/NBspecific_10_extension.ipynb,2026-01-14T17:43:14.340190,CellExecutionError,"An error occurred while executing the following cell:
------------------
from keras.preprocessing.sequence import TimeseriesGenerator
import tensorflow as tf

train=TimeseriesGenerator(train,train,length=720,sampling_rate=1,batch_size=32)
test=TimeseriesGenerator(test,test,length=720,sampling_rate=1,batch_size=32)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mImportError[0m                               Traceback (most recent call last)
[0;32m<ipython-input-125-1ce8a1846ada>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0;32mfrom[0m [0mkeras[0m[0;34m.[0m[0mpreprocessing[0m[0;34m.[0m[0msequence[0m [0;32mimport[0m [0mTimeseriesGenerator[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0;32mimport[0m [0mtensorflow[0m [0;32mas[0m [0mtf[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0;34m[0m[0m
[1;32m      4[0m [0mtrain[0m[0;34m=[0m[0mTimeseriesGenerator[0m[0;34m([0m[0mtrain[0m[0;34m,[0m[0mtrain[0m[0;34m,[0m[0mlength[0m[0;34m=[0m[0;36m720[0m[0;34m,[0m[0msampling_rate[0m[0;34m=[0m[0;36m1[0m[0;34m,[0m[0mbatch_size[0m[0;34m=[0m[0;36m32[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0mtest[0m[0;34m=[0m[0mTimeseriesGenerator[0m[0;34m([0m[0mtest[0m[0;34m,[0m[0mtest[0m[0;34m,[0m[0mlength[0m[0;34m=[0m[0;36m720[0m[0;34m,[0m[0msampling_rate[0m[0;34m=[0m[0;36m1[0m[0;34m,[0m[0mbatch_size[0m[0;34m=[0m[0;36m32[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mImportError[0m: cannot import name 'TimeseriesGenerator' from 'keras.preprocessing.sequence' (/usr/local/lib/python3.10/dist-packages/keras/api/preprocessing/sequence/__init__.py)
ImportError: cannot import name 'TimeseriesGenerator' from 'keras.preprocessing.sequence' (/usr/local/lib/python3.10/dist-packages/keras/api/preprocessing/sequence/__init__.py)
",ImportError,cannot import name 'TimeseriesGenerator' from 'keras.preprocessing.sequence' (/usr/local/lib/python3.10/dist-packages/keras/api/preprocessing/sequence/__init__.py)
/junobench_env/tensorflow_4/tensorflow_4_extension.ipynb,2026-01-14T17:44:15.145286,CellExecutionError,"An error occurred while executing the following cell:
------------------
def find_files_in_folder(path, folder_name):
    folder_path = None
    for root, dirs, files in os.walk(path):
        if folder_name in dirs:
            folder_path = os.path.join(root, folder_name)
            break
    img1 = []
    if folder_path:
        files = os.listdir(folder_path)
        for file in files:
            folder_name = os.path.dirname(file)
            file_name = os.path.basename(file)
            img1.append(file_name)
        return img1
    else:
        return None
    

train_data_names = []
test_data_names = []

train_data = []
train_labels = []

real_images = []
forged_images = []

# for per in os.listdir(train_dir):
#     for data in glob.glob(train_dir+'/'+per+'/*.*'):
        
#         train_data_names.append(data)
        
#         if per[-1]=='g':
#             img = cv2.imread(data)
#             img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#             img = cv2.resize(img, (SIZE,SIZE))
#             forged_images.append([img])
# #             train_labels.append(np.array(1))
#         else:
#             img = cv2.imread(data)
#             img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#             img = cv2.resize(img, (SIZE,SIZE))
#             real_images.append([img])
#             train_labels.append(np.array(0))

real_images_train, forged_images_train = [], []
for per in os.listdir(train_dir):
    for data in glob.glob(train_dir+'/'+per+'/*.*'):
        img = cv2.imread(data)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, (SIZE, SIZE))
        if per[-1] == 'f':
            forged_images_train.append(img)
        else:
            real_images_train.append(img)

# train_data = np.array(train_data)/255.0
# train_labels = np.array(train_labels)
# print(""number of real_images"",len(real_images))

train_data = np.concatenate([real_images_train, forged_images_train])
train_labels = np.concatenate([np.zeros(len(real_images_train)), np.ones(len(forged_images_train))])
print(""number of real_images"",len(real_images))
#Test Data

test_data = []
test_labels = []
real_images_test, forged_images_test = [], []
# for per in os.listdir(test_dir):
#     for data in glob.glob(test_dir+'/'+per+'/*.*'):
#         test_data_names.append(data)
        
#         if per[-1]=='g':
#             img = cv2.imread(data)
#             img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#             img = cv2.resize(img, (SIZE,SIZE))
#             forged_images.append([img])
# #             test_labels.append(np.array(1))
#         else:
#             img = cv2.imread(data)
#             img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#             img = cv2.resize(img, (SIZE,SIZE))
#             real_images.append([img])
#             test_labels.append(np.array(0))

# Populate testing images
for per in os.listdir(test_dir):
    for data in glob.glob(test_dir+'/'+per+'/*.*'):
        img = cv2.imread(data)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, (SIZE, SIZE))
        if per[-1] == 'f':
            forged_images_test.append(img)
        else:
            real_images_test.append(img)

# test_data = np.array(test_data)/255.0
# test_labels = np.array(test_labels)
test_data = np.concatenate([real_images_test, forged_images_test])
test_labels = np.concatenate([np.zeros(len(real_images_test)), np.ones(len(forged_images_test))])


# # Load the real signature images

# for filename in os.listdir(train_dir):
#     for file in filename:
#         files_in_folder = find_files_in_folder(train_dir, file)
#         if ""-f"" in file:
#             forged_images.append(file)
#         else:
#             real_images.append(file)
#     image = cv2.imread(os.path.join(train_dir, filename))
#     if image is not None:
#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#         image = cv2.resize(image, (224, 224))
#         real_images.append(image)

# # Load the forged signature images

# for filename in os.listdir(test_dir):
#     for file in filename:
#         files_in_folder = find_files_in_folder(test_dir, file)
#         if ""-f"" in file:
#             forged_images.append(file)
#         else:
#             real_images.append(file)
#     image = cv2.imread(os.path.join(forged_path, filename))
#     if image is not None:
#         image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#         image = cv2.resize(image, (224, 224))
#         forged_images.append(image)

# Convert the images to numpy arrays
real_images = np.array(real_images)
forged_images = np.array(forged_images)

# Create the labels (0 for real, 1 for forged)
real_labels = np.zeros((real_images.shape[0], 1))
forged_labels = np.ones((forged_images.shape[0], 1))

print(""number of real_images"",len(real_images))
print(""number of forged_images"",len(forged_images))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-9-d6f46251b639>[0m in [0;36m<cell line: 61>[0;34m()[0m
[1;32m     59[0m [0;31m# print(""number of real_images"",len(real_images))[0m[0;34m[0m[0;34m[0m[0m
[1;32m     60[0m [0;34m[0m[0m
[0;32m---> 61[0;31m [0mtrain_data[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mconcatenate[0m[0;34m([0m[0;34m[[0m[0mreal_images_train[0m[0;34m,[0m [0mforged_images_train[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     62[0m [0mtrain_labels[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mconcatenate[0m[0;34m([0m[0;34m[[0m[0mnp[0m[0;34m.[0m[0mzeros[0m[0;34m([0m[0mlen[0m[0;34m([0m[0mreal_images_train[0m[0;34m)[0m[0;34m)[0m[0;34m,[0m [0mnp[0m[0;34m.[0m[0mones[0m[0;34m([0m[0mlen[0m[0;34m([0m[0mforged_images_train[0m[0;34m)[0m[0;34m)[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     63[0m [0mprint[0m[0;34m([0m[0;34m""number of real_images""[0m[0;34m,[0m[0mlen[0m[0;34m([0m[0mreal_images[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)
ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)
",ValueError,"all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)"
/junobench_env/torch_8/torch_8_extension.ipynb,2026-01-14T17:44:54.522637,CellExecutionError,"An error occurred while executing the following cell:
------------------
model_ft = model_ft.cuda()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
[0;32m<ipython-input-22-bc652b219146>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mmodel_ft[0m [0;34m=[0m [0mmodel_ft[0m[0;34m.[0m[0mcuda[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py[0m in [0;36mcuda[0;34m(self, device)[0m
[1;32m    914[0m             [0mModule[0m[0;34m:[0m [0mself[0m[0;34m[0m[0;34m[0m[0m
[1;32m    915[0m         """"""
[0;32m--> 916[0;31m         [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_apply[0m[0;34m([0m[0;32mlambda[0m [0mt[0m[0;34m:[0m [0mt[0m[0;34m.[0m[0mcuda[0m[0;34m([0m[0mdevice[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    917[0m [0;34m[0m[0m
[1;32m    918[0m     [0;32mdef[0m [0mipu[0m[0;34m([0m[0mself[0m[0;34m:[0m [0mT[0m[0;34m,[0m [0mdevice[0m[0;34m:[0m [0mOptional[0m[0;34m[[0m[0mUnion[0m[0;34m[[0m[0mint[0m[0;34m,[0m [0mdevice[0m[0;34m][0m[0;34m][0m [0;34m=[0m [0;32mNone[0m[0;34m)[0m [0;34m->[0m [0mT[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py[0m in [0;36m_apply[0;34m(self, fn, recurse)[0m
[1;32m    778[0m         [0;32mif[0m [0mrecurse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    779[0m             [0;32mfor[0m [0mmodule[0m [0;32min[0m [0mself[0m[0;34m.[0m[0mchildren[0m[0;34m([0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 780[0;31m                 [0mmodule[0m[0;34m.[0m[0m_apply[0m[0;34m([0m[0mfn[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    781[0m [0;34m[0m[0m
[1;32m    782[0m         [0;32mdef[0m [0mcompute_should_use_set_data[0m[0;34m([0m[0mtensor[0m[0;34m,[0m [0mtensor_applied[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py[0m in [0;36m_apply[0;34m(self, fn, recurse)[0m
[1;32m    803[0m             [0;31m# `with torch.no_grad():`[0m[0;34m[0m[0;34m[0m[0m
[1;32m    804[0m             [0;32mwith[0m [0mtorch[0m[0;34m.[0m[0mno_grad[0m[0;34m([0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 805[0;31m                 [0mparam_applied[0m [0;34m=[0m [0mfn[0m[0;34m([0m[0mparam[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    806[0m             [0mp_should_use_set_data[0m [0;34m=[0m [0mcompute_should_use_set_data[0m[0;34m([0m[0mparam[0m[0;34m,[0m [0mparam_applied[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    807[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py[0m in [0;36m<lambda>[0;34m(t)[0m
[1;32m    914[0m             [0mModule[0m[0;34m:[0m [0mself[0m[0;34m[0m[0;34m[0m[0m
[1;32m    915[0m         """"""
[0;32m--> 916[0;31m         [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_apply[0m[0;34m([0m[0;32mlambda[0m [0mt[0m[0;34m:[0m [0mt[0m[0;34m.[0m[0mcuda[0m[0;34m([0m[0mdevice[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    917[0m [0;34m[0m[0m
[1;32m    918[0m     [0;32mdef[0m [0mipu[0m[0;34m([0m[0mself[0m[0;34m:[0m [0mT[0m[0;34m,[0m [0mdevice[0m[0;34m:[0m [0mOptional[0m[0;34m[[0m[0mUnion[0m[0;34m[[0m[0mint[0m[0;34m,[0m [0mdevice[0m[0;34m][0m[0;34m][0m [0;34m=[0m [0;32mNone[0m[0;34m)[0m [0;34m->[0m [0mT[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py[0m in [0;36m_lazy_init[0;34m()[0m
[1;32m    312[0m         [0;32mif[0m [0;34m""CUDA_MODULE_LOADING""[0m [0;32mnot[0m [0;32min[0m [0mos[0m[0;34m.[0m[0menviron[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    313[0m             [0mos[0m[0;34m.[0m[0menviron[0m[0;34m[[0m[0;34m""CUDA_MODULE_LOADING""[0m[0;34m][0m [0;34m=[0m [0;34m""LAZY""[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 314[0;31m         [0mtorch[0m[0;34m.[0m[0m_C[0m[0;34m.[0m[0m_cuda_init[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    315[0m         [0;31m# Some of the queued calls may reentrantly call _lazy_init();[0m[0;34m[0m[0;34m[0m[0m
[1;32m    316[0m         [0;31m# we need to just return without initializing in that case.[0m[0;34m[0m[0;34m[0m[0m

[0;31mRuntimeError[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx
RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx
",RuntimeError,Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx
/junobench_env/NBspecific_16/NBspecific_16_extension.ipynb,2026-01-14T17:46:39.765527,CellExecutionError,"An error occurred while executing the following cell:
------------------
hidden_reps = model.layers[-4].output  
hidden_model = Model(inputs=model.input, outputs=hidden_reps)
hidden_reps = hidden_model.predict(x_train)
x_test_hidden_reps = hidden_model.predict(x_test)
num_features_from_cnn = hidden_reps.shape[1]
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-15-0603b0500161>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0mhidden_reps[0m [0;34m=[0m [0mmodel[0m[0;34m.[0m[0mlayers[0m[0;34m[[0m[0;34m-[0m[0;36m4[0m[0;34m][0m[0;34m.[0m[0moutput[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mhidden_model[0m [0;34m=[0m [0mModel[0m[0;34m([0m[0minputs[0m[0;34m=[0m[0mmodel[0m[0;34m.[0m[0minput[0m[0;34m,[0m [0moutputs[0m[0;34m=[0m[0mhidden_reps[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      3[0m [0mhidden_reps[0m [0;34m=[0m [0mhidden_model[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mx_train[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0mx_test_hidden_reps[0m [0;34m=[0m [0mhidden_model[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mx_test[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0mnum_features_from_cnn[0m [0;34m=[0m [0mhidden_reps[0m[0;34m.[0m[0mshape[0m[0;34m[[0m[0;36m1[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py[0m in [0;36minput[0;34m(self)[0m
[1;32m    252[0m             [0mInput[0m [0mtensor[0m [0;32mor[0m [0mlist[0m [0mof[0m [0minput[0m [0mtensors[0m[0;34m.[0m[0;34m[0m[0;34m[0m[0m
[1;32m    253[0m         """"""
[0;32m--> 254[0;31m         [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_get_node_attribute_at_index[0m[0;34m([0m[0;36m0[0m[0;34m,[0m [0;34m""input_tensors""[0m[0;34m,[0m [0;34m""input""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    255[0m [0;34m[0m[0m
[1;32m    256[0m     [0;34m@[0m[0mproperty[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py[0m in [0;36m_get_node_attribute_at_index[0;34m(self, node_index, attr, attr_name)[0m
[1;32m    283[0m         """"""
[1;32m    284[0m         [0;32mif[0m [0;32mnot[0m [0mself[0m[0;34m.[0m[0m_inbound_nodes[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 285[0;31m             raise ValueError(
[0m[1;32m    286[0m                 [0;34mf""The layer {self.name} has never been called ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    287[0m                 [0;34mf""and thus has no defined {attr_name}.""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: The layer sequential has never been called and thus has no defined input.
ValueError: The layer sequential has never been called and thus has no defined input.
",ValueError,The layer sequential has never been called and thus has no defined input.
/junobench_env/NBspecific_11/NBspecific_11_extension.ipynb,2026-01-14T17:48:36.862302,CellExecutionError,"An error occurred while executing the following cell:
------------------
import advbox
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-21-f50ab8c978b3>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0;32mimport[0m [0madvbox[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;31mModuleNotFoundError[0m: No module named 'advbox'
ModuleNotFoundError: No module named 'advbox'
",ModuleNotFoundError,No module named 'advbox'
/junobench_env/NBspecific_18/NBspecific_18_extension.ipynb,2026-01-14T17:48:43.714436,CellExecutionError,"An error occurred while executing the following cell:
------------------
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_test, y_pred)
mae
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-27-f778b0ff9eb9>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;32mfrom[0m [0msklearn[0m[0;34m.[0m[0mmetrics[0m [0;32mimport[0m [0mmean_absolute_error[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mmae[0m [0;34m=[0m [0mmean_absolute_error[0m[0;34m([0m[0my_test[0m[0;34m,[0m [0my_pred[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      3[0m [0mmae[0m[0;34m[0m[0;34m[0m[0m

[0;31mNameError[0m: name 'y_pred' is not defined
NameError: name 'y_pred' is not defined
",NameError,name 'y_pred' is not defined
/junobench_env/torch_6/torch_6_extension.ipynb,2026-01-14T17:49:13.703775,CellExecutionError,"An error occurred while executing the following cell:
------------------
#no longer a testing block
device = ""cuda"" if torch.cuda.is_available() else ""cpu""
mo, preprocess = clip.load(""ViT-L/14"", device=device)

# X_train=pd.DataFrame.from_dict(X_train)
cols=t.columns
# X_train=X_train.to_numpy()
# X_train=pd.DataFrame(X_train,columns=cols)
print(X_train.shape)
path=""data_small/train/train/""
image_pro_stack = torch.empty((1,3,224,224)).to(device)
image_array =[]
img_vectors=[]
imageS=[]
all_features=torch.empty((1,1536)).to(device)
for i in range(X_train[""image""].shape[0]):
    image_array.append((path+X_train['image'][i]))
image_array = np.array(image_array)
all_tensors=[]
batch=20
for i in range(0,image_array.shape[0],batch):
    if (i+batch)<image_array.shape[0]:
        img_dirs=image_array[i:i+batch] 
        for img in img_dirs:
            image = preprocess(Image.open(img)).unsqueeze(0).to(device)
            image_pro_stack=torch.cat((image_pro_stack,image)).to(device)
        temp=range(i,i+batch)
        # text = clip.tokenize(df.loc[temp,""question""]).to(device)
        text = clip.tokenize(X_train.loc[temp, ""question""]).to(device)
    elif ((i+batch)>= image_array.shape[0]) and (i < image_array.shape[0]):
        img_dirs=image_array[i:image_array.shape[0]]
        for img in img_dirs:
            image = preprocess(Image.open(img)).unsqueeze(0).to(device)
            image_pro_stack=torch.cat((image_pro_stack,image)).to(device)
        temp=range(i,image_array.shape[0])
        # text = clip.tokenize(df.loc[temp,""question""]).to(device)
        text = clip.tokenize(X_train.loc[temp, ""question""]).to(device)



    with torch.no_grad():
        text_features = mo.encode_text(text).to(device)
        image_pro_stack = image_pro_stack[1:image_pro_stack.shape[0]].to(device)
        img_features=mo.encode_image(image_pro_stack).to(device)
        #print(""size of image is"")
        #print(img_features.shape)
        #print(""size of text is "")
        #print(text_features.shape)
        #print(i)
        feature_vector=torch.cat((img_features,text_features),dim=1).to(device)
        all_features=torch.cat((all_features,feature_vector)).to(device)
    #print(feature_vector.shape)
    image_pro_stack = torch.empty((1,3,224,224)).to(device)

all_features = all_features[1:all_features.shape[0]].to(device)
print(""done"")
    

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key)[0m
[1;32m   3652[0m         [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3653[0;31m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3654[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.Int64HashTable.get_item[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.Int64HashTable.get_item[0;34m()[0m

[0;31mKeyError[0m: 11

The above exception was the direct cause of the following exception:

[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m<ipython-input-18-a26b24fd7234>[0m in [0;36m<cell line: 16>[0;34m()[0m
[1;32m     15[0m [0mall_features[0m[0;34m=[0m[0mtorch[0m[0;34m.[0m[0mempty[0m[0;34m([0m[0;34m([0m[0;36m1[0m[0;34m,[0m[0;36m1536[0m[0;34m)[0m[0;34m)[0m[0;34m.[0m[0mto[0m[0;34m([0m[0mdevice[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     16[0m [0;32mfor[0m [0mi[0m [0;32min[0m [0mrange[0m[0;34m([0m[0mX_train[0m[0;34m[[0m[0;34m""image""[0m[0;34m][0m[0;34m.[0m[0mshape[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 17[0;31m     [0mimage_array[0m[0;34m.[0m[0mappend[0m[0;34m([0m[0;34m([0m[0mpath[0m[0;34m+[0m[0mX_train[0m[0;34m[[0m[0;34m'image'[0m[0;34m][0m[0;34m[[0m[0mi[0m[0;34m][0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     18[0m [0mimage_array[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0marray[0m[0;34m([0m[0mimage_array[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     19[0m [0mall_tensors[0m[0;34m=[0m[0;34m[[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py[0m in [0;36m__getitem__[0;34m(self, key)[0m
[1;32m   1005[0m [0;34m[0m[0m
[1;32m   1006[0m         [0;32melif[0m [0mkey_is_scalar[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1007[0;31m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_get_value[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1008[0m [0;34m[0m[0m
[1;32m   1009[0m         [0;32mif[0m [0mis_hashable[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py[0m in [0;36m_get_value[0;34m(self, label, takeable)[0m
[1;32m   1114[0m [0;34m[0m[0m
[1;32m   1115[0m         [0;31m# Similar to Index.get_value, but we do not fall back to positional[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1116[0;31m         [0mloc[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mindex[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mlabel[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1117[0m [0;34m[0m[0m
[1;32m   1118[0m         [0;32mif[0m [0mis_integer[0m[0;34m([0m[0mloc[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key)[0m
[1;32m   3653[0m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3654[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3655[0;31m             [0;32mraise[0m [0mKeyError[0m[0;34m([0m[0mkey[0m[0;34m)[0m [0;32mfrom[0m [0merr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3656[0m         [0;32mexcept[0m [0mTypeError[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3657[0m             [0;31m# If we have a listlike key, _check_indexing_error will raise[0m[0;34m[0m[0;34m[0m[0m

[0;31mKeyError[0m: 11
KeyError: 11
",KeyError,11
/junobench_env/torch_1/torch_1_extension.ipynb,2026-01-14T17:49:45.935071,DeadKernelError,Kernel died,,
/junobench_env/matplotlib_4/matplotlib_4_extension.ipynb,2026-01-14T17:50:05.781048,CellExecutionError,"An error occurred while executing the following cell:
------------------
resnet_model = Sequential() 
pretrained_model= tf.keras.applications.ResNet50(include_top=False, input_shape=(200,200,3), pooling='avg',classes=58, weights='imagenet') 
for layer in pretrained_model.layers: layer.trainable=False 
resnet_model.add(pretrained_model) 
# Removed the redundant Flatten() layer 
resnet_model.add(Dense(512, activation='relu')) 
resnet_model.add(Dense(58, activation='softmax'))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-10-10fa72d7d6db>[0m in [0;36m<cell line: 6>[0;34m()[0m
[1;32m      4[0m [0mresnet_model[0m[0;34m.[0m[0madd[0m[0;34m([0m[0mpretrained_model[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0;31m# Removed the redundant Flatten() layer[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 6[0;31m [0mresnet_model[0m[0;34m.[0m[0madd[0m[0;34m([0m[0mDense[0m[0;34m([0m[0;36m512[0m[0;34m,[0m [0mactivation[0m[0;34m=[0m[0;34m'relu'[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      7[0m [0mresnet_model[0m[0;34m.[0m[0madd[0m[0;34m([0m[0mDense[0m[0;34m([0m[0;36m58[0m[0;34m,[0m [0mactivation[0m[0;34m=[0m[0;34m'softmax'[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py[0m in [0;36madd[0;34m(self, layer, rebuild)[0m
[1;32m     93[0m                 [0mlayer[0m [0;34m=[0m [0morigin_layer[0m[0;34m[0m[0;34m[0m[0m
[1;32m     94[0m         [0;32mif[0m [0;32mnot[0m [0misinstance[0m[0;34m([0m[0mlayer[0m[0;34m,[0m [0mLayer[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 95[0;31m             raise ValueError(
[0m[1;32m     96[0m                 [0;34m""Only instances of `keras.Layer` can be ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m     97[0m                 [0;34mf""added to a Sequential model. Received: {layer} ""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow.python.keras.layers.core.Dense object at 0x7fd2342b6c20> (of type <class 'tensorflow.python.keras.layers.core.Dense'>)
ValueError: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow.python.keras.layers.core.Dense object at 0x7fd2342b6c20> (of type <class 'tensorflow.python.keras.layers.core.Dense'>)
",ValueError,Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow.python.keras.layers.core.Dense object at 0x7fd2342b6c20> (of type <class 'tensorflow.python.keras.layers.core.Dense'>)
/junobench_env/matplotlib_3/matplotlib_3_extension.ipynb,2026-01-14T17:50:48.882606,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Plot the architecture of the best model
best_model = tuner.oracle.get_best_trials(1)[0].model
best_model.summary()

# Plot the summary of the hyperparameter search
plot_summary(tuner.oracle.get_best_trials(5), metric='val_accuracy')

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAttributeError[0m                            Traceback (most recent call last)
[0;32m<ipython-input-20-59374f519abd>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;31m# Plot the architecture of the best model[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mbest_model[0m [0;34m=[0m [0mtuner[0m[0;34m.[0m[0moracle[0m[0;34m.[0m[0mget_best_trials[0m[0;34m([0m[0;36m1[0m[0;34m)[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m.[0m[0mmodel[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      3[0m [0mbest_model[0m[0;34m.[0m[0msummary[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0;34m[0m[0m
[1;32m      5[0m [0;31m# Plot the summary of the hyperparameter search[0m[0;34m[0m[0;34m[0m[0m

[0;31mAttributeError[0m: 'Trial' object has no attribute 'model'
AttributeError: 'Trial' object has no attribute 'model'
",AttributeError,'Trial' object has no attribute 'model'
/junobench_env/pandas_14/pandas_14_extension.ipynb,2026-01-14T17:51:02.879453,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Correlación de las variables
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(15,15))
p=sns.heatmap(df.corr(), annot=True,cmap='RdYlGn',square=True)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-17-9b9aa4217059>[0m in [0;36m<cell line: 5>[0;34m()[0m
[1;32m      3[0m [0;32mimport[0m [0mseaborn[0m [0;32mas[0m [0msns[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0mplt[0m[0;34m.[0m[0mfigure[0m[0;34m([0m[0mfigsize[0m[0;34m=[0m[0;34m([0m[0;36m15[0m[0;34m,[0m[0;36m15[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 5[0;31m [0mp[0m[0;34m=[0m[0msns[0m[0;34m.[0m[0mheatmap[0m[0;34m([0m[0mdf[0m[0;34m.[0m[0mcorr[0m[0;34m([0m[0;34m)[0m[0;34m,[0m [0mannot[0m[0;34m=[0m[0;32mTrue[0m[0;34m,[0m[0mcmap[0m[0;34m=[0m[0;34m'RdYlGn'[0m[0;34m,[0m[0msquare[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36mcorr[0;34m(self, method, min_periods, numeric_only)[0m
[1;32m  10052[0m         [0mcols[0m [0;34m=[0m [0mdata[0m[0;34m.[0m[0mcolumns[0m[0;34m[0m[0;34m[0m[0m
[1;32m  10053[0m         [0midx[0m [0;34m=[0m [0mcols[0m[0;34m.[0m[0mcopy[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m> 10054[0;31m         [0mmat[0m [0;34m=[0m [0mdata[0m[0;34m.[0m[0mto_numpy[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mfloat[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mnp[0m[0;34m.[0m[0mnan[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m  10055[0m [0;34m[0m[0m
[1;32m  10056[0m         [0;32mif[0m [0mmethod[0m [0;34m==[0m [0;34m""pearson""[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36mto_numpy[0;34m(self, dtype, copy, na_value)[0m
[1;32m   1836[0m         [0;32mif[0m [0mdtype[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1837[0m             [0mdtype[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mdtype[0m[0;34m([0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1838[0;31m         [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_mgr[0m[0;34m.[0m[0mas_array[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0mcopy[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mna_value[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1839[0m         [0;32mif[0m [0mresult[0m[0;34m.[0m[0mdtype[0m [0;32mis[0m [0;32mnot[0m [0mdtype[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1840[0m             [0mresult[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0marray[0m[0;34m([0m[0mresult[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py[0m in [0;36mas_array[0;34m(self, dtype, copy, na_value)[0m
[1;32m   1730[0m                 [0marr[0m[0;34m.[0m[0mflags[0m[0;34m.[0m[0mwriteable[0m [0;34m=[0m [0;32mFalse[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1731[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1732[0;31m             [0marr[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_interleave[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mna_value[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1733[0m             [0;31m# The underlying data was copied within _interleave, so no need[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1734[0m             [0;31m# to further copy if copy=True or setting na_value[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py[0m in [0;36m_interleave[0;34m(self, dtype, na_value)[0m
[1;32m   1792[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1793[0m                 [0marr[0m [0;34m=[0m [0mblk[0m[0;34m.[0m[0mget_values[0m[0;34m([0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1794[0;31m             [0mresult[0m[0;34m[[0m[0mrl[0m[0;34m.[0m[0mindexer[0m[0;34m][0m [0;34m=[0m [0marr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1795[0m             [0mitemmask[0m[0;34m[[0m[0mrl[0m[0;34m.[0m[0mindexer[0m[0;34m][0m [0;34m=[0m [0;36m1[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1796[0m [0;34m[0m[0m

[0;31mValueError[0m: could not convert string to float: 'Europa'
ValueError: could not convert string to float: 'Europa'
",ValueError,could not convert string to float: 'Europa'
/junobench_env/pandas_15/pandas_15_extension.ipynb,2026-01-14T17:51:13.948907,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Identify categorical columns
categorical_cols_final = train.select_dtypes(include=['object']).columns.tolist()

# One-hot encode categorical features
train_encoded = pd.get_dummies(train, columns=categorical_cols_final, drop_first=True)
test_encoded = pd.get_dummies(test, columns=categorical_cols_final, drop_first=True)

# Align columns between train and test
common_cols = list(set(train_encoded.columns) & set(test_encoded.columns))
train_encoded = train_encoded[common_cols]
test_encoded = test_encoded[common_cols]

# Remove target from test features if present
if 'SalePrice' in test_encoded.columns:
    test_encoded = test_encoded.drop('SalePrice', axis=1)

# Define features and target
X = train_encoded.drop('SalePrice', axis=1)
y = train['SalePrice']  # Use original column

# Align test features
x_val = test_encoded[X.columns]

# Train-test split and model training
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)
pred_rf = model.predict(x_val)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m<ipython-input-26-111a3050521c>[0m in [0;36m<cell line: 18>[0;34m()[0m
[1;32m     16[0m [0;34m[0m[0m
[1;32m     17[0m [0;31m# Define features and target[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 18[0;31m [0mX[0m [0;34m=[0m [0mtrain_encoded[0m[0;34m.[0m[0mdrop[0m[0;34m([0m[0;34m'SalePrice'[0m[0;34m,[0m [0maxis[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     19[0m [0my[0m [0;34m=[0m [0mtrain[0m[0;34m[[0m[0;34m'SalePrice'[0m[0;34m][0m  [0;31m# Use original column[0m[0;34m[0m[0;34m[0m[0m
[1;32m     20[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36mdrop[0;34m(self, labels, axis, index, columns, level, inplace, errors)[0m
[1;32m   5256[0m                 [0mweight[0m  [0;36m1.0[0m     [0;36m0.8[0m[0;34m[0m[0;34m[0m[0m
[1;32m   5257[0m         """"""
[0;32m-> 5258[0;31m         return super().drop(
[0m[1;32m   5259[0m             [0mlabels[0m[0;34m=[0m[0mlabels[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m   5260[0m             [0maxis[0m[0;34m=[0m[0maxis[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py[0m in [0;36mdrop[0;34m(self, labels, axis, index, columns, level, inplace, errors)[0m
[1;32m   4547[0m         [0;32mfor[0m [0maxis[0m[0;34m,[0m [0mlabels[0m [0;32min[0m [0maxes[0m[0;34m.[0m[0mitems[0m[0;34m([0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   4548[0m             [0;32mif[0m [0mlabels[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 4549[0;31m                 [0mobj[0m [0;34m=[0m [0mobj[0m[0;34m.[0m[0m_drop_axis[0m[0;34m([0m[0mlabels[0m[0;34m,[0m [0maxis[0m[0;34m,[0m [0mlevel[0m[0;34m=[0m[0mlevel[0m[0;34m,[0m [0merrors[0m[0;34m=[0m[0merrors[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   4550[0m [0;34m[0m[0m
[1;32m   4551[0m         [0;32mif[0m [0minplace[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py[0m in [0;36m_drop_axis[0;34m(self, labels, axis, level, errors, only_slice)[0m
[1;32m   4589[0m                 [0mnew_axis[0m [0;34m=[0m [0maxis[0m[0;34m.[0m[0mdrop[0m[0;34m([0m[0mlabels[0m[0;34m,[0m [0mlevel[0m[0;34m=[0m[0mlevel[0m[0;34m,[0m [0merrors[0m[0;34m=[0m[0merrors[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   4590[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 4591[0;31m                 [0mnew_axis[0m [0;34m=[0m [0maxis[0m[0;34m.[0m[0mdrop[0m[0;34m([0m[0mlabels[0m[0;34m,[0m [0merrors[0m[0;34m=[0m[0merrors[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   4592[0m             [0mindexer[0m [0;34m=[0m [0maxis[0m[0;34m.[0m[0mget_indexer[0m[0;34m([0m[0mnew_axis[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   4593[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36mdrop[0;34m(self, labels, errors)[0m
[1;32m   6697[0m         [0;32mif[0m [0mmask[0m[0;34m.[0m[0many[0m[0;34m([0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   6698[0m             [0;32mif[0m [0merrors[0m [0;34m!=[0m [0;34m""ignore""[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 6699[0;31m                 [0;32mraise[0m [0mKeyError[0m[0;34m([0m[0;34mf""{list(labels[mask])} not found in axis""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   6700[0m             [0mindexer[0m [0;34m=[0m [0mindexer[0m[0;34m[[0m[0;34m~[0m[0mmask[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[1;32m   6701[0m         [0;32mreturn[0m [0mself[0m[0;34m.[0m[0mdelete[0m[0;34m([0m[0mindexer[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mKeyError[0m: ""['SalePrice'] not found in axis""
KeyError: ""['SalePrice'] not found in axis""
",KeyError,['SalePrice'] not found in axis
/junobench_env/pandas_12/pandas_12_extension.ipynb,2026-01-14T17:51:31.117010,CellExecutionError,"An error occurred while executing the following cell:
------------------
plt.figure(figsize = (16,8))
for i,x in enumerate(num_cols):
  plt.title(""Boxplot for {}"".format(x))
  plt.subplot(2,4,i+1)
  sns.boxplot(df[x])
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-10-ddd84ef43344>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      2[0m [0;32mfor[0m [0mi[0m[0;34m,[0m[0mx[0m [0;32min[0m [0menumerate[0m[0;34m([0m[0mnum_cols[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m   [0mplt[0m[0;34m.[0m[0mtitle[0m[0;34m([0m[0;34m""Boxplot for {}""[0m[0;34m.[0m[0mformat[0m[0;34m([0m[0mx[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m   [0mplt[0m[0;34m.[0m[0msubplot[0m[0;34m([0m[0;36m2[0m[0;34m,[0m[0;36m4[0m[0;34m,[0m[0mi[0m[0;34m+[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m   [0msns[0m[0;34m.[0m[0mboxplot[0m[0;34m([0m[0mdf[0m[0;34m[[0m[0mx[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py[0m in [0;36msubplot[0;34m(*args, **kwargs)[0m
[1;32m   1321[0m [0;34m[0m[0m
[1;32m   1322[0m     [0;31m# First, search for an existing subplot with a matching spec.[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1323[0;31m     [0mkey[0m [0;34m=[0m [0mSubplotSpec[0m[0;34m.[0m[0m_from_subplot_args[0m[0;34m([0m[0mfig[0m[0;34m,[0m [0margs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1324[0m [0;34m[0m[0m
[1;32m   1325[0m     [0;32mfor[0m [0max[0m [0;32min[0m [0mfig[0m[0;34m.[0m[0maxes[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py[0m in [0;36m_from_subplot_args[0;34m(figure, args)[0m
[1;32m    598[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    599[0m             [0;32mif[0m [0;32mnot[0m [0misinstance[0m[0;34m([0m[0mnum[0m[0;34m,[0m [0mIntegral[0m[0;34m)[0m [0;32mor[0m [0mnum[0m [0;34m<[0m [0;36m1[0m [0;32mor[0m [0mnum[0m [0;34m>[0m [0mrows[0m[0;34m*[0m[0mcols[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 600[0;31m                 raise ValueError(
[0m[1;32m    601[0m                     [0;34mf""num must be an integer with 1 <= num <= {rows*cols}, ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    602[0m                     [0;34mf""not {num!r}""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: num must be an integer with 1 <= num <= 8, not 9
ValueError: num must be an integer with 1 <= num <= 8, not 9
",ValueError,"num must be an integer with 1 <= num <= 8, not 9"
/junobench_env/matplotlib_2/matplotlib_2_extension.ipynb,2026-01-14T17:53:42.746902,DeadKernelError,Kernel died,,
/junobench_env/pandas_2/pandas_2_extension.ipynb,2026-01-14T17:53:55.317348,CellExecutionError,"An error occurred while executing the following cell:
------------------
train_df.corr()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-12-a7a80d20a44e>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mtrain_df[0m[0;34m.[0m[0mcorr[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36mcorr[0;34m(self, method, min_periods, numeric_only)[0m
[1;32m  10052[0m         [0mcols[0m [0;34m=[0m [0mdata[0m[0;34m.[0m[0mcolumns[0m[0;34m[0m[0;34m[0m[0m
[1;32m  10053[0m         [0midx[0m [0;34m=[0m [0mcols[0m[0;34m.[0m[0mcopy[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m> 10054[0;31m         [0mmat[0m [0;34m=[0m [0mdata[0m[0;34m.[0m[0mto_numpy[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mfloat[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mnp[0m[0;34m.[0m[0mnan[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m  10055[0m [0;34m[0m[0m
[1;32m  10056[0m         [0;32mif[0m [0mmethod[0m [0;34m==[0m [0;34m""pearson""[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36mto_numpy[0;34m(self, dtype, copy, na_value)[0m
[1;32m   1836[0m         [0;32mif[0m [0mdtype[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1837[0m             [0mdtype[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mdtype[0m[0;34m([0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1838[0;31m         [0mresult[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_mgr[0m[0;34m.[0m[0mas_array[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0mcopy[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mna_value[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1839[0m         [0;32mif[0m [0mresult[0m[0;34m.[0m[0mdtype[0m [0;32mis[0m [0;32mnot[0m [0mdtype[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1840[0m             [0mresult[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0marray[0m[0;34m([0m[0mresult[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py[0m in [0;36mas_array[0;34m(self, dtype, copy, na_value)[0m
[1;32m   1730[0m                 [0marr[0m[0;34m.[0m[0mflags[0m[0;34m.[0m[0mwriteable[0m [0;34m=[0m [0;32mFalse[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1731[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1732[0;31m             [0marr[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_interleave[0m[0;34m([0m[0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mna_value[0m[0;34m=[0m[0mna_value[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1733[0m             [0;31m# The underlying data was copied within _interleave, so no need[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1734[0m             [0;31m# to further copy if copy=True or setting na_value[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py[0m in [0;36m_interleave[0;34m(self, dtype, na_value)[0m
[1;32m   1792[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1793[0m                 [0marr[0m [0;34m=[0m [0mblk[0m[0;34m.[0m[0mget_values[0m[0;34m([0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1794[0;31m             [0mresult[0m[0;34m[[0m[0mrl[0m[0;34m.[0m[0mindexer[0m[0;34m][0m [0;34m=[0m [0marr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1795[0m             [0mitemmask[0m[0;34m[[0m[0mrl[0m[0;34m.[0m[0mindexer[0m[0;34m][0m [0;34m=[0m [0;36m1[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1796[0m [0;34m[0m[0m

[0;31mValueError[0m: could not convert string to float: 'RL'
ValueError: could not convert string to float: 'RL'
",ValueError,could not convert string to float: 'RL'
/junobench_env/pandas_5/pandas_5_extension.ipynb,2026-01-14T17:53:59.382128,CellExecutionError,"An error occurred while executing the following cell:
------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the ""../input/"" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))

# Any results you write to the current directory are saved as output.
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mCalledProcessError[0m                        Traceback (most recent call last)
[0;32m<ipython-input-1-695361520314>[0m in [0;36m<cell line: 12>[0;34m()[0m
[1;32m     10[0m [0;34m[0m[0m
[1;32m     11[0m [0;32mfrom[0m [0msubprocess[0m [0;32mimport[0m [0mcheck_output[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 12[0;31m [0mprint[0m[0;34m([0m[0mcheck_output[0m[0;34m([0m[0;34m[[0m[0;34m""ls""[0m[0;34m,[0m [0;34m""../input""[0m[0;34m][0m[0;34m)[0m[0;34m.[0m[0mdecode[0m[0;34m([0m[0;34m""utf8""[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     13[0m [0;34m[0m[0m
[1;32m     14[0m [0;31m# Any results you write to the current directory are saved as output.[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/lib/python3.10/subprocess.py[0m in [0;36mcheck_output[0;34m(timeout, *popenargs, **kwargs)[0m
[1;32m    419[0m         [0mkwargs[0m[0;34m[[0m[0;34m'input'[0m[0;34m][0m [0;34m=[0m [0mempty[0m[0;34m[0m[0;34m[0m[0m
[1;32m    420[0m [0;34m[0m[0m
[0;32m--> 421[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
[0m[1;32m    422[0m                **kwargs).stdout
[1;32m    423[0m [0;34m[0m[0m

[0;32m/usr/lib/python3.10/subprocess.py[0m in [0;36mrun[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)[0m
[1;32m    524[0m         [0mretcode[0m [0;34m=[0m [0mprocess[0m[0;34m.[0m[0mpoll[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    525[0m         [0;32mif[0m [0mcheck[0m [0;32mand[0m [0mretcode[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 526[0;31m             raise CalledProcessError(retcode, process.args,
[0m[1;32m    527[0m                                      output=stdout, stderr=stderr)
[1;32m    528[0m     [0;32mreturn[0m [0mCompletedProcess[0m[0;34m([0m[0mprocess[0m[0;34m.[0m[0margs[0m[0;34m,[0m [0mretcode[0m[0;34m,[0m [0mstdout[0m[0;34m,[0m [0mstderr[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mCalledProcessError[0m: Command '['ls', '../input']' returned non-zero exit status 2.
CalledProcessError: Command '['ls', '../input']' returned non-zero exit status 2.
",CalledProcessError,"Command '['ls', '../input']' returned non-zero exit status 2."
/junobench_env/sklearn_13/sklearn_13_extension.ipynb,2026-01-14T17:54:04.288638,CellExecutionError,"An error occurred while executing the following cell:
------------------
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error

# linear_reg = LinearRegression() 
# linear_reg.fit(x,y)

df_encoded = pd.get_dummies(df, columns=['workclass'], drop_first=True)

# Define features and target
X = df_encoded.drop('Salary', axis=1).values
y = df_encoded['Salary'].values.reshape(-1, 1)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Fit Linear Regression model
linear_reg = LinearRegression()
linear_reg.fit(X_train, y_train)

print(""Model fitted successfully!"")
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-9-375f657ccb3d>[0m in [0;36m<cell line: 21>[0;34m()[0m
[1;32m     19[0m [0;31m# Fit Linear Regression model[0m[0;34m[0m[0;34m[0m[0m
[1;32m     20[0m [0mlinear_reg[0m [0;34m=[0m [0mLinearRegression[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 21[0;31m [0mlinear_reg[0m[0;34m.[0m[0mfit[0m[0;34m([0m[0mX_train[0m[0;34m,[0m [0my_train[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     22[0m [0;34m[0m[0m
[1;32m     23[0m [0mprint[0m[0;34m([0m[0;34m""Model fitted successfully!""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py[0m in [0;36mfit[0;34m(self, X, y, sample_weight)[0m
[1;32m    646[0m         [0maccept_sparse[0m [0;34m=[0m [0;32mFalse[0m [0;32mif[0m [0mself[0m[0;34m.[0m[0mpositive[0m [0;32melse[0m [0;34m[[0m[0;34m""csr""[0m[0;34m,[0m [0;34m""csc""[0m[0;34m,[0m [0;34m""coo""[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[1;32m    647[0m [0;34m[0m[0m
[0;32m--> 648[0;31m         X, y = self._validate_data(
[0m[1;32m    649[0m             [0mX[0m[0;34m,[0m [0my[0m[0;34m,[0m [0maccept_sparse[0m[0;34m=[0m[0maccept_sparse[0m[0;34m,[0m [0my_numeric[0m[0;34m=[0m[0;32mTrue[0m[0;34m,[0m [0mmulti_output[0m[0;34m=[0m[0;32mTrue[0m[0;34m[0m[0;34m[0m[0m
[1;32m    650[0m         )

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py[0m in [0;36m_validate_data[0;34m(self, X, y, reset, validate_separately, **check_params)[0m
[1;32m    582[0m                 [0my[0m [0;34m=[0m [0mcheck_array[0m[0;34m([0m[0my[0m[0;34m,[0m [0minput_name[0m[0;34m=[0m[0;34m""y""[0m[0;34m,[0m [0;34m**[0m[0mcheck_y_params[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    583[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 584[0;31m                 [0mX[0m[0;34m,[0m [0my[0m [0;34m=[0m [0mcheck_X_y[0m[0;34m([0m[0mX[0m[0;34m,[0m [0my[0m[0;34m,[0m [0;34m**[0m[0mcheck_params[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    585[0m             [0mout[0m [0;34m=[0m [0mX[0m[0;34m,[0m [0my[0m[0;34m[0m[0;34m[0m[0m
[1;32m    586[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py[0m in [0;36mcheck_X_y[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)[0m
[1;32m   1104[0m         )
[1;32m   1105[0m [0;34m[0m[0m
[0;32m-> 1106[0;31m     X = check_array(
[0m[1;32m   1107[0m         [0mX[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1108[0m         [0maccept_sparse[0m[0;34m=[0m[0maccept_sparse[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py[0m in [0;36mcheck_array[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)[0m
[1;32m    877[0m                     [0marray[0m [0;34m=[0m [0mxp[0m[0;34m.[0m[0mastype[0m[0;34m([0m[0marray[0m[0;34m,[0m [0mdtype[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    878[0m                 [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 879[0;31m                     [0marray[0m [0;34m=[0m [0m_asarray_with_order[0m[0;34m([0m[0marray[0m[0;34m,[0m [0morder[0m[0;34m=[0m[0morder[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m,[0m [0mxp[0m[0;34m=[0m[0mxp[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    880[0m             [0;32mexcept[0m [0mComplexWarning[0m [0;32mas[0m [0mcomplex_warning[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    881[0m                 raise ValueError(

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py[0m in [0;36m_asarray_with_order[0;34m(array, dtype, order, copy, xp)[0m
[1;32m    183[0m     [0;32mif[0m [0mxp[0m[0;34m.[0m[0m__name__[0m [0;32min[0m [0;34m{[0m[0;34m""numpy""[0m[0;34m,[0m [0;34m""numpy.array_api""[0m[0;34m}[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    184[0m         [0;31m# Use NumPy API to support order[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 185[0;31m         [0marray[0m [0;34m=[0m [0mnumpy[0m[0;34m.[0m[0masarray[0m[0;34m([0m[0marray[0m[0;34m,[0m [0morder[0m[0;34m=[0m[0morder[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    186[0m         [0;32mreturn[0m [0mxp[0m[0;34m.[0m[0masarray[0m[0;34m([0m[0marray[0m[0;34m,[0m [0mcopy[0m[0;34m=[0m[0mcopy[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    187[0m     [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: could not convert string to float: ' HS-grad'
ValueError: could not convert string to float: ' HS-grad'
",ValueError,could not convert string to float: ' HS-grad'
/junobench_env/torch_14/torch_14_extension.ipynb,2026-01-14T17:54:17.665652,CellExecutionError,"An error occurred while executing the following cell:
------------------
# import torch
# import torchvision
# from torchvision.models.detection import fasterrcnn_resnet50_fpn
# from torchvision.models.detection.rpn import AnchorGenerator
# from torchvision.transforms import transforms
# from torch.utils.data import DataLoader

# # 定义转换
# transform = transforms.Compose([
#     transforms.ToTensor(), 
#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
# ])

# # 加载数据集
# trainset = torchvision.datasets.VOCDetection(root=""data_small"", year='2012', image_set='train', download=False, transform=transform)
# testset = torchvision.datasets.VOCDetection(root=""data_small"", year='2012', image_set='val', download=False, transform=transform)

# # 创建数据加载器
# trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)
# testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)

import torch
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights

from torchvision.models.detection.rpn import AnchorGenerator
from torchvision.transforms import transforms
from torch.utils.data import DataLoader

# Define a custom collate function for object detection
def collate_fn(batch):
    images = [item[0] for item in batch]
    targets = [item[1] for item in batch]
    return images, targets

# Define transforms
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Load datasets
trainset = torchvision.datasets.VOCDetection(
    root=""data_small"",
    year='2012',
    image_set='train',
    download=False,
    transform=transform
)

testset = torchvision.datasets.VOCDetection(
    root=""data_small"",
    year='2012',
    image_set='val',
    download=False,
    transform=transform
)

# Create data loaders with the custom collate_fn
trainloader = DataLoader(
    trainset,
    batch_size=4,
    shuffle=True,
    num_workers=2,
    collate_fn=collate_fn
)

testloader = DataLoader(
    testset,
    batch_size=4,
    shuffle=False,
    num_workers=2,
    collate_fn=collate_fn
)

# 加载预训练的模型
# model = fasterrcnn_resnet50_fpn(pretrained=True)
model =fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)
# 替换分类器
num_classes = 21  # 20 类 + 背景
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)

# 定义优化器
optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)

# 训练模型
num_epochs = 10
for epoch in range(num_epochs):
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = sum(loss for loss in outputs.values())
        loss.backward()
        optimizer.step()

        if i % 2000 == 1999:    # 每 2000 mini-batches 打印一次
            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, loss.item()))

print('Finished Training')

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAssertionError[0m                            Traceback (most recent call last)
[0;32m<ipython-input-2-058b7c1bd20c>[0m in [0;36m<cell line: 91>[0;34m()[0m
[1;32m     93[0m         [0minputs[0m[0;34m,[0m [0mlabels[0m [0;34m=[0m [0mdata[0m[0;34m[0m[0;34m[0m[0m
[1;32m     94[0m         [0moptimizer[0m[0;34m.[0m[0mzero_grad[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 95[0;31m         [0moutputs[0m [0;34m=[0m [0mmodel[0m[0;34m([0m[0minputs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     96[0m         [0mloss[0m [0;34m=[0m [0msum[0m[0;34m([0m[0mloss[0m [0;32mfor[0m [0mloss[0m [0;32min[0m [0moutputs[0m[0;34m.[0m[0mvalues[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     97[0m         [0mloss[0m[0;34m.[0m[0mbackward[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py[0m in [0;36m_wrapped_call_impl[0;34m(self, *args, **kwargs)[0m
[1;32m   1551[0m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_compiled_call_impl[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m  [0;31m# type: ignore[misc][0m[0;34m[0m[0;34m[0m[0m
[1;32m   1552[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1553[0;31m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_call_impl[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1554[0m [0;34m[0m[0m
[1;32m   1555[0m     [0;32mdef[0m [0m_call_impl[0m[0;34m([0m[0mself[0m[0;34m,[0m [0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py[0m in [0;36m_call_impl[0;34m(self, *args, **kwargs)[0m
[1;32m   1560[0m                 [0;32mor[0m [0m_global_backward_pre_hooks[0m [0;32mor[0m [0m_global_backward_hooks[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1561[0m                 or _global_forward_hooks or _global_forward_pre_hooks):
[0;32m-> 1562[0;31m             [0;32mreturn[0m [0mforward_call[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1563[0m [0;34m[0m[0m
[1;32m   1564[0m         [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/generalized_rcnn.py[0m in [0;36mforward[0;34m(self, images, targets)[0m
[1;32m     60[0m         [0;32mif[0m [0mself[0m[0;34m.[0m[0mtraining[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     61[0m             [0;32mif[0m [0mtargets[0m [0;32mis[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 62[0;31m                 [0mtorch[0m[0;34m.[0m[0m_assert[0m[0;34m([0m[0;32mFalse[0m[0;34m,[0m [0;34m""targets should not be none when in training mode""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     63[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     64[0m                 [0;32mfor[0m [0mtarget[0m [0;32min[0m [0mtargets[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py[0m in [0;36m_assert[0;34m(condition, message)[0m
[1;32m   1775[0m     [0;32mif[0m [0mtype[0m[0;34m([0m[0mcondition[0m[0;34m)[0m [0;32mis[0m [0;32mnot[0m [0mtorch[0m[0;34m.[0m[0mTensor[0m [0;32mand[0m [0mhas_torch_function[0m[0;34m([0m[0;34m([0m[0mcondition[0m[0;34m,[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1776[0m         [0;32mreturn[0m [0mhandle_torch_function[0m[0;34m([0m[0m_assert[0m[0;34m,[0m [0;34m([0m[0mcondition[0m[0;34m,[0m[0;34m)[0m[0;34m,[0m [0mcondition[0m[0;34m,[0m [0mmessage[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1777[0;31m     [0;32massert[0m [0mcondition[0m[0;34m,[0m [0mmessage[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1778[0m [0;34m[0m[0m
[1;32m   1779[0m [0;31m################################################################################[0m[0;34m[0m[0;34m[0m[0m

[0;31mAssertionError[0m: targets should not be none when in training mode
AssertionError: targets should not be none when in training mode
",AssertionError,targets should not be none when in training mode
/junobench_env/sklearn_12/sklearn_12_extension.ipynb,2026-01-14T17:54:24.033555,CellExecutionError,"An error occurred while executing the following cell:
------------------
plt.figure(figsize=(8,8))
Series_feat_imp.sort_values(ascending=True).plot.barh()
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.show()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-13-6eabcdf360b5>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mplt[0m[0;34m.[0m[0mfigure[0m[0;34m([0m[0mfigsize[0m[0;34m=[0m[0;34m([0m[0;36m8[0m[0;34m,[0m[0;36m8[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0mSeries_feat_imp[0m[0;34m.[0m[0msort_values[0m[0;34m([0m[0mascending[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m.[0m[0mplot[0m[0;34m.[0m[0mbarh[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0mplt[0m[0;34m.[0m[0mxlabel[0m[0;34m([0m[0;34m'Feature Importance'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0mplt[0m[0;34m.[0m[0mylabel[0m[0;34m([0m[0;34m'Feature'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0mplt[0m[0;34m.[0m[0mshow[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mNameError[0m: name 'plt' is not defined
NameError: name 'plt' is not defined
",NameError,name 'plt' is not defined
/junobench_env/pandas_4/pandas_4_extension.ipynb,2026-01-14T17:54:43.360465,CellExecutionError,"An error occurred while executing the following cell:
------------------
# barplot class distribution of train, val and test
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

def setup_axe(axe,df,title):
    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)
    axe.set_xticklabels(emotion_labels)
    axe.set_xlabel(""Emotions"")
    axe.set_ylabel(""Number"")
    axe.set_title(title)
    
    # set individual bar lables using above list
    for i in axe.patches:
        # get_x pulls left or right; get_height pushes up or down
        axe.text(i.get_x()-.05, i.get_height()+120, \
                str(round((i.get_height()), 2)), fontsize=14, color='dimgrey',
                    rotation=0)

   
fig, axes = plt.subplots(1,3, figsize=(20,8), sharey=True)
setup_axe(axes[0],data_train,'train')
setup_axe(axes[1],data_val,'validation')
setup_axe(axes[2],data_test,'test')
plt.show()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-12-dc6ea77e11f3>[0m in [0;36m<cell line: 20>[0;34m()[0m
[1;32m     18[0m [0;34m[0m[0m
[1;32m     19[0m [0mfig[0m[0;34m,[0m [0maxes[0m [0;34m=[0m [0mplt[0m[0;34m.[0m[0msubplots[0m[0;34m([0m[0;36m1[0m[0;34m,[0m[0;36m3[0m[0;34m,[0m [0mfigsize[0m[0;34m=[0m[0;34m([0m[0;36m20[0m[0;34m,[0m[0;36m8[0m[0;34m)[0m[0;34m,[0m [0msharey[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 20[0;31m [0msetup_axe[0m[0;34m([0m[0maxes[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m,[0m[0mdata_train[0m[0;34m,[0m[0;34m'train'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     21[0m [0msetup_axe[0m[0;34m([0m[0maxes[0m[0;34m[[0m[0;36m1[0m[0;34m][0m[0;34m,[0m[0mdata_val[0m[0;34m,[0m[0;34m'validation'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     22[0m [0msetup_axe[0m[0;34m([0m[0maxes[0m[0;34m[[0m[0;36m2[0m[0;34m][0m[0;34m,[0m[0mdata_test[0m[0;34m,[0m[0;34m'test'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m<ipython-input-12-dc6ea77e11f3>[0m in [0;36msetup_axe[0;34m(axe, df, title)[0m
[1;32m      4[0m [0;32mdef[0m [0msetup_axe[0m[0;34m([0m[0maxe[0m[0;34m,[0m[0mdf[0m[0;34m,[0m[0mtitle[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m     [0mdf[0m[0;34m[[0m[0;34m'emotion'[0m[0;34m][0m[0;34m.[0m[0mvalue_counts[0m[0;34m([0m[0msort[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m.[0m[0mplot[0m[0;34m([0m[0max[0m[0;34m=[0m[0maxe[0m[0;34m,[0m [0mkind[0m[0;34m=[0m[0;34m'bar'[0m[0;34m,[0m [0mrot[0m[0;34m=[0m[0;36m0[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 6[0;31m     [0maxe[0m[0;34m.[0m[0mset_xticklabels[0m[0;34m([0m[0memotion_labels[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      7[0m     [0maxe[0m[0;34m.[0m[0mset_xlabel[0m[0;34m([0m[0;34m""Emotions""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      8[0m     [0maxe[0m[0;34m.[0m[0mset_ylabel[0m[0;34m([0m[0;34m""Number""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py[0m in [0;36mwrapper[0;34m(self, *args, **kwargs)[0m
[1;32m     72[0m [0;34m[0m[0m
[1;32m     73[0m         [0;32mdef[0m [0mwrapper[0m[0;34m([0m[0mself[0m[0;34m,[0m [0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 74[0;31m             [0;32mreturn[0m [0mget_method[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     75[0m [0;34m[0m[0m
[1;32m     76[0m         [0mwrapper[0m[0;34m.[0m[0m__module__[0m [0;34m=[0m [0mowner[0m[0;34m.[0m[0m__module__[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py[0m in [0;36mwrapper[0;34m(*args, **kwargs)[0m
[1;32m    295[0m                 f""for the old name will be dropped %(removal)s."")
[1;32m    296[0m             [0mkwargs[0m[0;34m[[0m[0mnew[0m[0;34m][0m [0;34m=[0m [0mkwargs[0m[0;34m.[0m[0mpop[0m[0;34m([0m[0mold[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 297[0;31m         [0;32mreturn[0m [0mfunc[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    298[0m [0;34m[0m[0m
[1;32m    299[0m     [0;31m# wrapper() must keep the same documented signature as func(): if we[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py[0m in [0;36mset_ticklabels[0;34m(self, labels, minor, fontdict, **kwargs)[0m
[1;32m   1967[0m             [0;31m# remove all tick labels, so only error for > 0 labels[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1968[0m             [0;32mif[0m [0mlen[0m[0;34m([0m[0mlocator[0m[0;34m.[0m[0mlocs[0m[0;34m)[0m [0;34m!=[0m [0mlen[0m[0;34m([0m[0mlabels[0m[0;34m)[0m [0;32mand[0m [0mlen[0m[0;34m([0m[0mlabels[0m[0;34m)[0m [0;34m!=[0m [0;36m0[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1969[0;31m                 raise ValueError(
[0m[1;32m   1970[0m                     [0;34m""The number of FixedLocator locations""[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1971[0m                     [0;34mf"" ({len(locator.locs)}), usually from a call to""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of labels (7).
ValueError: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of labels (7).
",ValueError,"The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of labels (7)."
/junobench_env/pandas_3/pandas_3_extension.ipynb,2026-01-14T17:54:49.649873,CellExecutionError,"An error occurred while executing the following cell:
------------------
train = procData(train, name_count_series, rescuer_count_series, RescuerID_encoder)
test = procData(test, name_count_series, rescuer_count_series, RescuerID_encoder)
data = train.copy()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py[0m in [0;36m_encode[0;34m(values, uniques, check_unknown)[0m
[1;32m    223[0m         [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 224[0;31m             [0;32mreturn[0m [0m_map_to_integer[0m[0;34m([0m[0mvalues[0m[0;34m,[0m [0muniques[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    225[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py[0m in [0;36m_map_to_integer[0;34m(values, uniques)[0m
[1;32m    163[0m     [0mtable[0m [0;34m=[0m [0m_nandict[0m[0;34m([0m[0;34m{[0m[0mval[0m[0;34m:[0m [0mi[0m [0;32mfor[0m [0mi[0m[0;34m,[0m [0mval[0m [0;32min[0m [0menumerate[0m[0;34m([0m[0muniques[0m[0;34m)[0m[0;34m}[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 164[0;31m     [0;32mreturn[0m [0mnp[0m[0;34m.[0m[0marray[0m[0;34m([0m[0;34m[[0m[0mtable[0m[0;34m[[0m[0mv[0m[0;34m][0m [0;32mfor[0m [0mv[0m [0;32min[0m [0mvalues[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    165[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py[0m in [0;36m<listcomp>[0;34m(.0)[0m
[1;32m    163[0m     [0mtable[0m [0;34m=[0m [0m_nandict[0m[0;34m([0m[0;34m{[0m[0mval[0m[0;34m:[0m [0mi[0m [0;32mfor[0m [0mi[0m[0;34m,[0m [0mval[0m [0;32min[0m [0menumerate[0m[0;34m([0m[0muniques[0m[0;34m)[0m[0;34m}[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 164[0;31m     [0;32mreturn[0m [0mnp[0m[0;34m.[0m[0marray[0m[0;34m([0m[0;34m[[0m[0mtable[0m[0;34m[[0m[0mv[0m[0;34m][0m [0;32mfor[0m [0mv[0m [0;32min[0m [0mvalues[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    165[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py[0m in [0;36m__missing__[0;34m(self, key)[0m
[1;32m    157[0m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0mnan_value[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 158[0;31m         [0;32mraise[0m [0mKeyError[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    159[0m [0;34m[0m[0m

[0;31mKeyError[0m: '2ece3b2573dcdcebd774e635dca15fd9'

During handling of the above exception, another exception occurred:

[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-4-ea39d1f24022>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0mtrain[0m [0;34m=[0m [0mprocData[0m[0;34m([0m[0mtrain[0m[0;34m,[0m [0mname_count_series[0m[0;34m,[0m [0mrescuer_count_series[0m[0;34m,[0m [0mRescuerID_encoder[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mtest[0m [0;34m=[0m [0mprocData[0m[0;34m([0m[0mtest[0m[0;34m,[0m [0mname_count_series[0m[0;34m,[0m [0mrescuer_count_series[0m[0;34m,[0m [0mRescuerID_encoder[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      3[0m [0mdata[0m [0;34m=[0m [0mtrain[0m[0;34m.[0m[0mcopy[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m<ipython-input-3-a3b1bbb10725>[0m in [0;36mprocData[0;34m(data, name_count_series, rescuer_count_series, RescuerID_encoder)[0m
[1;32m     30[0m [0;34m[0m[0m
[1;32m     31[0m     [0;31m# Encode RescuerID[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 32[0;31m     [0mdata[0m[0;34m[[0m[0;34m""RescuerID_encoded""[0m[0;34m][0m [0;34m=[0m [0mRescuerID_encoder[0m[0;34m.[0m[0mtransform[0m[0;34m([0m[0mdata[0m[0;34m[[0m[0;34m""RescuerID""[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     33[0m [0;34m[0m[0m
[1;32m     34[0m     [0;31m# Name-based features[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py[0m in [0;36mwrapped[0;34m(self, X, *args, **kwargs)[0m
[1;32m    138[0m     [0;34m@[0m[0mwraps[0m[0;34m([0m[0mf[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    139[0m     [0;32mdef[0m [0mwrapped[0m[0;34m([0m[0mself[0m[0;34m,[0m [0mX[0m[0;34m,[0m [0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 140[0;31m         [0mdata_to_wrap[0m [0;34m=[0m [0mf[0m[0;34m([0m[0mself[0m[0;34m,[0m [0mX[0m[0;34m,[0m [0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    141[0m         [0;32mif[0m [0misinstance[0m[0;34m([0m[0mdata_to_wrap[0m[0;34m,[0m [0mtuple[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    142[0m             [0;31m# only wrap the first output for cross decomposition[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py[0m in [0;36mtransform[0;34m(self, y)[0m
[1;32m    137[0m             [0;32mreturn[0m [0mnp[0m[0;34m.[0m[0marray[0m[0;34m([0m[0;34m[[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    138[0m [0;34m[0m[0m
[0;32m--> 139[0;31m         [0;32mreturn[0m [0m_encode[0m[0;34m([0m[0my[0m[0;34m,[0m [0muniques[0m[0;34m=[0m[0mself[0m[0;34m.[0m[0mclasses_[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    140[0m [0;34m[0m[0m
[1;32m    141[0m     [0;32mdef[0m [0minverse_transform[0m[0;34m([0m[0mself[0m[0;34m,[0m [0my[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py[0m in [0;36m_encode[0;34m(values, uniques, check_unknown)[0m
[1;32m    224[0m             [0;32mreturn[0m [0m_map_to_integer[0m[0;34m([0m[0mvalues[0m[0;34m,[0m [0muniques[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    225[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 226[0;31m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34mf""y contains previously unseen labels: {str(e)}""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    227[0m     [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    228[0m         [0;32mif[0m [0mcheck_unknown[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: y contains previously unseen labels: '2ece3b2573dcdcebd774e635dca15fd9'
ValueError: y contains previously unseen labels: '2ece3b2573dcdcebd774e635dca15fd9'
",ValueError,y contains previously unseen labels: '2ece3b2573dcdcebd774e635dca15fd9'
/junobench_env/torch_12/torch_12_extension.ipynb,2026-01-14T17:54:59.223799,CellExecutionError,"An error occurred while executing the following cell:
------------------
#By Ranamalla Nithin Reddy https://www.kaggle.com/code/nithinreddy90/chatpgpt-prompts

import matplotlib.pyplot as plt

# Create histograms for prompt and action token counts
plt.figure(figsize=(10, 6))
plt.hist(df['instruction_tokens'], bins=20, alpha=0.5, label='Instruction Tokens')
plt.hist(df['output_tokens'], bins=20, alpha=0.5, label='Output Tokens')
plt.xlabel('Token Count')
plt.ylabel('Frequency')
plt.title('Token Count Distribution')
plt.legend()
plt.show()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key)[0m
[1;32m   3652[0m         [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3653[0;31m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3654[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.PyObjectHashTable.get_item[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.PyObjectHashTable.get_item[0;34m()[0m

[0;31mKeyError[0m: 'instruction_tokens'

The above exception was the direct cause of the following exception:

[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m<ipython-input-11-392fb836e3d8>[0m in [0;36m<cell line: 7>[0;34m()[0m
[1;32m      5[0m [0;31m# Create histograms for prompt and action token counts[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m [0mplt[0m[0;34m.[0m[0mfigure[0m[0;34m([0m[0mfigsize[0m[0;34m=[0m[0;34m([0m[0;36m10[0m[0;34m,[0m [0;36m6[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 7[0;31m [0mplt[0m[0;34m.[0m[0mhist[0m[0;34m([0m[0mdf[0m[0;34m[[0m[0;34m'instruction_tokens'[0m[0;34m][0m[0;34m,[0m [0mbins[0m[0;34m=[0m[0;36m20[0m[0;34m,[0m [0malpha[0m[0;34m=[0m[0;36m0.5[0m[0;34m,[0m [0mlabel[0m[0;34m=[0m[0;34m'Instruction Tokens'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      8[0m [0mplt[0m[0;34m.[0m[0mhist[0m[0;34m([0m[0mdf[0m[0;34m[[0m[0;34m'output_tokens'[0m[0;34m][0m[0;34m,[0m [0mbins[0m[0;34m=[0m[0;36m20[0m[0;34m,[0m [0malpha[0m[0;34m=[0m[0;36m0.5[0m[0;34m,[0m [0mlabel[0m[0;34m=[0m[0;34m'Output Tokens'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m [0mplt[0m[0;34m.[0m[0mxlabel[0m[0;34m([0m[0;34m'Token Count'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36m__getitem__[0;34m(self, key)[0m
[1;32m   3759[0m             [0;32mif[0m [0mself[0m[0;34m.[0m[0mcolumns[0m[0;34m.[0m[0mnlevels[0m [0;34m>[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3760[0m                 [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_getitem_multilevel[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3761[0;31m             [0mindexer[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mcolumns[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3762[0m             [0;32mif[0m [0mis_integer[0m[0;34m([0m[0mindexer[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3763[0m                 [0mindexer[0m [0;34m=[0m [0;34m[[0m[0mindexer[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key)[0m
[1;32m   3653[0m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3654[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3655[0;31m             [0;32mraise[0m [0mKeyError[0m[0;34m([0m[0mkey[0m[0;34m)[0m [0;32mfrom[0m [0merr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3656[0m         [0;32mexcept[0m [0mTypeError[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3657[0m             [0;31m# If we have a listlike key, _check_indexing_error will raise[0m[0;34m[0m[0;34m[0m[0m

[0;31mKeyError[0m: 'instruction_tokens'
KeyError: 'instruction_tokens'
",KeyError,'instruction_tokens'
/junobench_env/tensorflow_10/tensorflow_10_extension.ipynb,2026-01-14T17:55:37.488332,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Compile and train the model
# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# model.fit(train_data, train_labels, epochs=10)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-20-9dc4154d65b9>[0m in [0;36m<cell line: 6>[0;34m()[0m
[1;32m      4[0m [0;34m[0m[0m
[1;32m      5[0m [0mmodel[0m[0;34m.[0m[0mcompile[0m[0;34m([0m[0moptimizer[0m[0;34m=[0m[0;34m'adam'[0m[0;34m,[0m [0mloss[0m[0;34m=[0m[0;34m'binary_crossentropy'[0m[0;34m,[0m [0mmetrics[0m[0;34m=[0m[0;34m[[0m[0;34m'accuracy'[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 6[0;31m [0mmodel[0m[0;34m.[0m[0mfit[0m[0;34m([0m[0mX_train[0m[0;34m,[0m [0my_train[0m[0;34m,[0m [0mepochs[0m[0;34m=[0m[0;36m10[0m[0;34m,[0m [0mvalidation_data[0m[0;34m=[0m[0;34m([0m[0mX_valid[0m[0;34m,[0m [0my_valid[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
[1;32m    120[0m             [0;31m# To get the full stack trace, call:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    121[0m             [0;31m# `keras.config.disable_traceback_filtering()`[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 122[0;31m             [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    123[0m         [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    124[0m             [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py[0m in [0;36m__call__[0;34m(self, *args, **kwargs)[0m
[1;32m    787[0m                     [0;32mand[0m [0marg[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[1;32m    788[0m                 ):
[0;32m--> 789[0;31m                     raise ValueError(
[0m[1;32m    790[0m                         [0;34m""Only input tensors may be passed as ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    791[0m                         [0;34m""positional arguments. The following argument value ""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: Exception encountered when calling Sequential.call().

[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor 'sequential_1/hugging_face_layer_1/tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0' shape=(32, 128, 768) dtype=float32>, pooler_output=<tf.Tensor 'sequential_1/hugging_face_layer_1/tf_bert_model/bert/pooler/dense/Tanh:0' shape=(32, 768) dtype=float32>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None) (of type <class 'transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions'>)[0m

Arguments received by Sequential.call():
  • inputs={'input_ids': 'tf.Tensor(shape=(32, 128), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(32, 128), dtype=int32)', 'token_type_ids': 'tf.Tensor(shape=(32, 128), dtype=int32)'}
  • training=True
  • mask={'input_ids': 'None', 'attention_mask': 'None', 'token_type_ids': 'None'}
ValueError: Exception encountered when calling Sequential.call().

[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor 'sequential_1/hugging_face_layer_1/tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0' shape=(32, 128, 768) dtype=float32>, pooler_output=<tf.Tensor 'sequential_1/hugging_face_layer_1/tf_bert_model/bert/pooler/dense/Tanh:0' shape=(32, 768) dtype=float32>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None) (of type <class 'transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions'>)[0m

Arguments received by Sequential.call():
  • inputs={'input_ids': 'tf.Tensor(shape=(32, 128), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(32, 128), dtype=int32)', 'token_type_ids': 'tf.Tensor(shape=(32, 128), dtype=int32)'}
  • training=True
  • mask={'input_ids': 'None', 'attention_mask': 'None', 'token_type_ids': 'None'}
",ValueError,Exception encountered when calling Sequential.call().
/junobench_env/lightgbm_1/lightgbm_1_extension.ipynb,2026-01-14T18:04:18.709326,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Check for NaNs in the target variable
print(
    f""NaNs in target 'quality' before handling: ""
    f""{train3[conf.target].isnull().sum()}""
)

initial_rows = train3.shape[0]

# Drop rows where the target variable is NaN
train3.dropna(subset=[conf.target], inplace=True)

print(
    f""Dropped {initial_rows - train3.shape[0]} rows with NaN in target.""
)

# Re-define X and y after dropping NaNs to ensure they are clean
y = train3[conf.target]
X = train3.drop([conf.target], axis=1)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key)[0m
[1;32m   3652[0m         [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3653[0;31m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3654[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.PyObjectHashTable.get_item[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.PyObjectHashTable.get_item[0;34m()[0m

[0;31mKeyError[0m: 'quality'

The above exception was the direct cause of the following exception:

[0;31mKeyError[0m                                  Traceback (most recent call last)
[0;32m<ipython-input-23-3f4b0c6d56c4>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      2[0m print(
[1;32m      3[0m     [0;34mf""NaNs in target 'quality' before handling: ""[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m     [0;34mf""{train3[conf.target].isnull().sum()}""[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m )
[1;32m      6[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py[0m in [0;36m__getitem__[0;34m(self, key)[0m
[1;32m   3759[0m             [0;32mif[0m [0mself[0m[0;34m.[0m[0mcolumns[0m[0;34m.[0m[0mnlevels[0m [0;34m>[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3760[0m                 [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_getitem_multilevel[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3761[0;31m             [0mindexer[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mcolumns[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3762[0m             [0;32mif[0m [0mis_integer[0m[0;34m([0m[0mindexer[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3763[0m                 [0mindexer[0m [0;34m=[0m [0;34m[[0m[0mindexer[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key)[0m
[1;32m   3653[0m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3654[0m         [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3655[0;31m             [0;32mraise[0m [0mKeyError[0m[0;34m([0m[0mkey[0m[0;34m)[0m [0;32mfrom[0m [0merr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3656[0m         [0;32mexcept[0m [0mTypeError[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3657[0m             [0;31m# If we have a listlike key, _check_indexing_error will raise[0m[0;34m[0m[0;34m[0m[0m

[0;31mKeyError[0m: 'quality'
KeyError: 'quality'
",KeyError,'quality'
/junobench_env/NBspecific_2/NBspecific_2_extension.ipynb,2026-01-14T18:12:08.112654,CellExecutionError,"An error occurred while executing the following cell:
------------------
from xgboost import XGBClassifier 
classifier = XGBClassifier(tree_method='gpu_hist', gpu_id=0, random_state=1) # Added random_state 
# Ensure X_train, y_train, X_test, y_test are defined by running the train_test_split cell first 
classifier.fit(X_train, y_train) 
y_hat = classifier.predict(X_test) 
accuracy_score(y_test, y_hat)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mXGBoostError[0m                              Traceback (most recent call last)
[0;32m<ipython-input-21-64031c81fcdf>[0m in [0;36m<cell line: 4>[0;34m()[0m
[1;32m      2[0m [0mclassifier[0m [0;34m=[0m [0mXGBClassifier[0m[0;34m([0m[0mtree_method[0m[0;34m=[0m[0;34m'gpu_hist'[0m[0;34m,[0m [0mgpu_id[0m[0;34m=[0m[0;36m0[0m[0;34m,[0m [0mrandom_state[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m [0;31m# Added random_state[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0;31m# Ensure X_train, y_train, X_test, y_test are defined by running the train_test_split cell first[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m [0mclassifier[0m[0;34m.[0m[0mfit[0m[0;34m([0m[0mX_train[0m[0;34m,[0m [0my_train[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0my_hat[0m [0;34m=[0m [0mclassifier[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mX_test[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m [0maccuracy_score[0m[0;34m([0m[0my_test[0m[0;34m,[0m [0my_hat[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py[0m in [0;36minner_f[0;34m(*args, **kwargs)[0m
[1;32m    728[0m             [0;32mfor[0m [0mk[0m[0;34m,[0m [0marg[0m [0;32min[0m [0mzip[0m[0;34m([0m[0msig[0m[0;34m.[0m[0mparameters[0m[0;34m,[0m [0margs[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    729[0m                 [0mkwargs[0m[0;34m[[0m[0mk[0m[0;34m][0m [0;34m=[0m [0marg[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 730[0;31m             [0;32mreturn[0m [0mfunc[0m[0;34m([0m[0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    731[0m [0;34m[0m[0m
[1;32m    732[0m         [0;32mreturn[0m [0minner_f[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py[0m in [0;36mfit[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)[0m
[1;32m   1517[0m             )
[1;32m   1518[0m [0;34m[0m[0m
[0;32m-> 1519[0;31m             self._Booster = train(
[0m[1;32m   1520[0m                 [0mparams[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1521[0m                 [0mtrain_dmatrix[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py[0m in [0;36minner_f[0;34m(*args, **kwargs)[0m
[1;32m    728[0m             [0;32mfor[0m [0mk[0m[0;34m,[0m [0marg[0m [0;32min[0m [0mzip[0m[0;34m([0m[0msig[0m[0;34m.[0m[0mparameters[0m[0;34m,[0m [0margs[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    729[0m                 [0mkwargs[0m[0;34m[[0m[0mk[0m[0;34m][0m [0;34m=[0m [0marg[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 730[0;31m             [0;32mreturn[0m [0mfunc[0m[0;34m([0m[0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    731[0m [0;34m[0m[0m
[1;32m    732[0m         [0;32mreturn[0m [0minner_f[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py[0m in [0;36mtrain[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)[0m
[1;32m    179[0m         [0;32mif[0m [0mcb_container[0m[0;34m.[0m[0mbefore_iteration[0m[0;34m([0m[0mbst[0m[0;34m,[0m [0mi[0m[0;34m,[0m [0mdtrain[0m[0;34m,[0m [0mevals[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    180[0m             [0;32mbreak[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 181[0;31m         [0mbst[0m[0;34m.[0m[0mupdate[0m[0;34m([0m[0mdtrain[0m[0;34m,[0m [0mi[0m[0;34m,[0m [0mobj[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    182[0m         [0;32mif[0m [0mcb_container[0m[0;34m.[0m[0mafter_iteration[0m[0;34m([0m[0mbst[0m[0;34m,[0m [0mi[0m[0;34m,[0m [0mdtrain[0m[0;34m,[0m [0mevals[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    183[0m             [0;32mbreak[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py[0m in [0;36mupdate[0;34m(self, dtrain, iteration, fobj)[0m
[1;32m   2048[0m [0;34m[0m[0m
[1;32m   2049[0m         [0;32mif[0m [0mfobj[0m [0;32mis[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 2050[0;31m             _check_call(
[0m[1;32m   2051[0m                 _LIB.XGBoosterUpdateOneIter(
[1;32m   2052[0m                     [0mself[0m[0;34m.[0m[0mhandle[0m[0;34m,[0m [0mctypes[0m[0;34m.[0m[0mc_int[0m[0;34m([0m[0miteration[0m[0;34m)[0m[0;34m,[0m [0mdtrain[0m[0;34m.[0m[0mhandle[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py[0m in [0;36m_check_call[0;34m(ret)[0m
[1;32m    280[0m     """"""
[1;32m    281[0m     [0;32mif[0m [0mret[0m [0;34m!=[0m [0;36m0[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 282[0;31m         [0;32mraise[0m [0mXGBoostError[0m[0;34m([0m[0mpy_str[0m[0;34m([0m[0m_LIB[0m[0;34m.[0m[0mXGBGetLastError[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    283[0m [0;34m[0m[0m
[1;32m    284[0m [0;34m[0m[0m

[0;31mXGBoostError[0m: [18:12:04] /workspace/src/tree/updater_gpu_hist.cu:781: Exception in gpu_hist: [18:12:04] /workspace/src/tree/updater_gpu_hist.cu:787: Check failed: ctx_->gpu_id >= 0 (-1 vs. 0) : Must have at least one device
Stack trace:
  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb27f2a) [0x7fe117f49f2a]
  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb3e95a) [0x7fe117f6095a]
  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb483cd) [0x7fe117f6a3cd]
  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x460c79) [0x7fe117882c79]
  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x461d09) [0x7fe117883d09]
  [bt] (5) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c54f7) [0x7fe1178e74f7]
  [bt] (6) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7fe117583ef0]
  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7fe2c0791e2e]
  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7fe2c078e493]



Stack trace:
  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb27f2a) [0x7fe117f49f2a]
  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb485c9) [0x7fe117f6a5c9]
  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x460c79) [0x7fe117882c79]
  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x461d09) [0x7fe117883d09]
  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c54f7) [0x7fe1178e74f7]
  [bt] (5) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7fe117583ef0]
  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7fe2c0791e2e]
  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7fe2c078e493]
  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7fe2bfedd3e9]


XGBoostError: [18:12:04] /workspace/src/tree/updater_gpu_hist.cu:781: Exception in gpu_hist: [18:12:04] /workspace/src/tree/updater_gpu_hist.cu:787: Check failed: ctx_->gpu_id >= 0 (-1 vs. 0) : Must have at least one device
Stack trace:
  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb27f2a) [0x7fe117f49f2a]
  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb3e95a) [0x7fe117f6095a]
  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb483cd) [0x7fe117f6a3cd]
  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x460c79) [0x7fe117882c79]
  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x461d09) [0x7fe117883d09]
  [bt] (5) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c54f7) [0x7fe1178e74f7]
  [bt] (6) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7fe117583ef0]
  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7fe2c0791e2e]
  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7fe2c078e493]



Stack trace:
  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb27f2a) [0x7fe117f49f2a]
  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0xb485c9) [0x7fe117f6a5c9]
  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x460c79) [0x7fe117882c79]
  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x461d09) [0x7fe117883d09]
  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4c54f7) [0x7fe1178e74f7]
  [bt] (5) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7fe117583ef0]
  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7fe2c0791e2e]
  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7fe2c078e493]
  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7fe2bfedd3e9]


",XGBoostError,[18:12:04] /workspace/src/tree/updater_gpu_hist.cu:781: Exception in gpu_hist: [18:12:04] /workspace/src/tree/updater_gpu_hist.cu:787: Check failed: ctx_->gpu_id >= 0 (-1 vs. 0) : Must have at least one device
/junobench_env/sklearn_7/sklearn_7_extension.ipynb,2026-01-14T18:13:13.606233,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Calculate average annual income by family size
family_income = data.groupby('Family Size')['Annual Income ($)'].mean().reset_index()

# Create column chart
plt.bar(family_income['Family Size'], family_income['Annual Income ($)'])
plt.title('Average Annual Income by Family Size')
plt.xlabel('Family Size')

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-12-1b5341736ef7>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;31m# Calculate average annual income by family size[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mfamily_income[0m [0;34m=[0m [0mdata[0m[0;34m.[0m[0mgroupby[0m[0;34m([0m[0;34m'Family Size'[0m[0;34m)[0m[0;34m[[0m[0;34m'Annual Income ($)'[0m[0;34m][0m[0;34m.[0m[0mmean[0m[0;34m([0m[0;34m)[0m[0;34m.[0m[0mreset_index[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      3[0m [0;34m[0m[0m
[1;32m      4[0m [0;31m# Create column chart[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0mplt[0m[0;34m.[0m[0mbar[0m[0;34m([0m[0mfamily_income[0m[0;34m[[0m[0;34m'Family Size'[0m[0;34m][0m[0;34m,[0m [0mfamily_income[0m[0;34m[[0m[0;34m'Annual Income ($)'[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mNameError[0m: name 'data' is not defined
NameError: name 'data' is not defined
",NameError,name 'data' is not defined
/junobench_env/sklearn_9/sklearn_9_extension.ipynb,2026-01-14T18:13:15.307055,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Input data files are available in the ""../input/"" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(os.listdir(""../input""))

# Any results you write to the current directory are saved as output.
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mFileNotFoundError[0m                         Traceback (most recent call last)
[0;32m<ipython-input-1-f341d1164f35>[0m in [0;36m<cell line: 5>[0;34m()[0m
[1;32m      3[0m [0;34m[0m[0m
[1;32m      4[0m [0;32mimport[0m [0mos[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 5[0;31m [0mprint[0m[0;34m([0m[0mos[0m[0;34m.[0m[0mlistdir[0m[0;34m([0m[0;34m""../input""[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      6[0m [0;34m[0m[0m
[1;32m      7[0m [0;31m# Any results you write to the current directory are saved as output.[0m[0;34m[0m[0;34m[0m[0m

[0;31mFileNotFoundError[0m: [Errno 2] No such file or directory: '../input'
FileNotFoundError: [Errno 2] No such file or directory: '../input'
",FileNotFoundError,[Errno 2] No such file or directory: '../input'
/junobench_env/numpy_3/numpy_3_extension.ipynb,2026-01-14T18:13:24.315954,CellExecutionError,"An error occurred while executing the following cell:
------------------
# %%opts Histogram[width=700 height=400 tools=['hover'] xrotation=0]{+axiswise +framewise}

g = df.groupby('STATUS')

cols = ['LOAN',
        'MORTDUE', 
        'VALUE',
        'YOJ',
        'DEROG',
        'DELINQ',
        'CLAGE',
        'NINQ',
        'CLNO']
dd={}

# Histograms
for col in cols:
    
    freq, edges = np.histogram(df[col].values)
    dd[col] = hv.Histogram((edges, freq), label='ALL Loans').redim.label(x=' ')
    
    freq, edges = np.histogram(g.get_group('PAID')[col].values, bins=edges)
    dd[col] *= hv.Histogram((edges, freq), label='PAID Loans').redim.label(x=' ')
    
    freq, edges = np.histogram(g.get_group('DEFAULT')[col].values, bins=edges)
    dd[col] *= hv.Histogram((edges, freq), label='DEFAULT Loans' ).redim.label(x=' ')   
    
var = [*dd]
kdims=hv.Dimension(('var', 'Variable'), values=var)    
hv.HoloMap(dd, kdims=kdims)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-9-f80eddf9cd65>[0m in [0;36m<cell line: 17>[0;34m()[0m
[1;32m     17[0m [0;32mfor[0m [0mcol[0m [0;32min[0m [0mcols[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     18[0m [0;34m[0m[0m
[0;32m---> 19[0;31m     [0mfreq[0m[0;34m,[0m [0medges[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mhistogram[0m[0;34m([0m[0mdf[0m[0;34m[[0m[0mcol[0m[0;34m][0m[0;34m.[0m[0mvalues[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     20[0m     [0mdd[0m[0;34m[[0m[0mcol[0m[0;34m][0m [0;34m=[0m [0mhv[0m[0;34m.[0m[0mHistogram[0m[0;34m([0m[0;34m([0m[0medges[0m[0;34m,[0m [0mfreq[0m[0;34m)[0m[0;34m,[0m [0mlabel[0m[0;34m=[0m[0;34m'ALL Loans'[0m[0;34m)[0m[0;34m.[0m[0mredim[0m[0;34m.[0m[0mlabel[0m[0;34m([0m[0mx[0m[0;34m=[0m[0;34m' '[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     21[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py[0m in [0;36mhistogram[0;34m(*args, **kwargs)[0m

[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py[0m in [0;36mhistogram[0;34m(a, bins, range, normed, weights, density)[0m
[1;32m    791[0m     [0ma[0m[0;34m,[0m [0mweights[0m [0;34m=[0m [0m_ravel_and_check_weights[0m[0;34m([0m[0ma[0m[0;34m,[0m [0mweights[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    792[0m [0;34m[0m[0m
[0;32m--> 793[0;31m     [0mbin_edges[0m[0;34m,[0m [0muniform_bins[0m [0;34m=[0m [0m_get_bin_edges[0m[0;34m([0m[0ma[0m[0;34m,[0m [0mbins[0m[0;34m,[0m [0mrange[0m[0;34m,[0m [0mweights[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    794[0m [0;34m[0m[0m
[1;32m    795[0m     [0;31m# Histogram is an integer or a float array depending on the weights.[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py[0m in [0;36m_get_bin_edges[0;34m(a, bins, range, weights)[0m
[1;32m    424[0m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m'`bins` must be positive, when an integer'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    425[0m [0;34m[0m[0m
[0;32m--> 426[0;31m         [0mfirst_edge[0m[0;34m,[0m [0mlast_edge[0m [0;34m=[0m [0m_get_outer_edges[0m[0;34m([0m[0ma[0m[0;34m,[0m [0mrange[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    427[0m [0;34m[0m[0m
[1;32m    428[0m     [0;32melif[0m [0mnp[0m[0;34m.[0m[0mndim[0m[0;34m([0m[0mbins[0m[0;34m)[0m [0;34m==[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/histograms.py[0m in [0;36m_get_outer_edges[0;34m(a, range)[0m
[1;32m    321[0m         [0mfirst_edge[0m[0;34m,[0m [0mlast_edge[0m [0;34m=[0m [0ma[0m[0;34m.[0m[0mmin[0m[0;34m([0m[0;34m)[0m[0;34m,[0m [0ma[0m[0;34m.[0m[0mmax[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    322[0m         [0;32mif[0m [0;32mnot[0m [0;34m([0m[0mnp[0m[0;34m.[0m[0misfinite[0m[0;34m([0m[0mfirst_edge[0m[0;34m)[0m [0;32mand[0m [0mnp[0m[0;34m.[0m[0misfinite[0m[0;34m([0m[0mlast_edge[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 323[0;31m             raise ValueError(
[0m[1;32m    324[0m                 ""autodetected range of [{}, {}] is not finite"".format(first_edge, last_edge))
[1;32m    325[0m [0;34m[0m[0m

[0;31mValueError[0m: autodetected range of [nan, nan] is not finite
ValueError: autodetected range of [nan, nan] is not finite
",ValueError,"autodetected range of [nan, nan] is not finite"
/junobench_env/numpy_4/numpy_4_extension.ipynb,2026-01-14T18:13:40.923602,CellExecutionError,"An error occurred while executing the following cell:
------------------
model.summary()
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-16-5f15418b3570>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mmodel[0m[0;34m.[0m[0msummary[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
[1;32m    120[0m             [0;31m# To get the full stack trace, call:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    121[0m             [0;31m# `keras.config.disable_traceback_filtering()`[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 122[0;31m             [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    123[0m         [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    124[0m             [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/optree/ops.py[0m in [0;36mtree_map[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)[0m
[1;32m    745[0m     [0mleaves[0m[0;34m,[0m [0mtreespec[0m [0;34m=[0m [0m_C[0m[0;34m.[0m[0mflatten[0m[0;34m([0m[0mtree[0m[0;34m,[0m [0mis_leaf[0m[0;34m,[0m [0mnone_is_leaf[0m[0;34m,[0m [0mnamespace[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    746[0m     [0mflat_args[0m [0;34m=[0m [0;34m[[0m[0mleaves[0m[0;34m][0m [0;34m+[0m [0;34m[[0m[0mtreespec[0m[0;34m.[0m[0mflatten_up_to[0m[0;34m([0m[0mr[0m[0;34m)[0m [0;32mfor[0m [0mr[0m [0;32min[0m [0mrests[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 747[0;31m     [0;32mreturn[0m [0mtreespec[0m[0;34m.[0m[0munflatten[0m[0;34m([0m[0mmap[0m[0;34m([0m[0mfunc[0m[0;34m,[0m [0;34m*[0m[0mflat_args[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    748[0m [0;34m[0m[0m
[1;32m    749[0m [0;34m[0m[0m

[0;31mValueError[0m: Undefined shapes are not supported.
ValueError: Undefined shapes are not supported.
",ValueError,Undefined shapes are not supported.
/junobench_env/numpy_10/numpy_10_extension.ipynb,2026-01-14T18:15:33.714394,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Imports here
%matplotlib inline
%config InlinBackend.figure_format = 'retina'
import numpy as np
import random
import torch
from torch import nn
from torch import optim
import torch.nn.functional as F
import ast
import torchvision.transforms as transforms
from torchvision import datasets, models, transforms
import torchvision.models as models
from torch.autograd import Variable
from collections import OrderedDict
from PIL import Image
import json
import time
import warnings
warnings.filterwarnings('ignore')
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-4-7c53b0e71201>[0m in [0;36m<cell line: 11>[0;34m()[0m
[1;32m      9[0m [0;32mimport[0m [0mtorch[0m[0;34m.[0m[0mnn[0m[0;34m.[0m[0mfunctional[0m [0;32mas[0m [0mF[0m[0;34m[0m[0;34m[0m[0m
[1;32m     10[0m [0;32mimport[0m [0mast[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 11[0;31m [0;32mimport[0m [0mtorchvision[0m[0;34m.[0m[0mtransforms[0m [0;32mas[0m [0mtransforms[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     12[0m [0;32mfrom[0m [0mtorchvision[0m [0;32mimport[0m [0mdatasets[0m[0;34m,[0m [0mmodels[0m[0;34m,[0m [0mtransforms[0m[0;34m[0m[0;34m[0m[0m
[1;32m     13[0m [0;32mimport[0m [0mtorchvision[0m[0;34m.[0m[0mmodels[0m [0;32mas[0m [0mmodels[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py[0m in [0;36m<module>[0;34m[0m
[1;32m      8[0m [0;31m# .extensions) before entering _meta_registrations.[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m [0;32mfrom[0m [0;34m.[0m[0mextension[0m [0;32mimport[0m [0m_HAS_OPS[0m  [0;31m# usort:skip[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 10[0;31m [0;32mfrom[0m [0mtorchvision[0m [0;32mimport[0m [0m_meta_registrations[0m[0;34m,[0m [0mdatasets[0m[0;34m,[0m [0mio[0m[0;34m,[0m [0mmodels[0m[0;34m,[0m [0mops[0m[0;34m,[0m [0mtransforms[0m[0;34m,[0m [0mutils[0m  [0;31m# usort:skip[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     11[0m [0;34m[0m[0m
[1;32m     12[0m [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/_meta_registrations.py[0m in [0;36m<module>[0;34m[0m
[1;32m      2[0m [0;34m[0m[0m
[1;32m      3[0m [0;32mimport[0m [0mtorch[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m [0;32mimport[0m [0mtorch[0m[0;34m.[0m[0m_custom_ops[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0;32mimport[0m [0mtorch[0m[0;34m.[0m[0mlibrary[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m [0;34m[0m[0m

[0;31mModuleNotFoundError[0m: No module named 'torch._custom_ops'
ModuleNotFoundError: No module named 'torch._custom_ops'
",ModuleNotFoundError,No module named 'torch._custom_ops'
/junobench_env/NBspecific_4/NBspecific_4_extension.ipynb,2026-01-14T18:15:42.544468,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Importation des bibliothèques que nous utiliserons dans cette partie de la classe
from sklearn.model_selection import train_test_split, KFold, cross_val_score # pour séparer les données
from sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report, f1_score, precision_score, recall_score #Pour évaluer notre modèle

from sklearn.model_selection import GridSearchCV

# Modèles d'algorithmes à comparer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
# TODO: Ajouter ici tout nouveau modèle que vous souhaitez essayer (ANN, etc.)

# Création des variables X et y
dataset_ready_x = dataset_ready.drop(['Risk_bad', 'Risk_good', 'Age', 'Sex_male'], axis='columns')
X = dataset_ready_x.values
feature_names = dataset_ready_x.columns

y = dataset_ready['Risk_bad'].values

# Séparation de X et y en version d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mImportError[0m                               Traceback (most recent call last)
[0;32m<ipython-input-21-0d52f8edbe50>[0m in [0;36m<cell line: 3>[0;34m()[0m
[1;32m      1[0m [0;31m# Importation des bibliothèques que nous utiliserons dans cette partie de la classe[0m[0;34m[0m[0;34m[0m[0m
[1;32m      2[0m [0;32mfrom[0m [0msklearn[0m[0;34m.[0m[0mmodel_selection[0m [0;32mimport[0m [0mtrain_test_split[0m[0;34m,[0m [0mKFold[0m[0;34m,[0m [0mcross_val_score[0m [0;31m# pour séparer les données[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 3[0;31m [0;32mfrom[0m [0msklearn[0m[0;34m.[0m[0mmetrics[0m [0;32mimport[0m [0maccuracy_score[0m[0;34m,[0m [0mplot_confusion_matrix[0m[0;34m,[0m [0mclassification_report[0m[0;34m,[0m [0mf1_score[0m[0;34m,[0m [0mprecision_score[0m[0;34m,[0m [0mrecall_score[0m [0;31m#Pour évaluer notre modèle[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      4[0m [0;34m[0m[0m
[1;32m      5[0m [0;32mfrom[0m [0msklearn[0m[0;34m.[0m[0mmodel_selection[0m [0;32mimport[0m [0mGridSearchCV[0m[0;34m[0m[0;34m[0m[0m

[0;31mImportError[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/usr/local/lib/python3.10/dist-packages/sklearn/metrics/__init__.py)
ImportError: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/usr/local/lib/python3.10/dist-packages/sklearn/metrics/__init__.py)
",ImportError,cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/usr/local/lib/python3.10/dist-packages/sklearn/metrics/__init__.py)
/junobench_env/statsmodels_1/statsmodels_1_extension.ipynb,2026-01-14T18:15:48.675460,CellExecutionError,"An error occurred while executing the following cell:
------------------
fig = sm.qqplot(train['osmo'],line=45,fit=True)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-29-1c3a8c52f37c>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mfig[0m [0;34m=[0m [0msm[0m[0;34m.[0m[0mqqplot[0m[0;34m([0m[0mtrain[0m[0;34m[[0m[0;34m'osmo'[0m[0;34m][0m[0;34m,[0m[0mline[0m[0;34m=[0m[0;36m45[0m[0;34m,[0m[0mfit[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/gofplots.py[0m in [0;36mqqplot[0;34m(data, dist, distargs, a, loc, scale, fit, line, ax, **plotkwargs)[0m
[1;32m    689[0m         [0mdata[0m[0;34m,[0m [0mdist[0m[0;34m=[0m[0mdist[0m[0;34m,[0m [0mdistargs[0m[0;34m=[0m[0mdistargs[0m[0;34m,[0m [0mfit[0m[0;34m=[0m[0mfit[0m[0;34m,[0m [0ma[0m[0;34m=[0m[0ma[0m[0;34m,[0m [0mloc[0m[0;34m=[0m[0mloc[0m[0;34m,[0m [0mscale[0m[0;34m=[0m[0mscale[0m[0;34m[0m[0;34m[0m[0m
[1;32m    690[0m     )
[0;32m--> 691[0;31m     [0mfig[0m [0;34m=[0m [0mprobplot[0m[0;34m.[0m[0mqqplot[0m[0;34m([0m[0max[0m[0;34m=[0m[0max[0m[0;34m,[0m [0mline[0m[0;34m=[0m[0mline[0m[0;34m,[0m [0;34m**[0m[0mplotkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    692[0m     [0;32mreturn[0m [0mfig[0m[0;34m[0m[0;34m[0m[0m
[1;32m    693[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/gofplots.py[0m in [0;36mqqplot[0;34m(self, xlabel, ylabel, line, other, ax, swap, **plotkwargs)[0m
[1;32m    475[0m [0;34m[0m[0m
[1;32m    476[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 477[0;31m             fig, ax = _do_plot(
[0m[1;32m    478[0m                 [0mself[0m[0;34m.[0m[0mtheoretical_quantiles[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    479[0m                 [0mself[0m[0;34m.[0m[0msample_quantiles[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/graphics/gofplots.py[0m in [0;36m_do_plot[0;34m(x, y, dist, line, ax, fmt, step, **kwargs)[0m
[1;32m   1047[0m         [0;32mif[0m [0mline[0m [0;32mnot[0m [0;32min[0m [0;34m[[0m[0;34m""r""[0m[0;34m,[0m [0;34m""q""[0m[0;34m,[0m [0;34m""45""[0m[0;34m,[0m [0;34m""s""[0m[0;34m][0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1048[0m             [0mmsg[0m [0;34m=[0m [0;34m""%s option for line not understood""[0m [0;34m%[0m [0mline[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1049[0;31m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0mmsg[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1050[0m [0;34m[0m[0m
[1;32m   1051[0m         [0mqqline[0m[0;34m([0m[0max[0m[0;34m,[0m [0mline[0m[0;34m,[0m [0mx[0m[0;34m=[0m[0mx[0m[0;34m,[0m [0my[0m[0;34m=[0m[0my[0m[0;34m,[0m [0mdist[0m[0;34m=[0m[0mdist[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: 45 option for line not understood
ValueError: 45 option for line not understood
",ValueError,45 option for line not understood
/junobench_env/tensorflow_11/tensorflow_11_extension.ipynb,2026-01-14T18:16:59.113154,DeadKernelError,Kernel died,,
/junobench_env/sklearn_8/sklearn_8_extension.ipynb,2026-01-14T18:17:27.234944,CellExecutionError,"An error occurred while executing the following cell:
------------------
# Create a DataFrame
test_predictions = RF.predict(
    insurance_test.drop('Id', axis=1)
)

submission = pd.DataFrame({
    'Id': insurance_test['Id'],
    'Response': test_predictions
})

# submission = pd.DataFrame({'Id': test_data['Id'], 'Response': predicted_classes})

# Save it as a CSV file
submission.to_csv('submission.csv', index=False)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-26-51ccbf17abdc>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;31m# Create a DataFrame[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m test_predictions = RF.predict(
[0m[1;32m      3[0m     [0minsurance_test[0m[0;34m.[0m[0mdrop[0m[0;34m([0m[0;34m'Id'[0m[0;34m,[0m [0maxis[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m )
[1;32m      5[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36mpredict[0;34m(self, X)[0m
[1;32m    818[0m             [0mThe[0m [0mpredicted[0m [0mclasses[0m[0;34m.[0m[0;34m[0m[0;34m[0m[0m
[1;32m    819[0m         """"""
[0;32m--> 820[0;31m         [0mproba[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mpredict_proba[0m[0;34m([0m[0mX[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    821[0m [0;34m[0m[0m
[1;32m    822[0m         [0;32mif[0m [0mself[0m[0;34m.[0m[0mn_outputs_[0m [0;34m==[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36mpredict_proba[0;34m(self, X)[0m
[1;32m    860[0m         [0mcheck_is_fitted[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    861[0m         [0;31m# Check data[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 862[0;31m         [0mX[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_validate_X_predict[0m[0;34m([0m[0mX[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    863[0m [0;34m[0m[0m
[1;32m    864[0m         [0;31m# Assign chunk of trees to jobs[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36m_validate_X_predict[0;34m(self, X)[0m
[1;32m    600[0m         Validate X whenever one tries to predict, apply, predict_proba.""""""
[1;32m    601[0m         [0mcheck_is_fitted[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 602[0;31m         [0mX[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_validate_data[0m[0;34m([0m[0mX[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mDTYPE[0m[0;34m,[0m [0maccept_sparse[0m[0;34m=[0m[0;34m""csr""[0m[0;34m,[0m [0mreset[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    603[0m         [0;32mif[0m [0missparse[0m[0;34m([0m[0mX[0m[0;34m)[0m [0;32mand[0m [0;34m([0m[0mX[0m[0;34m.[0m[0mindices[0m[0;34m.[0m[0mdtype[0m [0;34m!=[0m [0mnp[0m[0;34m.[0m[0mintc[0m [0;32mor[0m [0mX[0m[0;34m.[0m[0mindptr[0m[0;34m.[0m[0mdtype[0m [0;34m!=[0m [0mnp[0m[0;34m.[0m[0mintc[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    604[0m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m""No support for np.int64 index based sparse matrices""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py[0m in [0;36m_validate_data[0;34m(self, X, y, reset, validate_separately, **check_params)[0m
[1;32m    546[0m             [0mvalidated[0m[0;34m.[0m[0;34m[0m[0;34m[0m[0m
[1;32m    547[0m         """"""
[0;32m--> 548[0;31m         [0mself[0m[0;34m.[0m[0m_check_feature_names[0m[0;34m([0m[0mX[0m[0;34m,[0m [0mreset[0m[0;34m=[0m[0mreset[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    549[0m [0;34m[0m[0m
[1;32m    550[0m         [0;32mif[0m [0my[0m [0;32mis[0m [0;32mNone[0m [0;32mand[0m [0mself[0m[0;34m.[0m[0m_get_tags[0m[0;34m([0m[0;34m)[0m[0;34m[[0m[0;34m""requires_y""[0m[0;34m][0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py[0m in [0;36m_check_feature_names[0;34m(self, X, reset)[0m
[1;32m    479[0m                 )
[1;32m    480[0m [0;34m[0m[0m
[0;32m--> 481[0;31m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0mmessage[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    482[0m [0;34m[0m[0m
[1;32m    483[0m     def _validate_data(

[0;31mValueError[0m: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- InsuredInfo_7

ValueError: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- InsuredInfo_7

",ValueError,The feature names should match those that were passed during fit.
/junobench_env/numpy_2/numpy_2_extension.ipynb,2026-01-14T18:17:31.134636,CellExecutionError,"An error occurred while executing the following cell:
------------------
arr = np.concatenate((arr1, arr2), axis=1)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-23-102734ed91e7>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0marr[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mconcatenate[0m[0;34m([0m[0;34m([0m[0marr1[0m[0;34m,[0m [0marr2[0m[0;34m)[0m[0;34m,[0m [0maxis[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;31mNameError[0m: name 'arr1' is not defined
NameError: name 'arr1' is not defined
",NameError,name 'arr1' is not defined
/junobench_env/sklearn_1/sklearn_1_extension.ipynb,2026-01-14T18:17:43.457845,CellExecutionError,"An error occurred while executing the following cell:
------------------
from sklearn.utils.class_weight import compute_class_weight
# class_weights = compute_class_weight('balanced', np.unique(train_dataset.labels), train_dataset.labels)
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_dataset.classes),
    y=train_dataset.classes
)
class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}

# Compile the model with class weights
model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=METRICS, class_weight=class_weight_dict)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-10-09704a284e6f>[0m in [0;36m<cell line: 11>[0;34m()[0m
[1;32m      9[0m [0;34m[0m[0m
[1;32m     10[0m [0;31m# Compile the model with class weights[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 11[0;31m [0mmodel[0m[0;34m.[0m[0mcompile[0m[0;34m([0m[0moptimizer[0m[0;34m=[0m[0;34m'Adam'[0m[0;34m,[0m [0mloss[0m[0;34m=[0m[0;34m'categorical_crossentropy'[0m[0;34m,[0m [0mmetrics[0m[0;34m=[0m[0mMETRICS[0m[0;34m,[0m [0mclass_weight[0m[0;34m=[0m[0mclass_weight_dict[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
[1;32m    120[0m             [0;31m# To get the full stack trace, call:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    121[0m             [0;31m# `keras.config.disable_traceback_filtering()`[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 122[0;31m             [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    123[0m         [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    124[0m             [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tracking.py[0m in [0;36mwrapper[0;34m(*args, **kwargs)[0m
[1;32m     24[0m     [0;32mdef[0m [0mwrapper[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     25[0m         [0;32mwith[0m [0mDotNotTrackScope[0m[0;34m([0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 26[0;31m             [0;32mreturn[0m [0mfn[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     27[0m [0;34m[0m[0m
[1;32m     28[0m     [0;32mreturn[0m [0mwrapper[0m[0;34m[0m[0;34m[0m[0m

[0;31mTypeError[0m: Trainer.compile() got an unexpected keyword argument 'class_weight'
TypeError: Trainer.compile() got an unexpected keyword argument 'class_weight'
",TypeError,Trainer.compile() got an unexpected keyword argument 'class_weight'
/junobench_env/sklearn_6/sklearn_6_extension.ipynb,2026-01-14T18:18:07.804892,CellExecutionError,"An error occurred while executing the following cell:
------------------
predictions = FReg.predict(test_ds)
submissions_df = pd.DataFrame({
    ""ID"" : test_ds_ids, # test_data['ID'], # fix for crash isolation purpose
    ""Predictions"" : predictions
})

# submissions_df.to_csv('submission_csv', index = False)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-47-0b091944b5d9>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mpredictions[0m [0;34m=[0m [0mFReg[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mtest_ds[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m submissions_df = pd.DataFrame({
[1;32m      3[0m     [0;34m""ID""[0m [0;34m:[0m [0mtest_ds_ids[0m[0;34m,[0m [0;31m# test_data['ID'], # fix for crash isolation purpose[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m     [0;34m""Predictions""[0m [0;34m:[0m [0mpredictions[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m })

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36mpredict[0;34m(self, X)[0m
[1;32m    979[0m         [0mcheck_is_fitted[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    980[0m         [0;31m# Check data[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 981[0;31m         [0mX[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_validate_X_predict[0m[0;34m([0m[0mX[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    982[0m [0;34m[0m[0m
[1;32m    983[0m         [0;31m# Assign chunk of trees to jobs[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36m_validate_X_predict[0;34m(self, X)[0m
[1;32m    600[0m         Validate X whenever one tries to predict, apply, predict_proba.""""""
[1;32m    601[0m         [0mcheck_is_fitted[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 602[0;31m         [0mX[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_validate_data[0m[0;34m([0m[0mX[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mDTYPE[0m[0;34m,[0m [0maccept_sparse[0m[0;34m=[0m[0;34m""csr""[0m[0;34m,[0m [0mreset[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    603[0m         [0;32mif[0m [0missparse[0m[0;34m([0m[0mX[0m[0;34m)[0m [0;32mand[0m [0;34m([0m[0mX[0m[0;34m.[0m[0mindices[0m[0;34m.[0m[0mdtype[0m [0;34m!=[0m [0mnp[0m[0;34m.[0m[0mintc[0m [0;32mor[0m [0mX[0m[0;34m.[0m[0mindptr[0m[0;34m.[0m[0mdtype[0m [0;34m!=[0m [0mnp[0m[0;34m.[0m[0mintc[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    604[0m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m""No support for np.int64 index based sparse matrices""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py[0m in [0;36m_validate_data[0;34m(self, X, y, reset, validate_separately, **check_params)[0m
[1;32m    546[0m             [0mvalidated[0m[0;34m.[0m[0;34m[0m[0;34m[0m[0m
[1;32m    547[0m         """"""
[0;32m--> 548[0;31m         [0mself[0m[0;34m.[0m[0m_check_feature_names[0m[0;34m([0m[0mX[0m[0;34m,[0m [0mreset[0m[0;34m=[0m[0mreset[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    549[0m [0;34m[0m[0m
[1;32m    550[0m         [0;32mif[0m [0my[0m [0;32mis[0m [0;32mNone[0m [0;32mand[0m [0mself[0m[0;34m.[0m[0m_get_tags[0m[0;34m([0m[0;34m)[0m[0;34m[[0m[0;34m""requires_y""[0m[0;34m][0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py[0m in [0;36m_check_feature_names[0;34m(self, X, reset)[0m
[1;32m    479[0m                 )
[1;32m    480[0m [0;34m[0m[0m
[0;32m--> 481[0;31m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0mmessage[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    482[0m [0;34m[0m[0m
[1;32m    483[0m     def _validate_data(

[0;31mValueError[0m: The feature names should match those that were passed during fit.
Feature names seen at fit time, yet now missing:
- BsmtFullBath
- BsmtHalfBath
- Functional
- MSZoning
- Utilities

ValueError: The feature names should match those that were passed during fit.
Feature names seen at fit time, yet now missing:
- BsmtFullBath
- BsmtHalfBath
- Functional
- MSZoning
- Utilities

",ValueError,The feature names should match those that were passed during fit.
/junobench_env/torch_4/torch_4_extension.ipynb,2026-01-14T18:29:54.588087,CellExecutionError,"An error occurred while executing the following cell:
------------------
class Model(nn.Module):
    def __init__(self, vocab):
        super(Model, self).__init__()
        self.sent_rep_size = word_hidden_size * 2  # 双向lstm，每个词向量对应的隐藏层维度
        self.doc_rep_size = sent_hidden_size * 2  # 文档表示大小，每个句子对应隐藏层的维度
        self.all_parameters = {}
        
        parameters = []
        self.word_encoder = WordLSTMEncoder(vocab)
        self.word_attention = Attention(self.sent_rep_size)
        # filter(判断函数, 可迭代对象)
        parameters.extend(list(filter(lambda p: p.requires_grad, self.word_encoder.parameters())))
        parameters.extend(list(filter(lambda p: p.requires_grad, self.word_attention.parameters())))
        self.sent_encoder = SentEncoder(self.sent_rep_size)
        self.sent_attention = Attention(self.doc_rep_size)
        parameters.extend(list(filter(lambda p: p.requires_grad, self.sent_encoder.parameters())))
        parameters.extend(list(filter(lambda p: p.requires_grad, self.sent_attention.parameters())))
        self.out = nn.Linear(self.doc_rep_size, vocab.label_size, bias=True)
        parameters.extend(list(filter(lambda p: p.requires_grad, self.out.parameters())))
        
        self.to(device)
        
        if len(parameters) > 0:
            self.all_parameters['basic_parameters'] = parameters
            
        # 模型总参数量
        para_num = sum([np.prod(list(p.size())) for p in self.parameters()])
        
    def forward(self, batch_inputs):
        # batch_inputs(batch_inputs1, batch_inputs2): b x doc_len x sent_len
        # batch_masks: b x doc_len x sent_len
        # 不明白为什么这里要同时输入两个batch？？？？？？？
        batch_inputs1, batch_inputs2, batch_masks = batch_inputs
        batch_size, max_doc_len, max_sent_len = batch_inputs1.shape[0], batch_inputs1.shape[1], batch_inputs1.shape[2]
        batch_inputs1 = batch_inputs1.view(batch_size * max_doc_len, max_sent_len)
        batch_inputs2 = batch_inputs2.view(batch_size * max_doc_len, max_sent_len)
        batch_masks = batch_masks.view(batch_size * max_doc_len, max_sent_len)
        batch_hiddens = self.word_encoder(batch_inputs1, batch_inputs2, batch_masks)
        sent_reps, atten_scores = self.word_attention(batch_hiddens, batch_masks)
        sent_reps = sent_reps.view(batch_size, max_doc_len, self.sent_rep_size)
        batch_masks = batch_masks.view(batch_size, max_doc_len, max_sent_len)
        sent_masks = batch_masks.bool().any(2).float()
        sent_hiddens = self.sent_encoder(sent_reps, sent_masks)
        doc_reps, atten_scores = self.sent_attention(sent_hiddens, sent_masks)
        batch_outputs = self.out(doc_reps)
        
        return batch_outputs
    
model = Model(vocab)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-16-9dcaca8d46d8>[0m in [0;36m<cell line: 49>[0;34m()[0m
[1;32m     47[0m         [0;32mreturn[0m [0mbatch_outputs[0m[0;34m[0m[0;34m[0m[0m
[1;32m     48[0m [0;34m[0m[0m
[0;32m---> 49[0;31m [0mmodel[0m [0;34m=[0m [0mModel[0m[0;34m([0m[0mvocab[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m<ipython-input-16-9dcaca8d46d8>[0m in [0;36m__init__[0;34m(self, vocab)[0m
[1;32m     16[0m         [0mparameters[0m[0;34m.[0m[0mextend[0m[0;34m([0m[0mlist[0m[0;34m([0m[0mfilter[0m[0;34m([0m[0;32mlambda[0m [0mp[0m[0;34m:[0m [0mp[0m[0;34m.[0m[0mrequires_grad[0m[0;34m,[0m [0mself[0m[0;34m.[0m[0msent_encoder[0m[0;34m.[0m[0mparameters[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     17[0m         [0mparameters[0m[0;34m.[0m[0mextend[0m[0;34m([0m[0mlist[0m[0;34m([0m[0mfilter[0m[0;34m([0m[0;32mlambda[0m [0mp[0m[0;34m:[0m [0mp[0m[0;34m.[0m[0mrequires_grad[0m[0;34m,[0m [0mself[0m[0;34m.[0m[0msent_attention[0m[0;34m.[0m[0mparameters[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 18[0;31m         [0mself[0m[0;34m.[0m[0mout[0m [0;34m=[0m [0mnn[0m[0;34m.[0m[0mLinear[0m[0;34m([0m[0mself[0m[0;34m.[0m[0mdoc_rep_size[0m[0;34m,[0m [0mvocab[0m[0;34m.[0m[0mlabel_size[0m[0;34m,[0m [0mbias[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     19[0m         [0mparameters[0m[0;34m.[0m[0mextend[0m[0;34m([0m[0mlist[0m[0;34m([0m[0mfilter[0m[0;34m([0m[0;32mlambda[0m [0mp[0m[0;34m:[0m [0mp[0m[0;34m.[0m[0mrequires_grad[0m[0;34m,[0m [0mself[0m[0;34m.[0m[0mout[0m[0;34m.[0m[0mparameters[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     20[0m [0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py[0m in [0;36m__init__[0;34m(self, in_features, out_features, bias, device, dtype)[0m
[1;32m     83[0m         [0mself[0m[0;34m.[0m[0min_features[0m [0;34m=[0m [0min_features[0m[0;34m[0m[0;34m[0m[0m
[1;32m     84[0m         [0mself[0m[0;34m.[0m[0mout_features[0m [0;34m=[0m [0mout_features[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 85[0;31m         [0mself[0m[0;34m.[0m[0mweight[0m [0;34m=[0m [0mParameter[0m[0;34m([0m[0mtorch[0m[0;34m.[0m[0mempty[0m[0;34m([0m[0;34m([0m[0mout_features[0m[0;34m,[0m [0min_features[0m[0;34m)[0m[0;34m,[0m [0;34m**[0m[0mfactory_kwargs[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     86[0m         [0;32mif[0m [0mbias[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     87[0m             [0mself[0m[0;34m.[0m[0mbias[0m [0;34m=[0m [0mParameter[0m[0;34m([0m[0mtorch[0m[0;34m.[0m[0mempty[0m[0;34m([0m[0mout_features[0m[0;34m,[0m [0;34m**[0m[0mfactory_kwargs[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mTypeError[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

",TypeError,"empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:"
/junobench_env/NBspecific_14/NBspecific_14_extension.ipynb,2026-01-14T18:30:00.675141,CellExecutionError,"An error occurred while executing the following cell:
------------------
from sklearn.ensemble import RandomForestClassifier

y = train_data[""Survived""]

features = [""Pclass"", ""Sex"", ""SibSp"", ""Parch"", ""Fare""]
X = pd.get_dummies(train_data[features])
X_test = pd.get_dummies(test_data[features])

model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)
model.fit(X, y)
predictions = model.predict(X_test)

output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})
output.to_csv('submission.csv', index=False)
print(""Your submission was successfully saved!"")
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-6-35e2f8bf0a65>[0m in [0;36m<cell line: 11>[0;34m()[0m
[1;32m      9[0m [0mmodel[0m [0;34m=[0m [0mRandomForestClassifier[0m[0;34m([0m[0mn_estimators[0m[0;34m=[0m[0;36m100[0m[0;34m,[0m [0mmax_depth[0m[0;34m=[0m[0;36m5[0m[0;34m,[0m [0mrandom_state[0m[0;34m=[0m[0;36m1[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     10[0m [0mmodel[0m[0;34m.[0m[0mfit[0m[0;34m([0m[0mX[0m[0;34m,[0m [0my[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 11[0;31m [0mpredictions[0m [0;34m=[0m [0mmodel[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mX_test[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     12[0m [0;34m[0m[0m
[1;32m     13[0m [0moutput[0m [0;34m=[0m [0mpd[0m[0;34m.[0m[0mDataFrame[0m[0;34m([0m[0;34m{[0m[0;34m'PassengerId'[0m[0;34m:[0m [0mtest_data[0m[0;34m.[0m[0mPassengerId[0m[0;34m,[0m [0;34m'Survived'[0m[0;34m:[0m [0mpredictions[0m[0;34m}[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36mpredict[0;34m(self, X)[0m
[1;32m    818[0m             [0mThe[0m [0mpredicted[0m [0mclasses[0m[0;34m.[0m[0;34m[0m[0;34m[0m[0m
[1;32m    819[0m         """"""
[0;32m--> 820[0;31m         [0mproba[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mpredict_proba[0m[0;34m([0m[0mX[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    821[0m [0;34m[0m[0m
[1;32m    822[0m         [0;32mif[0m [0mself[0m[0;34m.[0m[0mn_outputs_[0m [0;34m==[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36mpredict_proba[0;34m(self, X)[0m
[1;32m    860[0m         [0mcheck_is_fitted[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    861[0m         [0;31m# Check data[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 862[0;31m         [0mX[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_validate_X_predict[0m[0;34m([0m[0mX[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    863[0m [0;34m[0m[0m
[1;32m    864[0m         [0;31m# Assign chunk of trees to jobs[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py[0m in [0;36m_validate_X_predict[0;34m(self, X)[0m
[1;32m    600[0m         Validate X whenever one tries to predict, apply, predict_proba.""""""
[1;32m    601[0m         [0mcheck_is_fitted[0m[0;34m([0m[0mself[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 602[0;31m         [0mX[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_validate_data[0m[0;34m([0m[0mX[0m[0;34m,[0m [0mdtype[0m[0;34m=[0m[0mDTYPE[0m[0;34m,[0m [0maccept_sparse[0m[0;34m=[0m[0;34m""csr""[0m[0;34m,[0m [0mreset[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    603[0m         [0;32mif[0m [0missparse[0m[0;34m([0m[0mX[0m[0;34m)[0m [0;32mand[0m [0;34m([0m[0mX[0m[0;34m.[0m[0mindices[0m[0;34m.[0m[0mdtype[0m [0;34m!=[0m [0mnp[0m[0;34m.[0m[0mintc[0m [0;32mor[0m [0mX[0m[0;34m.[0m[0mindptr[0m[0;34m.[0m[0mdtype[0m [0;34m!=[0m [0mnp[0m[0;34m.[0m[0mintc[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    604[0m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m""No support for np.int64 index based sparse matrices""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py[0m in [0;36m_validate_data[0;34m(self, X, y, reset, validate_separately, **check_params)[0m
[1;32m    563[0m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m""Validation should be done on X, y or both.""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    564[0m         [0;32melif[0m [0;32mnot[0m [0mno_val_X[0m [0;32mand[0m [0mno_val_y[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 565[0;31m             [0mX[0m [0;34m=[0m [0mcheck_array[0m[0;34m([0m[0mX[0m[0;34m,[0m [0minput_name[0m[0;34m=[0m[0;34m""X""[0m[0;34m,[0m [0;34m**[0m[0mcheck_params[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    566[0m             [0mout[0m [0;34m=[0m [0mX[0m[0;34m[0m[0;34m[0m[0m
[1;32m    567[0m         [0;32melif[0m [0mno_val_X[0m [0;32mand[0m [0;32mnot[0m [0mno_val_y[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py[0m in [0;36mcheck_array[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)[0m
[1;32m    919[0m [0;34m[0m[0m
[1;32m    920[0m         [0;32mif[0m [0mforce_all_finite[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 921[0;31m             _assert_all_finite(
[0m[1;32m    922[0m                 [0marray[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    923[0m                 [0minput_name[0m[0;34m=[0m[0minput_name[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py[0m in [0;36m_assert_all_finite[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)[0m
[1;32m    159[0m                 [0;34m""#estimators-that-handle-nan-values""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    160[0m             )
[0;32m--> 161[0;31m         [0;32mraise[0m [0mValueError[0m[0;34m([0m[0mmsg_err[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    162[0m [0;34m[0m[0m
[1;32m    163[0m [0;34m[0m[0m

[0;31mValueError[0m: Input X contains NaN.
RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
ValueError: Input X contains NaN.
RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
",ValueError,Input X contains NaN.
/junobench_env/NBspecific_13/NBspecific_13_extension.ipynb,2026-01-14T18:30:14.944529,CellExecutionError,"An error occurred while executing the following cell:
------------------
y= df['output']
x = df.drop(['output'],axis = 1)
X_train , X_test, y_train , y_test = train_test_split(X,y)
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier
model.fit(X_train , y_train)
y_hat= model.predict (X_test)
print (accuracy_score (y_hat, y_test))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mTypeError[0m                                 Traceback (most recent call last)
[0;32m<ipython-input-33-89f36b1f32fa>[0m in [0;36m<cell line: 7>[0;34m()[0m
[1;32m      5[0m [0;34m[0m[0m
[1;32m      6[0m [0mmodel[0m [0;34m=[0m [0mDecisionTreeClassifier[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 7[0;31m [0mmodel[0m[0;34m.[0m[0mfit[0m[0;34m([0m[0mX_train[0m [0;34m,[0m [0my_train[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      8[0m [0my_hat[0m[0;34m=[0m [0mmodel[0m[0;34m.[0m[0mpredict[0m [0;34m([0m[0mX_test[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m [0mprint[0m [0;34m([0m[0maccuracy_score[0m [0;34m([0m[0my_hat[0m[0;34m,[0m [0my_test[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mTypeError[0m: DecisionTreeClassifier.fit() missing 1 required positional argument: 'y'
TypeError: DecisionTreeClassifier.fit() missing 1 required positional argument: 'y'
",TypeError,DecisionTreeClassifier.fit() missing 1 required positional argument: 'y'
/junobench_env/tensorflow_8/tensorflow_8_extension.ipynb,2026-01-14T18:30:29.039126,CellExecutionError,"An error occurred while executing the following cell:
------------------
os.mkdir('data/augmented')
# os.mkdir('data/augmented/benign')
# os.mkdir('data/augmented/malignant')
os.makedirs('data/augmented/benign', exist_ok=True)
os.makedirs('data/augmented/malignant', exist_ok=True)

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mFileExistsError[0m                           Traceback (most recent call last)
[0;32m<ipython-input-4-02f0c5c35e74>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mos[0m[0;34m.[0m[0mmkdir[0m[0;34m([0m[0;34m'data/augmented'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0;31m# os.mkdir('data/augmented/benign')[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0;31m# os.mkdir('data/augmented/malignant')[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0mos[0m[0;34m.[0m[0mmakedirs[0m[0;34m([0m[0;34m'data/augmented/benign'[0m[0;34m,[0m [0mexist_ok[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0mos[0m[0;34m.[0m[0mmakedirs[0m[0;34m([0m[0;34m'data/augmented/malignant'[0m[0;34m,[0m [0mexist_ok[0m[0;34m=[0m[0;32mTrue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mFileExistsError[0m: [Errno 17] File exists: 'data/augmented'
FileExistsError: [Errno 17] File exists: 'data/augmented'
",FileExistsError,[Errno 17] File exists: 'data/augmented'
/junobench_env/tensorflow_1/tensorflow_1_extension.ipynb,2026-01-14T18:30:46.606692,CellExecutionError,"An error occurred while executing the following cell:
------------------
# history = model.fit(train_ds,validation_data=val_ds, epochs=1)
history = model.fit(train_ds,validation_data=val_ds, epochs=epochs)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mInvalidArgumentError[0m                      Traceback (most recent call last)
[0;32m<ipython-input-19-d5b13aba279e>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;31m# history = model.fit(train_ds,validation_data=val_ds, epochs=1)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mhistory[0m [0;34m=[0m [0mmodel[0m[0;34m.[0m[0mfit[0m[0;34m([0m[0mtrain_ds[0m[0;34m,[0m[0mvalidation_data[0m[0;34m=[0m[0mval_ds[0m[0;34m,[0m [0mepochs[0m[0;34m=[0m[0mepochs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
[1;32m    120[0m             [0;31m# To get the full stack trace, call:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    121[0m             [0;31m# `keras.config.disable_traceback_filtering()`[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 122[0;31m             [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    123[0m         [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    124[0m             [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[1;32m     51[0m   [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     52[0m     [0mctx[0m[0;34m.[0m[0mensure_initialized[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 53[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
[0m[1;32m     54[0m                                         inputs, attrs, num_outputs)
[1;32m     55[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mInvalidArgumentError[0m: Graph execution error:

Detected at node decode_image/DecodeImage defined at (most recent call last):
<stack traces unavailable>
Unknown image file format. One of JPEG, PNG, GIF, BMP required.
	 [[{{node decode_image/DecodeImage}}]]
	 [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_4690]
InvalidArgumentError: Graph execution error:

Detected at node decode_image/DecodeImage defined at (most recent call last):
<stack traces unavailable>
Unknown image file format. One of JPEG, PNG, GIF, BMP required.
	 [[{{node decode_image/DecodeImage}}]]
	 [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_4690]
",InvalidArgumentError,Graph execution error:
/junobench_env/tensorflow_6/tensorflow_6_extension.ipynb,2026-01-14T18:32:31.101550,CellExecutionError,"An error occurred while executing the following cell:
------------------
model = keras.models.load_model(checkpoint_filepath)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-27-25b03261b4a9>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0mmodel[0m [0;34m=[0m [0mkeras[0m[0;34m.[0m[0mmodels[0m[0;34m.[0m[0mload_model[0m[0;34m([0m[0mcheckpoint_filepath[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py[0m in [0;36mload_model[0;34m(filepath, custom_objects, compile, safe_mode)[0m
[1;32m    191[0m         )
[1;32m    192[0m     [0;32melif[0m [0mstr[0m[0;34m([0m[0mfilepath[0m[0;34m)[0m[0;34m.[0m[0mendswith[0m[0;34m([0m[0;34m"".keras""[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 193[0;31m         raise ValueError(
[0m[1;32m    194[0m             [0;34mf""File not found: filepath={filepath}. ""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    195[0m             [0;34m""Please ensure the file is an accessible `.keras` ""[0m[0;34m[0m[0;34m[0m[0m

[0;31mValueError[0m: File not found: filepath=best_model.keras. Please ensure the file is an accessible `.keras` zip file.
ValueError: File not found: filepath=best_model.keras. Please ensure the file is an accessible `.keras` zip file.
",ValueError,File not found: filepath=best_model.keras. Please ensure the file is an accessible `.keras` zip file.
/junobench_env/NBspecific_15/NBspecific_15_extension.ipynb,2026-01-14T18:32:39.622642,CellExecutionError,"An error occurred while executing the following cell:
------------------
from google.colab import drive
drive.mount('/content/drive')
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNotImplementedError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-11-d5df0069828e>[0m in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [0;32mfrom[0m [0mgoogle[0m[0;34m.[0m[0mcolab[0m [0;32mimport[0m [0mdrive[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 2[0;31m [0mdrive[0m[0;34m.[0m[0mmount[0m[0;34m([0m[0;34m'/content/drive'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py[0m in [0;36mmount[0;34m(mountpoint, force_remount, timeout_ms, readonly)[0m
[1;32m     98[0m [0;32mdef[0m [0mmount[0m[0;34m([0m[0mmountpoint[0m[0;34m,[0m [0mforce_remount[0m[0;34m=[0m[0;32mFalse[0m[0;34m,[0m [0mtimeout_ms[0m[0;34m=[0m[0;36m120000[0m[0;34m,[0m [0mreadonly[0m[0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     99[0m   [0;34m""""""Mount your Google Drive at the specified mountpoint path.""""""[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 100[0;31m   return _mount(
[0m[1;32m    101[0m       [0mmountpoint[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    102[0m       [0mforce_remount[0m[0;34m=[0m[0mforce_remount[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py[0m in [0;36m_mount[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)[0m
[1;32m    116[0m   [0;34m""""""Internal helper to mount Google Drive.""""""[0m[0;34m[0m[0;34m[0m[0m
[1;32m    117[0m   [0;32mif[0m [0;32mnot[0m [0m_os[0m[0;34m.[0m[0mpath[0m[0;34m.[0m[0mexists[0m[0;34m([0m[0;34m'/var/colab/hostname'[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 118[0;31m     raise NotImplementedError(
[0m[1;32m    119[0m         [0;34m'Mounting drive is unsupported in this environment. Use PyDrive'[0m[0;34m[0m[0;34m[0m[0m
[1;32m    120[0m         [0;34m' instead. See examples at'[0m[0;34m[0m[0;34m[0m[0m

[0;31mNotImplementedError[0m: Mounting drive is unsupported in this environment. Use PyDrive instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.
NotImplementedError: Mounting drive is unsupported in this environment. Use PyDrive instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.
",NotImplementedError,Mounting drive is unsupported in this environment. Use PyDrive instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.
/junobench_env/torch_2/torch_2_extension.ipynb,2026-01-14T18:32:43.881208,CellExecutionError,"An error occurred while executing the following cell:
------------------
from torchvision.io import read_image
from torchvision.models import vit_b_16, ViT_B_16_Weights, list_models
from torchvision.datasets import ImageNet, ImageFolder
from torch.utils.data import DataLoader
from torchmetrics.classification import MulticlassAccuracy
import torch
import time
from torchvision.transforms import transforms
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-1-fd60bcbf1e25>[0m in [0;36m<cell line: 1>[0;34m()[0m
[0;32m----> 1[0;31m [0;32mfrom[0m [0mtorchvision[0m[0;34m.[0m[0mio[0m [0;32mimport[0m [0mread_image[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      2[0m [0;32mfrom[0m [0mtorchvision[0m[0;34m.[0m[0mmodels[0m [0;32mimport[0m [0mvit_b_16[0m[0;34m,[0m [0mViT_B_16_Weights[0m[0;34m,[0m [0mlist_models[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0;32mfrom[0m [0mtorchvision[0m[0;34m.[0m[0mdatasets[0m [0;32mimport[0m [0mImageNet[0m[0;34m,[0m [0mImageFolder[0m[0;34m[0m[0;34m[0m[0m
[1;32m      4[0m [0;32mfrom[0m [0mtorch[0m[0;34m.[0m[0mutils[0m[0;34m.[0m[0mdata[0m [0;32mimport[0m [0mDataLoader[0m[0;34m[0m[0;34m[0m[0m
[1;32m      5[0m [0;32mfrom[0m [0mtorchmetrics[0m[0;34m.[0m[0mclassification[0m [0;32mimport[0m [0mMulticlassAccuracy[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py[0m in [0;36m<module>[0;34m[0m
[1;32m      8[0m [0;31m# .extensions) before entering _meta_registrations.[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m [0;32mfrom[0m [0;34m.[0m[0mextension[0m [0;32mimport[0m [0m_HAS_OPS[0m  [0;31m# usort:skip[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 10[0;31m [0;32mfrom[0m [0mtorchvision[0m [0;32mimport[0m [0m_meta_registrations[0m[0;34m,[0m [0mdatasets[0m[0;34m,[0m [0mio[0m[0;34m,[0m [0mmodels[0m[0;34m,[0m [0mops[0m[0;34m,[0m [0mtransforms[0m[0;34m,[0m [0mutils[0m  [0;31m# usort:skip[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     11[0m [0;34m[0m[0m
[1;32m     12[0m [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/_meta_registrations.py[0m in [0;36m<module>[0;34m[0m
[1;32m      2[0m [0;34m[0m[0m
[1;32m      3[0m [0;32mimport[0m [0mtorch[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m [0;32mimport[0m [0mtorch[0m[0;34m.[0m[0m_custom_ops[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0;32mimport[0m [0mtorch[0m[0;34m.[0m[0mlibrary[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m [0;34m[0m[0m

[0;31mModuleNotFoundError[0m: No module named 'torch._custom_ops'
ModuleNotFoundError: No module named 'torch._custom_ops'
",ModuleNotFoundError,No module named 'torch._custom_ops'
/junobench_env/torch_5/torch_5_extension.ipynb,2026-01-14T18:32:47.621035,CellExecutionError,"An error occurred while executing the following cell:
------------------
import os, time
import numpy as np
import random
random.seed(42)
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report

import torch
torch.manual_seed(42)
from torch import nn
from torch.optim import SGD, Adam
from torch.utils.data import DataLoader, RandomSampler
from torch.utils.data.dataset import Dataset
from torchvision.models import resnet
from torchvision import transforms, datasets, models
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torch
import torch.nn as nn
import torchvision
import torch.nn.functional as F
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-1-6a55ac603f3b>[0m in [0;36m<cell line: 16>[0;34m()[0m
[1;32m     14[0m [0;32mfrom[0m [0mtorch[0m[0;34m.[0m[0mutils[0m[0;34m.[0m[0mdata[0m [0;32mimport[0m [0mDataLoader[0m[0;34m,[0m [0mRandomSampler[0m[0;34m[0m[0;34m[0m[0m
[1;32m     15[0m [0;32mfrom[0m [0mtorch[0m[0;34m.[0m[0mutils[0m[0;34m.[0m[0mdata[0m[0;34m.[0m[0mdataset[0m [0;32mimport[0m [0mDataset[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 16[0;31m [0;32mfrom[0m [0mtorchvision[0m[0;34m.[0m[0mmodels[0m [0;32mimport[0m [0mresnet[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     17[0m [0;32mfrom[0m [0mtorchvision[0m [0;32mimport[0m [0mtransforms[0m[0;34m,[0m [0mdatasets[0m[0;34m,[0m [0mmodels[0m[0;34m[0m[0;34m[0m[0m
[1;32m     18[0m [0;32mfrom[0m [0mtorch[0m[0;34m.[0m[0moptim[0m[0;34m.[0m[0mlr_scheduler[0m [0;32mimport[0m [0mReduceLROnPlateau[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py[0m in [0;36m<module>[0;34m[0m
[1;32m      8[0m [0;31m# .extensions) before entering _meta_registrations.[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m [0;32mfrom[0m [0;34m.[0m[0mextension[0m [0;32mimport[0m [0m_HAS_OPS[0m  [0;31m# usort:skip[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 10[0;31m [0;32mfrom[0m [0mtorchvision[0m [0;32mimport[0m [0m_meta_registrations[0m[0;34m,[0m [0mdatasets[0m[0;34m,[0m [0mio[0m[0;34m,[0m [0mmodels[0m[0;34m,[0m [0mops[0m[0;34m,[0m [0mtransforms[0m[0;34m,[0m [0mutils[0m  [0;31m# usort:skip[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     11[0m [0;34m[0m[0m
[1;32m     12[0m [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/_meta_registrations.py[0m in [0;36m<module>[0;34m[0m
[1;32m      2[0m [0;34m[0m[0m
[1;32m      3[0m [0;32mimport[0m [0mtorch[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m [0;32mimport[0m [0mtorch[0m[0;34m.[0m[0m_custom_ops[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0;32mimport[0m [0mtorch[0m[0;34m.[0m[0mlibrary[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m [0;34m[0m[0m

[0;31mModuleNotFoundError[0m: No module named 'torch._custom_ops'
ModuleNotFoundError: No module named 'torch._custom_ops'
",ModuleNotFoundError,No module named 'torch._custom_ops'
/junobench_env/tensorflow_7/tensorflow_7_extension.ipynb,2026-01-14T18:34:09.292536,DeadKernelError,Kernel died,,
/junobench_env/tensorflow_9/tensorflow_9_extension.ipynb,2026-01-14T18:34:36.019327,CellExecutionError,"An error occurred while executing the following cell:
------------------
# input_ids = torch.tensor(bert_input.input_ids)
# attention_mask = torch.tensor(bert_input.attention_mask)
input_ids = bert_input.input_ids.squeeze(0)
attention_mask = bert_input.attention_mask.squeeze(0)

bert_model = BertModel.from_pretrained('bert-base-uncased')
last_hidden_state, pooled_output = bert_model(input_ids=input_ids, attention_mask=attention_mask, return_dict =False)

print(last_hidden_state.shape)
print(bert_model.config.hidden_size)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-20-fa5d9cf12f0a>[0m in [0;36m<cell line: 7>[0;34m()[0m
[1;32m      5[0m [0;34m[0m[0m
[1;32m      6[0m [0mbert_model[0m [0;34m=[0m [0mBertModel[0m[0;34m.[0m[0mfrom_pretrained[0m[0;34m([0m[0;34m'bert-base-uncased'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 7[0;31m [0mlast_hidden_state[0m[0;34m,[0m [0mpooled_output[0m [0;34m=[0m [0mbert_model[0m[0;34m([0m[0minput_ids[0m[0;34m=[0m[0minput_ids[0m[0;34m,[0m [0mattention_mask[0m[0;34m=[0m[0mattention_mask[0m[0;34m,[0m [0mreturn_dict[0m [0;34m=[0m[0;32mFalse[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      8[0m [0;34m[0m[0m
[1;32m      9[0m [0mprint[0m[0;34m([0m[0mlast_hidden_state[0m[0;34m.[0m[0mshape[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py[0m in [0;36m_call_impl[0;34m(self, *input, **kwargs)[0m
[1;32m   1108[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
[1;32m   1109[0m                 or _global_forward_hooks or _global_forward_pre_hooks):
[0;32m-> 1110[0;31m             [0;32mreturn[0m [0mforward_call[0m[0;34m([0m[0;34m*[0m[0minput[0m[0;34m,[0m [0;34m**[0m[0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1111[0m         [0;31m# Do not call functions when jit is used[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1112[0m         [0mfull_backward_hooks[0m[0;34m,[0m [0mnon_full_backward_hooks[0m [0;34m=[0m [0;34m[[0m[0;34m][0m[0;34m,[0m [0;34m[[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py[0m in [0;36mforward[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)[0m
[1;32m   1061[0m             [0;32mraise[0m [0mValueError[0m[0;34m([0m[0;34m""You have to specify either input_ids or inputs_embeds""[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1062[0m [0;34m[0m[0m
[0;32m-> 1063[0;31m         [0mbatch_size[0m[0;34m,[0m [0mseq_length[0m [0;34m=[0m [0minput_shape[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   1064[0m         [0mdevice[0m [0;34m=[0m [0minput_ids[0m[0;34m.[0m[0mdevice[0m [0;32mif[0m [0minput_ids[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m [0;32melse[0m [0minputs_embeds[0m[0;34m.[0m[0mdevice[0m[0;34m[0m[0;34m[0m[0m
[1;32m   1065[0m [0;34m[0m[0m

[0;31mValueError[0m: not enough values to unpack (expected 2, got 1)
ValueError: not enough values to unpack (expected 2, got 1)
",ValueError,"not enough values to unpack (expected 2, got 1)"
/junobench_env/pandas_10/pandas_10_extension.ipynb,2026-01-14T18:34:39.900184,RuntimeError,Kernel didn't respond in 60 seconds,,
/junobench_env/matplotlib_6/matplotlib_6_extension.ipynb,2026-01-14T18:37:52.027731,CellExecutionError,"An error occurred while executing the following cell:
------------------
sns.set_style('darkgrid')
fig, ax = plt.subplots(6,1, figsize=(20, 45))#Original was 9,1
for i, col in enumerate(list(df.columns)):
    axes_hist = ax[i]
    sns.histplot(data=df, x=col, ax=axes_hist,color = '#a5c687', stat = ""density"",edgecolor='#ff1195')
    sns.kdeplot(x = col, data = df,ax=axes_hist, color = '#5678f1', linewidth = 5)
    ax[i].set_title(col,fontsize=35,color='#561195')
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mIndexError[0m                                Traceback (most recent call last)
[0;32m<ipython-input-14-cf1281bad4c0>[0m in [0;36m<cell line: 3>[0;34m()[0m
[1;32m      2[0m [0mfig[0m[0;34m,[0m [0max[0m [0;34m=[0m [0mplt[0m[0;34m.[0m[0msubplots[0m[0;34m([0m[0;36m6[0m[0;34m,[0m[0;36m1[0m[0;34m,[0m [0mfigsize[0m[0;34m=[0m[0;34m([0m[0;36m20[0m[0;34m,[0m [0;36m45[0m[0;34m)[0m[0;34m)[0m[0;31m#Original was 9,1[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0;32mfor[0m [0mi[0m[0;34m,[0m [0mcol[0m [0;32min[0m [0menumerate[0m[0;34m([0m[0mlist[0m[0;34m([0m[0mdf[0m[0;34m.[0m[0mcolumns[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m     [0maxes_hist[0m [0;34m=[0m [0max[0m[0;34m[[0m[0mi[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m     [0msns[0m[0;34m.[0m[0mhistplot[0m[0;34m([0m[0mdata[0m[0;34m=[0m[0mdf[0m[0;34m,[0m [0mx[0m[0;34m=[0m[0mcol[0m[0;34m,[0m [0max[0m[0;34m=[0m[0maxes_hist[0m[0;34m,[0m[0mcolor[0m [0;34m=[0m [0;34m'#a5c687'[0m[0;34m,[0m [0mstat[0m [0;34m=[0m [0;34m""density""[0m[0;34m,[0m[0medgecolor[0m[0;34m=[0m[0;34m'#ff1195'[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m     [0msns[0m[0;34m.[0m[0mkdeplot[0m[0;34m([0m[0mx[0m [0;34m=[0m [0mcol[0m[0;34m,[0m [0mdata[0m [0;34m=[0m [0mdf[0m[0;34m,[0m[0max[0m[0;34m=[0m[0maxes_hist[0m[0;34m,[0m [0mcolor[0m [0;34m=[0m [0;34m'#5678f1'[0m[0;34m,[0m [0mlinewidth[0m [0;34m=[0m [0;36m5[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

[0;31mIndexError[0m: index 6 is out of bounds for axis 0 with size 6
IndexError: index 6 is out of bounds for axis 0 with size 6
",IndexError,index 6 is out of bounds for axis 0 with size 6
/junobench_env/matplotlib_1/matplotlib_1_extension.ipynb,2026-01-14T18:42:48.157654,CellExecutionError,"An error occurred while executing the following cell:
------------------
from tensorflow import keras 
train_folder = ""../input/intel-image-classification/seg_train/seg_train"" 
test_folder = ""../input/intel-image-classification/seg_test/seg_test"" 
train_ds = keras.utils.image_dataset_from_directory(directory=train_folder, labels=""inferred"", label_mode=""int"", color_mode=""rgb"", batch_size=32, image_size=(150, 150), validation_split=0.25, subset=""training"", seed=123) 
val_ds = keras.utils.image_dataset_from_directory(directory=train_folder, labels=""inferred"", label_mode=""int"", color_mode=""rgb"", batch_size=32, image_size=(150, 150), validation_split=0.25, subset=""validation"", seed=123) 
test_ds = keras.utils.image_dataset_from_directory(directory=test_folder, labels=""inferred"", 
                                                   # Added for clarity and robustness 
                                                   label_mode=""int"", 
                                                   # Added for clarity and robustness 
                                                   color_mode=""rgb"", batch_size=32, image_size=(150, 150))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNotFoundError[0m                             Traceback (most recent call last)
[0;32m<ipython-input-11-204f2a872b0a>[0m in [0;36m<cell line: 4>[0;34m()[0m
[1;32m      2[0m [0mtrain_folder[0m [0;34m=[0m [0;34m""../input/intel-image-classification/seg_train/seg_train""[0m[0;34m[0m[0;34m[0m[0m
[1;32m      3[0m [0mtest_folder[0m [0;34m=[0m [0;34m""../input/intel-image-classification/seg_test/seg_test""[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 4[0;31m [0mtrain_ds[0m [0;34m=[0m [0mkeras[0m[0;34m.[0m[0mutils[0m[0;34m.[0m[0mimage_dataset_from_directory[0m[0;34m([0m[0mdirectory[0m[0;34m=[0m[0mtrain_folder[0m[0;34m,[0m [0mlabels[0m[0;34m=[0m[0;34m""inferred""[0m[0;34m,[0m [0mlabel_mode[0m[0;34m=[0m[0;34m""int""[0m[0;34m,[0m [0mcolor_mode[0m[0;34m=[0m[0;34m""rgb""[0m[0;34m,[0m [0mbatch_size[0m[0;34m=[0m[0;36m32[0m[0;34m,[0m [0mimage_size[0m[0;34m=[0m[0;34m([0m[0;36m150[0m[0;34m,[0m [0;36m150[0m[0;34m)[0m[0;34m,[0m [0mvalidation_split[0m[0;34m=[0m[0;36m0.25[0m[0;34m,[0m [0msubset[0m[0;34m=[0m[0;34m""training""[0m[0;34m,[0m [0mseed[0m[0;34m=[0m[0;36m123[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      5[0m [0mval_ds[0m [0;34m=[0m [0mkeras[0m[0;34m.[0m[0mutils[0m[0;34m.[0m[0mimage_dataset_from_directory[0m[0;34m([0m[0mdirectory[0m[0;34m=[0m[0mtrain_folder[0m[0;34m,[0m [0mlabels[0m[0;34m=[0m[0;34m""inferred""[0m[0;34m,[0m [0mlabel_mode[0m[0;34m=[0m[0;34m""int""[0m[0;34m,[0m [0mcolor_mode[0m[0;34m=[0m[0;34m""rgb""[0m[0;34m,[0m [0mbatch_size[0m[0;34m=[0m[0;36m32[0m[0;34m,[0m [0mimage_size[0m[0;34m=[0m[0;34m([0m[0;36m150[0m[0;34m,[0m [0;36m150[0m[0;34m)[0m[0;34m,[0m [0mvalidation_split[0m[0;34m=[0m[0;36m0.25[0m[0;34m,[0m [0msubset[0m[0;34m=[0m[0;34m""validation""[0m[0;34m,[0m [0mseed[0m[0;34m=[0m[0;36m123[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m      6[0m test_ds = keras.utils.image_dataset_from_directory(directory=test_folder, labels=""inferred"", 

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset_utils.py[0m in [0;36mimage_dataset_from_directory[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)[0m
[1;32m    221[0m     [0;32mif[0m [0mseed[0m [0;32mis[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    222[0m         [0mseed[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mrandom[0m[0;34m.[0m[0mrandint[0m[0;34m([0m[0;36m1e6[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 223[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(
[0m[1;32m    224[0m         [0mdirectory[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    225[0m         [0mlabels[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/dataset_utils.py[0m in [0;36mindex_directory[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)[0m
[1;32m    528[0m     [0;32mif[0m [0mlabels[0m [0;34m==[0m [0;34m""inferred""[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    529[0m         [0msubdirs[0m [0;34m=[0m [0;34m[[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 530[0;31m         [0;32mfor[0m [0msubdir[0m [0;32min[0m [0msorted[0m[0;34m([0m[0mtf[0m[0;34m.[0m[0mio[0m[0;34m.[0m[0mgfile[0m[0;34m.[0m[0mlistdir[0m[0;34m([0m[0mdirectory[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    531[0m             [0;32mif[0m [0mtf[0m[0;34m.[0m[0mio[0m[0;34m.[0m[0mgfile[0m[0;34m.[0m[0misdir[0m[0;34m([0m[0mtf[0m[0;34m.[0m[0mio[0m[0;34m.[0m[0mgfile[0m[0;34m.[0m[0mjoin[0m[0;34m([0m[0mdirectory[0m[0;34m,[0m [0msubdir[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    532[0m                 [0;32mif[0m [0;32mnot[0m [0msubdir[0m[0;34m.[0m[0mstartswith[0m[0;34m([0m[0;34m"".""[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py[0m in [0;36mlist_directory_v2[0;34m(path)[0m
[1;32m    766[0m   """"""
[1;32m    767[0m   [0;32mif[0m [0;32mnot[0m [0mis_directory[0m[0;34m([0m[0mpath[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 768[0;31m     raise errors.NotFoundError(
[0m[1;32m    769[0m         [0mnode_def[0m[0;34m=[0m[0;32mNone[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[1;32m    770[0m         [0mop[0m[0;34m=[0m[0;32mNone[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

[0;31mNotFoundError[0m: Could not find directory ../input/intel-image-classification/seg_train/seg_train
NotFoundError: Could not find directory ../input/intel-image-classification/seg_train/seg_train
",NotFoundError,Could not find directory ../input/intel-image-classification/seg_train/seg_train