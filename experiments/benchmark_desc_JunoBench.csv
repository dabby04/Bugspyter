nb_name,eid,ename,evalue,traceback,label_root_cause,label_refined_exp_type,label_ML_pipeline,label_if_ML_bug,DatasetTitle_1,DatasetTitle_2,DatasetLicenseName_1,DatasetLicenseName_2,DatasetUrl_1,DatasetUrl_2,NotebookUrl
NBspecific_1,dac09c73-577f-3d5d-834b-45942405eabb,nameerror,name 'tf_idf' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', '/tmp/ipykernel_1018/1279619201.py in <module>\n----> 1 tf_idf.toarray()\n', ""NameError: name 'tf_idf' is not defined""]",NB specific,variable not found,data preparation,ML bug,IMDB Dataset of 50K Movie Reviews,,Allow academic research,,https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews,,https://www.kaggle.com/code/pradeepparida/imdb-dataset
NBspecific_2,86d3fc43-5a6a-3e80-94ef-e82ea833017b,nameerror,name 'X_train' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', ""<ipython-input-3-6b970bf11e02> in <module>\n      3 classifier = XGBClassifier(tree_method='gp_hist', gpu_id=0)\n      4 \n----> 5 classifier.fit(X_train, y_train)\n      6 y_hat = classifier.predict(X_test)\n      7 accuracy_score(y_test, y_hat)\n"", ""NameError: name 'X_train' is not defined""]",NB specific,variable not found,training,ML bug,Fashion MNIST,,MIT,,https://www.kaggle.com/datasets/zalando-research/fashionmnist,,https://www.kaggle.com/code/salomonokn/exercice-zalando
NBspecific_3,698da925-8121-3961-92ac-9445e54cad54,valueerror,"operands could not be broadcast together with shapes (68,) (272,) ","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/1513200142.py in <module>\n      4 SST = sum((y_test-yMean)**2)  # SST: ????\n      5 SSR = sum((yFit-yMean)**2)  # SSR: ?????\n----> 6 SSE = sum((y_test-yFit)**2)  # SSE: ?????\n      7 Fstats = (SSR/m) / (SSE/(n-m-1))  # F ???\n      8 probFstats = stats.f.sf(Fstats, m, n-m-1)  # F??? P?\n', 'ValueError: operands could not be broadcast together with shapes (68,) (272,) ']",NB specific,unsupported broadcast,evaluation/prediction,ML bug,mywordle_data,,Unknown,,https://www.kaggle.com/datasets/dhuwly/mywordle-data,,https://www.kaggle.com/code/senorisky/mcm2023-c-1-b-lr
NBspecific_4,f69e2754-c8c7-3e98-9f18-494fc9674d4d,nameerror,name 'sns' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', ""/tmp/ipykernel_27/106132795.py in <module>\n----> 1 sns.set_context('talk', font_scale=.9)\n      2 # Exemple des types d'analyse qui peuvent être effectués\n      3 \n      4 # Count plot nous aide à visualiser le nombre d'éléments par catégorie\n      5 sns.countplot(data=dataset, x='Sex', hue='Risk')\n"", ""NameError: name 'sns' is not defined""]",NB specific,module not found,data visualization,ML bug,German Credit Risk - With Target,,CC0: Public Domain,,https://www.kaggle.com/datasets/kabure/german-credit-data-with-risk,,https://www.kaggle.com/code/diegoeliascosta/mgl7811-germancreditreport
NBspecific_5,1ca74ad2-3814-3ec8-add0-17046e7be5ae,keyerror,"""['num_outbound_cmds'] not found in axis""","['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', ""<ipython-input-21-4356dc8164e0> in <module>\n      1 #column 'num_outbound_cmds' is zero everywhere, we will delete it\n----> 2 df.drop(columns='num_outbound_cmds', inplace=True)\n      3 \n      4 #remove from list of numeric columns\n      5 numeric_columns.remove('num_outbound_cmds')\n"", '/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in drop(self, labels, axis, index, columns, level, inplace, errors)\n   4167             level=level,\n   4168             inplace=inplace,\n-> 4169             errors=errors,\n   4170         )\n   4171 \n', '/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in drop(self, labels, axis, index, columns, level, inplace, errors)\n   3882         for axis, labels in axes.items():\n   3883             if labels is not None:\n-> 3884                 obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n   3885 \n   3886         if inplace:\n', '/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in _drop_axis(self, labels, axis, level, errors)\n   3916                 new_axis = axis.drop(labels, level=level, errors=errors)\n   3917             else:\n-> 3918                 new_axis = axis.drop(labels, errors=errors)\n   3919             result = self.reindex(**{axis_name: new_axis})\n   3920 \n', '/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py in drop(self, labels, errors)\n   5276         if mask.any():\n   5277             if errors != ""ignore"":\n-> 5278                 raise KeyError(f""{labels[mask]} not found in axis"")\n   5279             indexer = indexer[~mask]\n   5280         return self.delete(indexer)\n', 'KeyError: ""[\'num_outbound_cmds\'] not found in axis""']",NB specific,key error,data preparation,ML bug,NSL-KDD,,Unknown,,https://www.kaggle.com/datasets/kiranmahesh/nslkdd,,https://www.kaggle.com/code/rafik1992/attacks-detection-using-cnn
NBspecific_6,a4bec0b5-5bfe-35ed-8f24-eebeb07b1e4b,nameerror,name 'history' is not defined,"---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-17-91c7d6fec2eb> in <cell line: 1>()
----> 1 plt.plot(history.history['accuracy'],label='Train Accuracy')
      2 plt.plot(history.history['val_accuracy'],label='Validation Accuracy')
      3 plt.title('Accuracy Per epoch')
      4 plt.ylabel('Accuracy')
      5 plt.xlabel('Epoch')

NameError: name 'history' is not defined",NB specific,variable not found,evaluation/prediction,ML bug,Bitcoin Limit Order Book (LOB) Data,,GPL 2,,https://www.kaggle.com/datasets/siavashraz/bitcoin-perpetualbtcusdtp-limit-order-book-data,,https://www.kaggle.com/code/siavashraz/implmenting-deeplob-model-on-bitcoin-perpetual
NBspecific_7,f7c4f578-8411-3c44-b3a3-08301d1c4216,keyerror,%percent emission',"['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', ""/tmp/ipykernel_27/3431530099.py in <module>\n----> 1 df6=df.groupby('region').get_group('Asia Pacific').sort_values(by='%percent emission')\n"", '/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs)\n    309                     stacklevel=stacklevel,\n    310                 )\n--> 311             return func(*args, **kwargs)\n    312 \n    313         return wrapper\n', '/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in sort_values(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\n   6257 \n   6258             by = by[0]\n-> 6259             k = self._get_label_or_level_values(by, axis=axis)\n   6260 \n   6261             # need to rewrap column in Series to apply key function\n', '/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in _get_label_or_level_values(self, key, axis)\n   1777             values = self.axes[axis].get_level_values(key)._values\n   1778         else:\n-> 1779             raise KeyError(key)\n   1780 \n   1781         # Check for duplicates\n', ""KeyError: '%percent emission'""]",NB specific,key error,data visualization,ML bug,Global Emissions.,,CC0: Public Domain,,https://www.kaggle.com/datasets/ashishraut64/global-methane-emissions,,https://www.kaggle.com/code/varshajais123/global-emission-eda
NBspecific_8,3517dfa8-7421-3564-ba41-65b343e95418,keyerror,'Amount',"['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653, in Index.get_loc(self, key)\n   3652 try:\n-> 3653     return self._engine.get_loc(casted_key)\n   3654 except KeyError as err:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:147, in pandas._libs.index.IndexEngine.get_loc()\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:176, in pandas._libs.index.IndexEngine.get_loc()\n', 'File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n', 'File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n', ""KeyError: 'Amount'"", '\nThe above exception was the direct cause of the following exception:\n', 'KeyError                                  Traceback (most recent call last)', ""Cell In[17], line 2\n      1 from sklearn.preprocessing import StandardScaler\n----> 2 df['scaled_Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n      3 df = df.drop(['Amount'],axis=1)\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3761, in DataFrame.__getitem__(self, key)\n   3759 if self.columns.nlevels > 1:\n   3760     return self._getitem_multilevel(key)\n-> 3761 indexer = self.columns.get_loc(key)\n   3762 if is_integer(indexer):\n   3763     indexer = [indexer]\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655, in Index.get_loc(self, key)\n   3653     return self._engine.get_loc(casted_key)\n   3654 except KeyError as err:\n-> 3655     raise KeyError(key) from err\n   3656 except TypeError:\n   3657     # If we have a listlike key, _check_indexing_error will raise\n   3658     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3659     #  the TypeError.\n   3660     self._check_indexing_error(key)\n', ""KeyError: 'Amount'""]",NB specific,key error,data preparation,ML bug,Credit Card Fraud Detection,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud,,https://www.kaggle.com/code/aloksingh00001/fraud-detection-with-naive-bayes-classifier
NBspecific_9,57b33894-a3e2-3e0a-9d5e-be7f993cdee9,keyerror,'[10472] not found in axis',"['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', '/tmp/ipykernel_28/756187615.py in <module>\n----> 1 df.drop([10472],inplace = True);\n', '/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs)\n    309                     stacklevel=stacklevel,\n    310                 )\n--> 311             return func(*args, **kwargs)\n    312 \n    313         return wrapper\n', '/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in drop(self, labels, axis, index, columns, level, inplace, errors)\n   4911             level=level,\n   4912             inplace=inplace,\n-> 4913             errors=errors,\n   4914         )\n   4915 \n', '/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in drop(self, labels, axis, index, columns, level, inplace, errors)\n   4148         for axis, labels in axes.items():\n   4149             if labels is not None:\n-> 4150                 obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n   4151 \n   4152         if inplace:\n', '/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in _drop_axis(self, labels, axis, level, errors)\n   4183                 new_axis = axis.drop(labels, level=level, errors=errors)\n   4184             else:\n-> 4185                 new_axis = axis.drop(labels, errors=errors)\n   4186             result = self.reindex(**{axis_name: new_axis})\n   4187 \n', '/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py in drop(self, labels, errors)\n   6015         if mask.any():\n   6016             if errors != ""ignore"":\n-> 6017                 raise KeyError(f""{labels[mask]} not found in axis"")\n   6018             indexer = indexer[~mask]\n   6019         return self.delete(indexer)\n', ""KeyError: '[10472] not found in axis'""]",NB specific,key error,data preparation,ML bug,Google Play Store Apps,,Unknown,,https://www.kaggle.com/datasets/lava18/google-play-store-apps,,https://www.kaggle.com/code/nithyak7/google-play-store-analysis
NBspecific_10,6b1b4ed3-15c6-3c41-8afc-b6920d23d305,indexerror,"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices","['---------------------------------------------------------------------------', 'IndexError                                Traceback (most recent call last)', ""/tmp/ipykernel_23/1766986922.py in <module>\n      2 from statsmodels.tsa.stattools import adfuller\n      3 \n----> 4 check_stationarity(train['ActivePower'])\n"", 'IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices']",NB specific,index error,data preparation,ML bug,Wind Power Forecasting,,CC0: Public Domain,,https://www.kaggle.com/datasets/theforcecoder/wind-power-forecasting,,https://www.kaggle.com/code/anand1994sp/wind-electricity-forecasting-11model-anand
NBspecific_11,3ed26d39-0497-32e2-9470-074abb0d90af,typeerror,"Invalid shape (3, 224, 224) for image data","['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[36], line 1\n----> 1 plt.imshow(adv)\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:2695, in imshow(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\n   2690     return gca().minorticks_off()\n   2693 # Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\n   2694 @_copy_docstring_and_deprecators(Axes.minorticks_on)\n-> 2695 def minorticks_on():\n   2696     return gca().minorticks_on()\n   2699 # Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py:1442, in inner(ax, data, *args, **kwargs)\n   1440 inner.__doc__ = _add_data_doc(inner.__doc__, replace_names)\n   1441 inner.__signature__ = new_sig\n-> 1442 return inner\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5665, in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\n   5628 @_preprocess_data()\n   5629 @docstring.dedent_interpd\n   5630 def pcolor(self, *args, shading=None, alpha=None, norm=None, cmap=None,\n   5631            vmin=None, vmax=None, **kwargs):\n   5632     r""""""\n   5633     Create a pseudocolor plot with a non-regular rectangular grid.\n   5634 \n   5635     Call signature::\n   5636 \n   5637         pcolor([X, Y,] C, **kwargs)\n   5638 \n   5639     *X* and *Y* can be used to specify the corners of the quadrilaterals.\n   5640 \n   5641     .. hint::\n   5642 \n   5643         ``pcolor()`` can be very slow for large arrays. In most\n   5644         cases you should use the similar but much faster\n   5645         `~.Axes.pcolormesh` instead. See\n   5646         :ref:`Differences between pcolor() and pcolormesh()\n   5647         <differences-pcolor-pcolormesh>` for a discussion of the\n   5648         differences.\n   5649 \n   5650     Parameters\n   5651     ----------\n   5652     C : 2D array-like\n   5653         The color-mapped values.\n   5654 \n   5655     X, Y : array-like, optional\n   5656         The coordinates of the corners of quadrilaterals of a pcolormesh::\n   5657 \n   5658             (X[i+1, j], Y[i+1, j])       (X[i+1, j+1], Y[i+1, j+1])\n   5659                                   +-----+\n   5660                                   |     |\n   5661                                   +-----+\n   5662                 (X[i, j], Y[i, j])       (X[i, j+1], Y[i, j+1])\n   5663 \n   5664         Note that the column index corresponds to the x-coordinate, and\n-> 5665         the row index corresponds to y. For details, see the\n   5666         :ref:`Notes <axes-pcolormesh-grid-orientation>` section below.\n   5667 \n   5668         If ``shading=\'flat\'`` the dimensions of *X* and *Y* should be one\n   5669         greater than those of *C*, and the quadrilateral is colored due\n   5670         to the value at ``C[i, j]``.  If *X*, *Y* and *C* have equal\n   5671         dimensions, a warning will be raised and the last row and column\n   5672         of *C* will be ignored.\n   5673 \n   5674         If ``shading=\'nearest\'``, the dimensions of *X* and *Y* should be\n   5675         the same as those of *C* (if not, a ValueError will be raised). The\n   5676         color ``C[i, j]`` will be centered on ``(X[i, j], Y[i, j])``.\n   5677 \n   5678         If *X* and/or *Y* are 1-D arrays or column vectors they will be\n   5679         expanded as needed into the appropriate 2D arrays, making a\n   5680         rectangular grid.\n   5681 \n   5682     shading : {\'flat\', \'nearest\', \'auto\'}, default: :rc:`pcolor.shading`\n   5683         The fill style for the quadrilateral. Possible values:\n   5684 \n   5685         - \'flat\': A solid color is used for each quad. The color of the\n   5686           quad (i, j), (i+1, j), (i, j+1), (i+1, j+1) is given by\n   5687           ``C[i, j]``. The dimensions of *X* and *Y* should be\n   5688           one greater than those of *C*; if they are the same as *C*,\n   5689           then a deprecation warning is raised, and the last row\n   5690           and column of *C* are dropped.\n   5691         - \'nearest\': Each grid point will have a color centered on it,\n   5692           extending halfway between the adjacent grid centers.  The\n   5693           dimensions of *X* and *Y* must be the same as *C*.\n   5694         - \'auto\': Choose \'flat\' if dimensions of *X* and *Y* are one\n   5695           larger than *C*.  Choose \'nearest\' if dimensions are the same.\n   5696 \n   5697         See :doc:`/gallery/images_contours_and_fields/pcolormesh_grids`\n   5698         for more description.\n   5699 \n   5700     cmap : str or `~matplotlib.colors.Colormap`, default: :rc:`image.cmap`\n   5701         A Colormap instance or registered colormap name. The colormap\n   5702         maps the *C* values to colors.\n   5703 \n   5704     norm : `~matplotlib.colors.Normalize`, optional\n   5705         The Normalize instance scales the data values to the canonical\n   5706         colormap range [0, 1] for mapping to colors. By default, the data\n   5707         range is mapped to the colorbar range using linear scaling.\n   5708 \n   5709     vmin, vmax : float, default: None\n   5710         The colorbar range. If *None*, suitable min/max values are\n   5711         automatically chosen by the `.Normalize` instance (defaults to\n   5712         the respective min/max values of *C* in case of the default linear\n   5713         scaling).\n   5714         It is an error to use *vmin*/*vmax* when *norm* is given.\n   5715 \n   5716     edgecolors : {\'none\', None, \'face\', color, color sequence}, optional\n   5717         The color of the edges. Defaults to \'none\'. Possible values:\n   5718 \n   5719         - \'none\' or \'\': No edge.\n   5720         - *None*: :rc:`patch.edgecolor` will be used. Note that currently\n   5721           :rc:`patch.force_edgecolor` has to be True for this to work.\n   5722         - \'face\': Use the adjacent face color.\n   5723         - A color or sequence of colors will set the edge color.\n   5724 \n   5725         The singular form *edgecolor* works as an alias.\n   5726 \n   5727     alpha : float, default: None\n   5728         The alpha blending value of the face color, between 0 (transparent)\n   5729         and 1 (opaque). Note: The edgecolor is currently not affected by\n   5730         this.\n   5731 \n   5732     snap : bool, default: False\n   5733         Whether to snap the mesh to pixel boundaries.\n   5734 \n   5735     Returns\n   5736     -------\n   5737     `matplotlib.collections.Collection`\n   5738 \n   5739     Other Parameters\n   5740     ----------------\n   5741     antialiaseds : bool, default: False\n   5742         The default *antialiaseds* is False if the default\n   5743         *edgecolors*\\ =""none"" is used.  This eliminates artificial lines\n   5744         at patch boundaries, and works regardless of the value of alpha.\n   5745         If *edgecolors* is not ""none"", then the default *antialiaseds*\n   5746         is taken from :rc:`patch.antialiased`.\n   5747         Stroking the edges may be preferred if *alpha* is 1, but will\n   5748         cause artifacts otherwise.\n   5749 \n   5750     data : indexable object, optional\n   5751         DATA_PARAMETER_PLACEHOLDER\n   5752 \n   5753     **kwargs\n   5754         Additionally, the following arguments are allowed. They are passed\n   5755         along to the `~matplotlib.collections.PolyCollection` constructor:\n   5756 \n   5757     %(PolyCollection:kwdoc)s\n   5758 \n   5759     See Also\n   5760     --------\n   5761     pcolormesh : for an explanation of the differences between\n   5762         pcolor and pcolormesh.\n   5763     imshow : If *X* and *Y* are each equidistant, `~.Axes.imshow` can be a\n   5764         faster alternative.\n   5765 \n   5766     Notes\n   5767     -----\n   5768     **Masked arrays**\n   5769 \n   5770     *X*, *Y* and *C* may be masked arrays. If either ``C[i, j]``, or one\n   5771     of the vertices surrounding ``C[i, j]`` (*X* or *Y* at\n   5772     ``[i, j], [i+1, j], [i, j+1], [i+1, j+1]``) is masked, nothing is\n   5773     plotted.\n   5774 \n   5775     .. _axes-pcolor-grid-orientation:\n   5776 \n   5777     **Grid orientation**\n   5778 \n   5779     The grid orientation follows the standard matrix convention: An array\n   5780     *C* with shape (nrows, ncolumns) is plotted with the column number as\n   5781     *X* and the row number as *Y*.\n   5782     """"""\n   5784     if shading is None:\n   5785         shading = rcParams[\'pcolor.shading\']\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/image.py:710, in set_data(self, A)\n    704 if (self._A.dtype != np.uint8 and\n    705         not np.can_cast(self._A.dtype, float, ""same_kind"")):\n    706     raise TypeError(""Image data of dtype {} cannot be converted to ""\n    707                     ""float"".format(self._A.dtype))\n    709 if self._A.ndim == 3 and self._A.shape[-1] == 1:\n--> 710     # If just one dimension assume scalar and apply colormap\n    711     self._A = self._A[:, :, 0]\n    713 if not (self._A.ndim == 2\n    714         or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n', 'TypeError: Invalid shape (3, 224, 224) for image data']",NB specific,invalid argument,evaluation/prediction,ML bug,cow-attack,,Unknown,,https://www.kaggle.com/datasets/zhengcoming/cow-attack,,https://www.kaggle.com/code/zhengcoming/cw-pytorch
NBspecific_12,97096fcf-170b-3262-a1b2-4f738b75aa2c,nameerror,name 'plt' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', 'Cell In[45], line 1\n----> 1 fig, axs = plt.subplots(6, 3, figsize=(7, 17))\n      2 for col,ax in zip(numvars,axs.ravel()):\n      3     if pp.train[col].dtype == float or pp.train[col].dtype == int:\n', ""NameError: name 'plt' is not defined""]",NB specific,module not found,data visualization,ML bug,Smoker Status Prediction using Bio-Signals,Binary Prediction of Smoker Status using Bio-Signals,Apache 2.0,Attribution 4.0 International (CC BY 4.0),https://www.kaggle.com/datasets/gauravduttakiit/smoker-status-prediction-using-biosignals,https://www.kaggle.com/competitions/playground-series-s3e24/data,https://www.kaggle.com/code/manaknarang/baseline-model-xgboost-hyperparameter-tuning
NBspecific_13,ea3fa3e6-48ec-3cb2-aae2-f614cc9087ef,nameerror,name 'X' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', 'Cell In[1], line 3\n      1 from sklearn.tree import DecisionTreeClassifier\n      2 model = DecisionTreeClassifier()\n----> 3 model .fit(X,y)\n      4 y_hat = model.predict(X)\n      5 print ( accuracy_score(y_hat,y))\n', ""NameError: name 'X' is not defined""]",NB specific,variable not found,training,ML bug,Basic datasets,,Unknown,,https://www.kaggle.com/datasets/pyim59/basic-datasets,,https://www.kaggle.com/code/amelachaieb/ia-avancee
NBspecific_14,9dae5005-d2d2-3e01-adc5-699951ac5338,nameerror,name 'train_data' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', 'Cell In[1], line 3\n      1 from sklearn.ensemble import RandomForestClassifier\n----> 3 y = train_data[""Survived""]\n      5 features = [""Pclass"", ""Sex"", ""SibSp"", ""Parch"", ""Fare""]\n      6 X = pd.get_dummies(train_data[features])\n', ""NameError: name 'train_data' is not defined""]",NB specific,variable not found,data preparation,ML bug,Titanic - Machine Learning from Disaster,,"Competition Use and Academic, Non-Commercial Use Only",,https://www.kaggle.com/competitions/titanic/data,,https://www.kaggle.com/code/rileykeller08/getting-started-with-titanic
NBspecific_15,ee95ab77-7991-30cf-adcd-c6d007019937,nameerror,name 'src_images' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', '<ipython-input-5-d6e830721ac4> in <module>\n      1 import numpy as np\n      2 import cv2\n----> 3 random_img = np.random.randint(0 , len(src_images))\n      4 fig = plt.figure(figsize = (16, 16))\n      5 src_img = np.reshape(src_images[random_img] , (256 , 256 ,3))\n', ""NameError: name 'src_images' is not defined""]",NB specific,variable not found,data preparation,ML bug,low_light_enhancement,,Unknown,,https://www.kaggle.com/datasets/hamzadope/low-light-enhancement,,https://www.kaggle.com/code/hamzadope/low-light-enhancementv2
NBspecific_16,12eb745c-9342-33a2-9553-38a616ab2f03,nameerror,name 'skin_df' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', 'Cell In[2], line 1\n----> 1 skin_df.head()\n', ""NameError: name 'skin_df' is not defined""]",NB specific,variable not found,data preparation,ML bug,Skin Cancer MNIST: HAM10000,,CC BY-NC-SA 4.0,,https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000,,https://www.kaggle.com/code/mandlagowtham/mtp-dnf-training
NBspecific_17,f5035eb2-3584-31b6-b997-348ee09354a0,nameerror,name 'X' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', 'Cell In[41], line 2\n      1 poly = PolynomialFeatures(degree=3)\n----> 2 poly_X = poly.fit_transform(X)\n      4 X.shape, poly_X.shape\n', ""NameError: name 'X' is not defined""]",NB specific,variable not found,data preparation,ML bug,House Prices - Advanced Regression Techniques,,MIT,,https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data,,https://www.kaggle.com/code/seonhwajung/ai-final
NBspecific_18,9b2d05a0-2b2f-3d1a-b79a-553c1ab75c48,nameerror,name 'y_pred' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', 'Cell In[28], line 2\n      1 from sklearn.metrics import mean_absolute_error\n----> 2 mae = mean_absolute_error(y_test, y_pred)\n      3 mae\n', ""NameError: name 'y_pred' is not defined""]",NB specific,variable not found,training,ML bug,Used Car Prices,,Apache 2.0,,https://www.kaggle.com/datasets/sujay1844/used-car-prices,,https://www.kaggle.com/code/pushkars007/notebookd120bb149d
NBspecific_19,493b11b1-5b97-3d24-bdac-2bf9b717dd42,nameerror,name 'torch' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', 'Cell In[1], line 1\n----> 1 X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n      2 predictions = model(X_test_tensor)\n      3 _, predicted_labels = torch.max(predictions, 1)\n', ""NameError: name 'torch' is not defined""]",NB specific,module not found,evaluation/prediction,ML bug,The CIFAR-10 dataset,,MIT,,https://www.cs.toronto.edu/%7Ekriz/cifar.html,,https://www.kaggle.com/code/theguardian11/pytorch-cifar10
tensorflow_1,fa2561a4-72fc-32ca-98d9-6dca427df50a,invalidargumenterror,Graph execution error:,"['---------------------------------------------------------------------------', 'InvalidArgumentError                      Traceback (most recent call last)', 'Cell In[65], line 1\n----> 1 history = model.fit(train_ds,validation_data=val_ds, epochs=1)\n', 'File /opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n', 'File /opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     51 try:\n     52   ctx.ensure_initialized()\n---> 53   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     54                                       inputs, attrs, num_outputs)\n     55 except core._NotOkStatusException as e:\n     56   if name is not None:\n', 'InvalidArgumentError: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_18868]']",API misuse,io error,training,ML bug,Diamond Images Dataset,,MIT,,https://www.kaggle.com/datasets/aayushpurswani/diamond-images-dataset,,https://www.kaggle.com/code/hariharanalm/90-accuracy-tensorflow-diamonds
tensorflow_2,cba13bab-dd7e-39ea-a4c9-3f6c40fb26fc,invalidargumenterror,Graph execution error:,"['---------------------------------------------------------------------------', 'InvalidArgumentError                      Traceback (most recent call last)', 'Cell In[46], line 11\n      9     return model\n     10 model = prepare_model()\n---> 11 model.fit_generator(train_generator,\n     12                     validation_data = valid_generator,\n     13                     epochs=5)\n     14 model.evaluate(test_generator)\n', 'File /opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:2810, in Model.fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\n   2798 """"""Fits the model on data yielded batch-by-batch by a Python generator.\n   2799 \n   2800 DEPRECATED:\n   2801   `Model.fit` now supports generators, so there is no longer any need to\n   2802   use this endpoint.\n   2803 """"""\n   2804 warnings.warn(\n   2805     ""`Model.fit_generator` is deprecated and ""\n   2806     ""will be removed in a future version. ""\n   2807     ""Please use `Model.fit`, which supports generators."",\n   2808     stacklevel=2,\n   2809 )\n-> 2810 return self.fit(\n   2811     generator,\n   2812     steps_per_epoch=steps_per_epoch,\n   2813     epochs=epochs,\n   2814     verbose=verbose,\n   2815     callbacks=callbacks,\n   2816     validation_data=validation_data,\n   2817     validation_steps=validation_steps,\n   2818     validation_freq=validation_freq,\n   2819     class_weight=class_weight,\n   2820     max_queue_size=max_queue_size,\n   2821     workers=workers,\n   2822     use_multiprocessing=use_multiprocessing,\n   2823     shuffle=shuffle,\n   2824     initial_epoch=initial_epoch,\n   2825 )\n', 'File /opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n', 'File /opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     51 try:\n     52   ctx.ensure_initialized()\n---> 53   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     54                                       inputs, attrs, num_outputs)\n     55 except core._NotOkStatusException as e:\n     56   if name is not None:\n', 'InvalidArgumentError: Graph execution error:\n\nDetected at node \'sequential_5/dense_10/Relu\' defined at (most recent call last):\n    File ""/opt/conda/lib/python3.10/runpy.py"", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File ""/opt/conda/lib/python3.10/runpy.py"", line 86, in _run_code\n      exec(code, run_globals)\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py"", line 17, in <module>\n      app.launch_new_instance()\n    File ""/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py"", line 1043, in launch_instance\n      app.start()\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py"", line 736, in start\n      self.io_loop.start()\n    File ""/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py"", line 195, in start\n      self.asyncio_loop.run_forever()\n    File ""/opt/conda/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever\n      self._run_once()\n    File ""/opt/conda/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once\n      handle._run()\n    File ""/opt/conda/lib/python3.10/asyncio/events.py"", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 516, in dispatch_queue\n      await self.process_one()\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 505, in process_one\n      await dispatch(*args)\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 412, in dispatch_shell\n      await result\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 740, in execute_request\n      reply_content = await reply_content\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py"", line 422, in do_execute\n      res = shell.run_cell(\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py"", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3009, in run_cell\n      result = self._run_cell(\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3064, in _run_cell\n      result = runner(coro)\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File ""/tmp/ipykernel_42/8764930.py"", line 11, in <module>\n      model.fit_generator(train_generator,\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py"", line 2810, in fit_generator\n      return self.fit(\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1338, in train_function\n      return step_function(self, iterator)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1303, in run_step\n      outputs = model.train_step(data)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py"", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py"", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/base_layer.py"", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/sequential.py"", line 405, in call\n      return super().call(inputs, training=training, mask=mask)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/functional.py"", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/functional.py"", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/engine/base_layer.py"", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py"", line 255, in call\n      outputs = self.activation(outputs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/activations.py"", line 321, in relu\n      return backend.relu(\n    File ""/opt/conda/lib/python3.10/site-packages/keras/src/backend.py"", line 5397, in relu\n      x = tf.nn.relu(x)\nNode: \'sequential_5/dense_10/Relu\'\nMatrix size-incompatible: In[0]: [30,387200], In[1]: [76832,16]\n\t [[{{node sequential_5/dense_10/Relu}}]] [Op:__inference_train_function_5471]']",API misuse,tensor shape mismatch,training,ML bug,Cat and Dog,,CC0: Public Domain,,https://www.kaggle.com/datasets/tongpython/cat-and-dog,,https://www.kaggle.com/code/rupayan0057/cat-and-dog-neel1
tensorflow_3,2463d2b7-55e5-382a-8eab-7a7b934a9bbc,attributeerror,'Sequential' object has no attribute 'load',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', 'Cell In[14], line 1\n----> 1 model.load (""train.h5"")\n', ""AttributeError: 'Sequential' object has no attribute 'load'""]",API misuse,attribute error,model construction,ML bug,cats_and_dogs,,Unknown,,https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip,,https://www.kaggle.com/code/kouthairbizid/notebook2388138c14
tensorflow_4,8d9101a0-6ddc-35a0-8472-a60bf59a1ff0,valueerror,Exception encountered when calling layer 'sequential' (type Sequential).,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[17], line 29\n     26 early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n     28 # train the model\n---> 29 history = model.fit(train_data, train_labels, batch_size=32, epochs=10, validation_split=.2, callbacks=[early_stop])\n     31 # plot accuracy and loss\n     32 import matplotlib.pyplot as plt\n"", 'File /opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n', 'File /tmp/__autograph_generated_filep2cz96wq.py:15, in outer_factory.<locals>.inner_factory.<locals>.tf__train_function(iterator)\n     13 try:\n     14     do_return = True\n---> 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n     16 except:\n     17     do_return = False\n', 'ValueError: in user code:\n\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py"", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \'sequential\' (type Sequential).\n    \n    Input 0 of layer ""lstm"" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1, 224, 224)\n    \n    Call arguments received by layer \'sequential\' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1, 224, 224), dtype=float32)\n      • training=True\n      • mask=None\n']",API misuse,tensor shape mismatch,training,ML bug,Signature_Verification_Dataset,Signature Verification Dataset iraninan,CC0: Public Domain,Unknown,https://www.kaggle.com/datasets/robinreni/signature-verification-dataset,https://www.kaggle.com/datasets/shirazumlintraminhaghjou/signature-verification-dataset-iraninan,https://www.kaggle.com/code/hrutikajare/signature-verification-using-rnn-c-rnn-b-rnn
tensorflow_5,b0154ba0-2f8f-33e3-9dea-61ca7d1c87a8,invalidargumenterror,Graph execution error:,"['---------------------------------------------------------------------------', 'InvalidArgumentError                      Traceback (most recent call last)', 'Cell In[75], line 2\n      1 # Model training\n----> 2 history = model.fit(\n      3     x=X_train_array,\n      4     y=y_train,\n      5     batch_size=batch_size,\n      6     epochs=5,\n      7     verbose=1,\n      8     validation_data=(X_test_array, y_test),\n      9     callbacks=my_callbacks\n     10 )\n', 'File /opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n', 'File /opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     50 try:\n     51   ctx.ensure_initialized()\n---> 52   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     53                                       inputs, attrs, num_outputs)\n     54 except core._NotOkStatusException as e:\n     55   if name is not None:\n', 'InvalidArgumentError: Graph execution error:\n\nDetected at node \'model_3/anime_embedding/embedding_lookup\' defined at (most recent call last):\n    File ""/opt/conda/lib/python3.10/runpy.py"", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File ""/opt/conda/lib/python3.10/runpy.py"", line 86, in _run_code\n      exec(code, run_globals)\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py"", line 17, in <module>\n      app.launch_new_instance()\n    File ""/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py"", line 1043, in launch_instance\n      app.start()\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py"", line 725, in start\n      self.io_loop.start()\n    File ""/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py"", line 215, in start\n      self.asyncio_loop.run_forever()\n    File ""/opt/conda/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever\n      self._run_once()\n    File ""/opt/conda/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once\n      handle._run()\n    File ""/opt/conda/lib/python3.10/asyncio/events.py"", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 513, in dispatch_queue\n      await self.process_one()\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 502, in process_one\n      await dispatch(*args)\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 409, in dispatch_shell\n      await result\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py"", line 729, in execute_request\n      reply_content = await reply_content\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py"", line 422, in do_execute\n      res = shell.run_cell(\n    File ""/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py"", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3006, in run_cell\n      result = self._run_cell(\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3061, in _run_cell\n      result = runner(coro)\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File ""/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py"", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File ""/tmp/ipykernel_34/627539252.py"", line 2, in <module>\n      history = model.fit(\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1249, in train_function\n      return step_function(self, iterator)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1222, in run_step\n      outputs = model.train_step(data)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py"", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py"", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py"", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py"", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/layers/core/embedding.py"", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: \'model_3/anime_embedding/embedding_lookup\'\nindices[0,0] = -2147483648 is not in [0, 1000)\n\t [[{{node model_3/anime_embedding/embedding_lookup}}]] [Op:__inference_train_function_5913]']",API misuse,invalid argument,training,ML bug,Anime Recommendation Database 2020,,CC0: Public Domain,,https://www.kaggle.com/datasets/hernan4444/anime-recommendation-database-2020,,https://www.kaggle.com/code/alinadir/neural-collaborative-filtering-anime
tensorflow_6,23ea6d07-7fc5-3715-b82e-e914a8978002,keyerror,'acc',"['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', 'Cell In[53], line 6\n      3 ax[0].plot(history.history[\'val_loss\'], color=\'r\', label=""validation loss"",axes =ax[0])\n      4 legend = ax[0].legend(loc=\'best\', shadow=True)\n----> 6 ax[1].plot(history.history[\'acc\'], color=\'b\', label=""Training accuracy"")\n      7 ax[1].plot(history.history[\'val_acc\'], color=\'r\',label=""Validation accuracy"")\n      8 legend = ax[1].legend(loc=\'best\', shadow=True)\n', ""KeyError: 'acc'""]",API misuse,key error,evaluation/prediction,ML bug,mnist_data,,Unknown,,https://www.kaggle.com/datasets/ashmmani/mnist-data,,https://www.kaggle.com/code/xuyouqian/cnn-keras
tensorflow_7,c38029cb-568b-3e86-913d-bc089f7b4750,valueerror,"Input 0 is incompatible with layer model: expected shape=(None, 50), found shape=(None, 259)","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/665779900.py in <module>\n----> 1 model.fit(train_input, train.label.values, epochs = 2, verbose = 1, batch_size = 64, validation_split = 0.2)\n', '/opt/conda/lib/python3.7/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\n   1182                 _r=1):\n   1183               callbacks.on_train_batch_begin(step)\n-> 1184               tmp_logs = self.train_function(iterator)\n   1185               if data_handler.should_sync:\n   1186                 context.async_wait()\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\n    883 \n    884       with OptionalXlaContext(self._jit_compile):\n--> 885         result = self._call(*args, **kwds)\n    886 \n    887       new_tracing_count = self.experimental_get_tracing_count()\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\n    931       # This is the first call of __call__, so we have to initialize.\n    932       initializers = []\n--> 933       self._initialize(args, kwds, add_initializers_to=initializers)\n    934     finally:\n    935       # At this point we know that the initialization is complete (or less\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\n    758     self._concrete_stateful_fn = (\n    759         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n--> 760             *args, **kwds))\n    761 \n    762     def invalid_creator_scope(*unused_args, **unused_kwds):\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\n   3064       args, kwargs = None, None\n   3065     with self._lock:\n-> 3066       graph_function, _ = self._maybe_define_function(args, kwargs)\n   3067     return graph_function\n   3068 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\n   3461 \n   3462           self._function_cache.missed.add(call_context_key)\n-> 3463           graph_function = self._create_graph_function(args, kwargs)\n   3464           self._function_cache.primary[cache_key] = graph_function\n   3465 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\n   3306             arg_names=arg_names,\n   3307             override_flat_arg_shapes=override_flat_arg_shapes,\n-> 3308             capture_by_value=self._capture_by_value),\n   3309         self._function_attributes,\n   3310         function_spec=self.function_spec,\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\n   1005         _, original_func = tf_decorator.unwrap(python_func)\n   1006 \n-> 1007       func_outputs = python_func(*func_args, **func_kwargs)\n   1008 \n   1009       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\n    666         # the function a weak reference to itself to avoid a reference cycle.\n    667         with OptionalXlaContext(compile_with_xla):\n--> 668           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    669         return out\n    670 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\n    992           except Exception as e:  # pylint:disable=broad-except\n    993             if hasattr(e, ""ag_error_metadata""):\n--> 994               raise e.ag_error_metadata.to_exception(e)\n    995             else:\n    996               raise\n', ""ValueError: in user code:\n\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py:269 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 50), found shape=(None, 259)\n""]",API misuse,tensor shape mismatch,training,ML bug,"Contradictory, My Dear Watson",,Allow any purpose,,https://www.kaggle.com/competitions/contradictory-my-dear-watson/data,,https://www.kaggle.com/code/famapa/using-nli-to-detect-contradictions-and-truths
tensorflow_8,85f04894-8153-3f9a-a839-0b2c211b0916,attributeerror,'Functional' object has no attribute 'predict_classes',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', 'Cell In[26], line 1\n----> 1 y_pred = model.predict_classes(X_val)\n      2 acc_test = 0\n      4 for i in range(X_val.shape[0]):\n', ""AttributeError: 'Functional' object has no attribute 'predict_classes'""]",API misuse,attribute error,evaluation/prediction,ML bug,BreakHis,,Unknown,,https://www.kaggle.com/datasets/ambarish/breakhis,,https://www.kaggle.com/code/shafimbh/modified-bottleneck-block
tensorflow_9,48241d9e-dcf9-38fb-87d0-f3f542bbb45e,attributeerror,'BertModel' object has no attribute 'built',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', 'Cell In[23], line 2\n      1 import tensorflow as tf\n----> 2 tf.keras.utils.plot_model(bert_model)\n', 'File /opt/conda/lib/python3.10/site-packages/keras/utils/vis_utils.py:444, in plot_model(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations, show_trainable)\n    378 @keras_export(""keras.utils.plot_model"")\n    379 def plot_model(\n    380     model,\n   (...)\n    390     show_trainable=False,\n    391 ):\n    392     """"""Converts a Keras model to dot format and save to a file.\n    393 \n    394     Example:\n   (...)\n    441       This enables in-line display of the model plots in notebooks.\n    442     """"""\n--> 444     if not model.built:\n    445         raise ValueError(\n    446             ""This model has not yet been built. ""\n    447             ""Build the model first by calling `build()` or by calling ""\n    448             ""the model on a batch of data.""\n    449         )\n    451     if not check_graphviz():\n', 'File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1614, in Module.__getattr__(self, name)\n   1612     if name in modules:\n   1613         return modules[name]\n-> 1614 raise AttributeError(""\'{}\' object has no attribute \'{}\'"".format(\n   1615     type(self).__name__, name))\n', ""AttributeError: 'BertModel' object has no attribute 'built'""]",ML model confusion,attribute error,model construction,ML bug,Natural Language Processing with Disaster Tweets,,"Competition Use and Academic, Non-Commercial Use Only",,https://www.kaggle.com/competitions/nlp-getting-started/data,,https://www.kaggle.com/code/trishanudas/disaster-tweets-with-bert-with-val-accuracy-82
tensorflow_10,085ef695-7b52-3e89-92ef-d481a9ab9cb2,typeerror,"Value passed to parameter 'input' has DataType string not in list of allowed values: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, float16, uint32, uint64, qint8, quint8, qint32, qint16, quint16","['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', ""Cell In[55], line 3\n      1 # Compile and train the model\n      2 model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n----> 3 model.fit(train_data, train_labels, epochs=10)\n"", 'File /opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n', 'File /tmp/__autograph_generated_file0uma5t6e.py:15, in outer_factory.<locals>.inner_factory.<locals>.tf__train_function(iterator)\n     13 try:\n     14     do_return = True\n---> 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n     16 except:\n     17     do_return = False\n', 'File /tmp/__autograph_generated_file_7qcj_31.py:10, in outer_factory.<locals>.inner_factory.<locals>.tf__call(self, inputs, **kwargs)\n      8 do_return = False\n      9 retval_ = ag__.UndefinedReturnValue()\n---> 10 outputs = ag__.converted_call(ag__.ld(self).model, (ag__.ld(inputs),), dict(**ag__.ld(kwargs)), fscope)\n     11 try:\n     12     do_return = True\n', 'File /tmp/__autograph_generated_file4cxfdhhw.py:37, in outer_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs(self, *args, **kwargs)\n     35 try:\n     36     do_return = True\n---> 37     retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n     38 except:\n     39     do_return = False\n', 'File /tmp/__autograph_generated_filei01ktml5.py:31, in outer_factory.<locals>.inner_factory.<locals>.tf__call(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\n     29 do_return = False\n     30 retval_ = ag__.UndefinedReturnValue()\n---> 31 outputs = ag__.converted_call(ag__.ld(self).bert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), token_type_ids=ag__.ld(token_type_ids), position_ids=ag__.ld(position_ids), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), encoder_hidden_states=ag__.ld(encoder_hidden_states), encoder_attention_mask=ag__.ld(encoder_attention_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n     32 try:\n     33     do_return = True\n', 'File /tmp/__autograph_generated_file4cxfdhhw.py:37, in outer_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs(self, *args, **kwargs)\n     35 try:\n     36     do_return = True\n---> 37     retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n     38 except:\n     39     do_return = False\n', ""File /tmp/__autograph_generated_file8w9ibu71.py:127, in outer_factory.<locals>.inner_factory.<locals>.tf__call(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\n    125     pass\n    126 ag__.if_stmt(ag__.ld(token_type_ids) is None, if_body_6, else_body_6, get_state_6, set_state_6, ('token_type_ids',), 1)\n--> 127 embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n    128 attention_mask_shape = ag__.converted_call(ag__.ld(shape_list), (ag__.ld(attention_mask),), None, fscope)\n    129 mask_seq_length = ag__.ld(seq_length) + ag__.ld(past_key_values_length)\n"", ""File /tmp/__autograph_generated_filev0vda2ze.py:46, in outer_factory.<locals>.inner_factory.<locals>.tf__call(self, input_ids, position_ids, token_type_ids, inputs_embeds, past_key_values_length, training)\n     44     nonlocal inputs_embeds\n     45     pass\n---> 46 ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n     47 input_shape = ag__.converted_call(ag__.ld(shape_list), (ag__.ld(inputs_embeds),), None, fscope)[:-1]\n     49 def get_state_2():\n"", 'File /tmp/__autograph_generated_filev0vda2ze.py:40, in outer_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_1()\n     38 def if_body_1():\n     39     nonlocal inputs_embeds\n---> 40     ag__.converted_call(ag__.ld(check_embeddings_within_bounds), (ag__.ld(input_ids), ag__.ld(self).config.vocab_size), None, fscope)\n     41     inputs_embeds = ag__.converted_call(ag__.ld(tf).gather, (), dict(params=ag__.ld(self).weight, indices=ag__.ld(input_ids)), fscope)\n', 'File /tmp/__autograph_generated_file29zlsorl.py:17, in outer_factory.<locals>.inner_factory.<locals>.tf__check_embeddings_within_bounds(tensor, embed_dim, tensor_name)\n      7         """"""\n      8 `tf.gather`, on which TF embedding layers are based, won\'t check positive out of bound indices on GPU, returning\n      9 zeros instead. This function adds a check against that dangerous silent behavior.\n   (...)\n     14     tensor_name (`str`, *optional*): The name of the tensor to use in the error message.\n     15 """"""\n     16         with ag__.FunctionScope(\'check_embeddings_within_bounds\', \'fscope\', ag__.STD) as fscope:\n---> 17             ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(tensor), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(embed_dim),), dict(dtype=ag__.ld(tensor).dtype), fscope)), dict(message=f""The maximum value of {ag__.ld(tensor_name)} ({ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(tensor),), None, fscope)}) must be smaller than the embedding layer\'s input dimension ({ag__.ld(embed_dim)}). The likely cause is some problem at tokenization time.""), fscope)\n', 'TypeError: in user code:\n\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/engine/training.py"", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File ""/tmp/__autograph_generated_file_7qcj_31.py"", line 10, in tf__call\n        outputs = ag__.converted_call(ag__.ld(self).model, (ag__.ld(inputs),), dict(**ag__.ld(kwargs)), fscope)\n    File ""/tmp/__autograph_generated_file4cxfdhhw.py"", line 37, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File ""/tmp/__autograph_generated_filei01ktml5.py"", line 31, in tf__call\n        outputs = ag__.converted_call(ag__.ld(self).bert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), token_type_ids=ag__.ld(token_type_ids), position_ids=ag__.ld(position_ids), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), encoder_hidden_states=ag__.ld(encoder_hidden_states), encoder_attention_mask=ag__.ld(encoder_attention_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File ""/tmp/__autograph_generated_file4cxfdhhw.py"", line 37, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File ""/tmp/__autograph_generated_file8w9ibu71.py"", line 127, in tf__call\n        embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n    File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 46, in tf__call\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, (\'inputs_embeds\',), 1)\n    File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 40, in if_body_1\n        ag__.converted_call(ag__.ld(check_embeddings_within_bounds), (ag__.ld(input_ids), ag__.ld(self).config.vocab_size), None, fscope)\n    File ""/tmp/__autograph_generated_file29zlsorl.py"", line 17, in tf__check_embeddings_within_bounds\n        ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(tensor), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(embed_dim),), dict(dtype=ag__.ld(tensor).dtype), fscope)), dict(message=f""The maximum value of {ag__.ld(tensor_name)} ({ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(tensor),), None, fscope)}) must be smaller than the embedding layer\'s input dimension ({ag__.ld(embed_dim)}). The likely cause is some problem at tokenization time.""), fscope)\n\n    TypeError: Exception encountered when calling layer \'hugging_face_layer_3\' (type HuggingFaceLayer).\n    \n    in user code:\n    \n        File ""/tmp/ipykernel_32/1009480242.py"", line 14, in call  *\n            outputs = self.model(inputs, **kwargs)\n        File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File ""/tmp/__autograph_generated_file4cxfdhhw.py"", line 37, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File ""/tmp/__autograph_generated_filei01ktml5.py"", line 31, in tf__call\n            outputs = ag__.converted_call(ag__.ld(self).bert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), token_type_ids=ag__.ld(token_type_ids), position_ids=ag__.ld(position_ids), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), encoder_hidden_states=ag__.ld(encoder_hidden_states), encoder_attention_mask=ag__.ld(encoder_attention_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n        File ""/tmp/__autograph_generated_file4cxfdhhw.py"", line 37, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File ""/tmp/__autograph_generated_file8w9ibu71.py"", line 127, in tf__call\n            embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n        File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 46, in tf__call\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, (\'inputs_embeds\',), 1)\n        File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 40, in if_body_1\n            ag__.converted_call(ag__.ld(check_embeddings_within_bounds), (ag__.ld(input_ids), ag__.ld(self).config.vocab_size), None, fscope)\n        File ""/tmp/__autograph_generated_file29zlsorl.py"", line 17, in tf__check_embeddings_within_bounds\n            ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(tensor), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(embed_dim),), dict(dtype=ag__.ld(tensor).dtype), fscope)), dict(message=f""The maximum value of {ag__.ld(tensor_name)} ({ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(tensor),), None, fscope)}) must be smaller than the embedding layer\'s input dimension ({ag__.ld(embed_dim)}). The likely cause is some problem at tokenization time.""), fscope)\n    \n        TypeError: Exception encountered when calling layer \'tf_bert_model_3\' (type TFBertModel).\n        \n        in user code:\n        \n            File ""/opt/conda/lib/python3.10/site-packages/transformers/modeling_tf_utils.py"", line 1061, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File ""/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py"", line 1088, in call  *\n                outputs = self.bert(\n            File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File ""/tmp/__autograph_generated_file4cxfdhhw.py"", line 37, in tf__run_call_with_unpacked_inputs\n                retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n            File ""/tmp/__autograph_generated_file8w9ibu71.py"", line 127, in tf__call\n                embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (), dict(input_ids=ag__.ld(input_ids), position_ids=ag__.ld(position_ids), token_type_ids=ag__.ld(token_type_ids), inputs_embeds=ag__.ld(inputs_embeds), past_key_values_length=ag__.ld(past_key_values_length), training=ag__.ld(training)), fscope)\n            File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 46, in tf__call\n                ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, (\'inputs_embeds\',), 1)\n            File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 40, in if_body_1\n                ag__.converted_call(ag__.ld(check_embeddings_within_bounds), (ag__.ld(input_ids), ag__.ld(self).config.vocab_size), None, fscope)\n            File ""/tmp/__autograph_generated_file29zlsorl.py"", line 17, in tf__check_embeddings_within_bounds\n                ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(tensor), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(embed_dim),), dict(dtype=ag__.ld(tensor).dtype), fscope)), dict(message=f""The maximum value of {ag__.ld(tensor_name)} ({ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(tensor),), None, fscope)}) must be smaller than the embedding layer\'s input dimension ({ag__.ld(embed_dim)}). The likely cause is some problem at tokenization time.""), fscope)\n        \n            TypeError: Exception encountered when calling layer \'bert\' (type TFBertMainLayer).\n            \n            in user code:\n            \n                File ""/opt/conda/lib/python3.10/site-packages/transformers/modeling_tf_utils.py"", line 1061, in run_call_with_unpacked_inputs  *\n                    return func(self, **unpacked_inputs)\n                File ""/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py"", line 780, in call  *\n                    embedding_output = self.embeddings(\n                File ""/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 46, in tf__call\n                    ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, (\'inputs_embeds\',), 1)\n                File ""/tmp/__autograph_generated_filev0vda2ze.py"", line 40, in if_body_1\n                    ag__.converted_call(ag__.ld(check_embeddings_within_bounds), (ag__.ld(input_ids), ag__.ld(self).config.vocab_size), None, fscope)\n                File ""/tmp/__autograph_generated_file29zlsorl.py"", line 17, in tf__check_embeddings_within_bounds\n                    ag__.converted_call(ag__.ld(tf).debugging.assert_less, (ag__.ld(tensor), ag__.converted_call(ag__.ld(tf).cast, (ag__.ld(embed_dim),), dict(dtype=ag__.ld(tensor).dtype), fscope)), dict(message=f""The maximum value of {ag__.ld(tensor_name)} ({ag__.converted_call(ag__.ld(tf).math.reduce_max, (ag__.ld(tensor),), None, fscope)}) must be smaller than the embedding layer\'s input dimension ({ag__.ld(embed_dim)}). The likely cause is some problem at tokenization time.""), fscope)\n            \n                TypeError: Exception encountered when calling layer \'embeddings\' (type TFBertEmbeddings).\n                \n                in user code:\n                \n                    File ""/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py"", line 202, in call  *\n                        check_embeddings_within_bounds(input_ids, self.config.vocab_size)\n                    File ""/opt/conda/lib/python3.10/site-packages/transformers/tf_utils.py"", line 161, in check_embeddings_within_bounds  *\n                        tf.debugging.assert_less(\n                \n                    TypeError: Value passed to parameter \'input\' has DataType string not in list of allowed values: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, float16, uint32, uint64, qint8, quint8, qint32, qint16, quint16\n                \n                \n                Call arguments received by layer \'embeddings\' (type TFBertEmbeddings):\n                  • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n                  • position_ids=None\n                  • token_type_ids=tf.Tensor(shape=(None, 1), dtype=int32)\n                  • inputs_embeds=None\n                  • past_key_values_length=0\n                  • training=True\n            \n            \n            Call arguments received by layer \'bert\' (type TFBertMainLayer):\n              • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n              • attention_mask=None\n              • token_type_ids=None\n              • position_ids=None\n              • head_mask=None\n              • inputs_embeds=None\n              • encoder_hidden_states=None\n              • encoder_attention_mask=None\n              • past_key_values=None\n              • use_cache=True\n              • output_attentions=False\n              • output_hidden_states=False\n              • return_dict=True\n              • training=True\n        \n        \n        Call arguments received by layer \'tf_bert_model_3\' (type TFBertModel):\n          • input_ids=tf.Tensor(shape=(None, 1), dtype=string)\n          • attention_mask=None\n          • token_type_ids=Non",API misuse,invalid argument,training,ML bug,TechMedical,,Unknown,,https://www.kaggle.com/datasets/baorbaor/techmedical,,https://www.kaggle.com/code/baonguyengia123/techmedical-with-bert-hugging-face
tensorflow_11,5e70c05a-37b5-3b31-9d6e-9c234ec89dc6,invalidargumenterror,Graph execution error:,"['---------------------------------------------------------------------------', 'InvalidArgumentError                      Traceback (most recent call last)', '/tmp/ipykernel_27/3829365925.py in <module>\n      3     validation_data=val_images,\n      4     epochs=30,\n----> 5     callbacks=callbacks\n      6 )\n', '/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)\n     68             # To get the full stack trace, call:\n     69             # `tf.debugging.disable_traceback_filtering()`\n---> 70             raise e.with_traceback(filtered_tb) from None\n     71         finally:\n     72             del filtered_tb\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     51     ctx.ensure_initialized()\n     52     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n---> 53                                         inputs, attrs, num_outputs)\n     54   except core._NotOkStatusException as e:\n     55     if name is not None:\n', 'InvalidArgumentError: Graph execution error:\n\nDetected at node \'categorical_crossentropy/softmax_cross_entropy_with_logits\' defined at (most recent call last):\n    File ""/opt/conda/lib/python3.7/runpy.py"", line 193, in _run_module_as_main\n      ""__main__"", mod_spec)\n    File ""/opt/conda/lib/python3.7/runpy.py"", line 85, in _run_code\n      exec(code, run_globals)\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py"", line 17, in <module>\n      app.launch_new_instance()\n    File ""/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py"", line 1041, in launch_instance\n      app.start()\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py"", line 712, in start\n      self.io_loop.start()\n    File ""/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py"", line 215, in start\n      self.asyncio_loop.run_forever()\n    File ""/opt/conda/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever\n      self._run_once()\n    File ""/opt/conda/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once\n      handle._run()\n    File ""/opt/conda/lib/python3.7/asyncio/events.py"", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 510, in dispatch_queue\n      await self.process_one()\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 499, in process_one\n      await dispatch(*args)\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 406, in dispatch_shell\n      await result\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py"", line 730, in execute_request\n      reply_content = await reply_content\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py"", line 387, in do_execute\n      cell_id=cell_id,\n    File ""/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py"", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3030, in _run_cell\n      return runner(coro)\n    File ""/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py"", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File ""/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py"", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File ""/tmp/ipykernel_27/3829365925.py"", line 5, in <module>\n      callbacks=callbacks\n    File ""/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/engine/training.py"", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/engine/training.py"", line 1249, in train_function\n      return step_function(self, iterator)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/engine/training.py"", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File ""/opt/conda/lib/python3.7/site-packages/keras/engine/training.py"", line 1222, in run_step\n      outputs = model.train_step(data)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/engine/training.py"", line 1024, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/engine/training.py"", line 1083, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses\n    File ""/opt/conda/lib/python3.7/site-packages/keras/engine/compile_utils.py"", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/losses.py"", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/losses.py"", line 284, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File ""/opt/conda/lib/python3.7/site-packages/keras/losses.py"", line 2005, in categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis\n    File ""/opt/conda/lib/python3.7/site-packages/keras/backend.py"", line 5539, in categorical_crossentropy\n      labels=target, logits=output, axis=axis\nNode: \'categorical_crossentropy/softmax_cross_entropy_with_logits\'\nlogits and labels must be broadcastable: logits_size=[32,5] labels_size=[32,2]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_47270]']",API misuse,tensor shape mismatch,training,ML bug,Cars and Tanks Image Classification,,CC0: Public Domain,,https://www.kaggle.com/datasets/gatewayadam/cars-and-tanks-image-classification,,https://www.kaggle.com/code/alanluciomaldonado/actividad7
tensorflow_12,58e8fcb0-046c-3e4f-bed2-76fec5d9a381,valueerror,Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_23/3987115718.py in <module>\n----> 1 history = model.fit(train_images, train_labels, batch_size = 16, epochs=5, validation_data=(val_images, val_labels), verbose = 1)\n', '/opt/conda/lib/python3.7/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\n   1146           use_multiprocessing=use_multiprocessing,\n   1147           model=self,\n-> 1148           steps_per_execution=self._steps_per_execution)\n   1149 \n   1150       # Container that configures and calls `tf.keras.Callback`s.\n', '/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py in get_data_handler(*args, **kwargs)\n   1381   if getattr(kwargs[""model""], ""_cluster_coordinator"", None):\n   1382     return _ClusterCoordinatorDataHandler(*args, **kwargs)\n-> 1383   return DataHandler(*args, **kwargs)\n   1384 \n   1385 \n', '/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\n   1148         use_multiprocessing=use_multiprocessing,\n   1149         distribution_strategy=tf.distribute.get_strategy(),\n-> 1150         model=model)\n   1151 \n   1152     strategy = tf.distribute.get_strategy()\n', '/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\n    228                **kwargs):\n    229     super(TensorLikeDataAdapter, self).__init__(x, y, **kwargs)\n--> 230     x, y, sample_weights = _process_tensorlike((x, y, sample_weights))\n    231     sample_weight_modes = broadcast_sample_weight_modes(\n    232         sample_weights, sample_weight_modes)\n', '/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py in _process_tensorlike(inputs)\n   1029     return x\n   1030 \n-> 1031   inputs = tf.nest.map_structure(_convert_numpy_and_scipy, inputs)\n   1032   return tf.__internal__.nest.list_to_tuple(inputs)\n   1033 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\n    867 \n    868   return pack_sequence_as(\n--> 869       structure[0], [func(*x) for x in entries],\n    870       expand_composites=expand_composites)\n    871 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\n    867 \n    868   return pack_sequence_as(\n--> 869       structure[0], [func(*x) for x in entries],\n    870       expand_composites=expand_composites)\n    871 \n', '/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py in _convert_numpy_and_scipy(x)\n   1024       if issubclass(x.dtype.type, np.floating):\n   1025         dtype = backend.floatx()\n-> 1026       return tf.convert_to_tensor(x, dtype=dtype)\n   1027     elif _is_scipy_sparse(x):\n   1028       return _scipy_sparse_to_sparse_tensor(x)\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\n    204     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""\n    205     try:\n--> 206       return target(*args, **kwargs)\n    207     except (TypeError, ValueError):\n    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor_v2_with_dispatch(value, dtype, dtype_hint, name)\n   1429   """"""\n   1430   return convert_to_tensor_v2(\n-> 1431       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n   1432 \n   1433 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\n   1439       name=name,\n   1440       preferred_dtype=dtype_hint,\n-> 1441       as_ref=False)\n   1442 \n   1443 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)\n    161         with Trace(trace_name, **trace_kwargs):\n    162           return func(*args, **kwargs)\n--> 163       return func(*args, **kwargs)\n    164 \n    165     return wrapped\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\n   1564 \n   1565     if ret is None:\n-> 1566       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n   1567 \n   1568     if ret is NotImplemented:\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py in _default_conversion_function(***failed resolving arguments***)\n     50 def _default_conversion_function(value, dtype, name, as_ref):\n     51   del as_ref  # Unused.\n---> 52   return constant_op.constant(value, dtype, name=name)\n     53 \n     54 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\n    270   """"""\n    271   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n--> 272                         allow_broadcast=True)\n    273 \n    274 \n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\n    281       with trace.Trace(""tf.constant""):\n    282         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n--> 283     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n    284 \n    285   g = ops.get_default_graph()\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n    306 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):\n    307   """"""Creates a constant on the current device.""""""\n--> 308   t = convert_to_eager_tensor(value, ctx, dtype)\n    309   if shape is None:\n    310     return t\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\n    104       dtype = dtypes.as_dtype(dtype).as_datatype_enum\n    105   ctx.ensure_initialized()\n--> 106   return ops.EagerTensor(value, ctx.device_name, dtype)\n    107 \n    108 \n', 'ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).']",API misuse,tensor shape mismatch,training,ML bug,Images after converted,dataset_breat,Unknown,Unknown,https://www.kaggle.com/datasets/bobotrnhth/images-after-converted,https://www.kaggle.com/datasets/bobotrnhth/dataset-breat,https://www.kaggle.com/code/bobotrnhth/modelvgg
tensorflow_13,20e73553-36d2-36dc-9796-3d6637e81257,valueerror,`sequences` must be a list of iterables. Found non-iterable: 101,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'File /opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py:1094, in pad_sequences(sequences, maxlen, dtype, padding, truncating, value)\n   1093 try:\n-> 1094     lengths.append(len(x))\n   1095     if flag and len(x):\n', ""TypeError: object of type 'int' has no len()"", '\nThe above exception was the direct cause of the following exception:\n', 'ValueError                                Traceback (most recent call last)', 'Cell In[40], line 7\n      3 from tensorflow.keras.preprocessing.text import Tokenizer\n      5 max_length = 768\n----> 7 docs = np.array([np.array(pad_sequences(tokenize_text(i)), maxlen=max_length) for i in docs])\n', 'Cell In[40], line 7, in <listcomp>(.0)\n      3 from tensorflow.keras.preprocessing.text import Tokenizer\n      5 max_length = 768\n----> 7 docs = np.array([np.array(pad_sequences(tokenize_text(i)), maxlen=max_length) for i in docs])\n', 'File /opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py:1099, in pad_sequences(sequences, maxlen, dtype, padding, truncating, value)\n   1097             flag = False\n   1098     except TypeError as e:\n-> 1099         raise ValueError(\n   1100             ""`sequences` must be a list of iterables. ""\n   1101             f""Found non-iterable: {str(x)}""\n   1102         ) from e\n   1104 if maxlen is None:\n   1105     maxlen = np.max(lengths)\n', 'ValueError: `sequences` must be a list of iterables. Found non-iterable: 101']",API misuse,type error,data preparation,ML bug,Glove.6B.50d,,Open Data Commons Public Domain Dedication and License (PDDL),,http://nlp.stanford.edu/data/glove.6B.zip,,https://www.kaggle.com/code/baorbaor/bert-glove
tensorflow_14,e62e29da-fd8a-346f-b488-fec35357fd34,valueerror,"Layer count mismatch when loading weights from file. Model expected 13 layers, found 16 saved layers.","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[9], line 36\n     33 base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n     35 # Load the previously saved model weights\n---> 36 base_model.load_weights('/kaggle/input/face-recog/vgg_face_weights.h5')\n     38 # Continue training the model\n     39 base_model.fit(\n     40     train_generator,\n     41     steps_per_epoch=len(train_generator),\n     42     epochs=10,  # You can adjust the number of epochs\n     43 )\n"", 'File /opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n', 'File /opt/conda/lib/python3.10/site-packages/keras/saving/legacy/hdf5_format.py:808, in load_weights_from_hdf5_group(f, model)\n    806 layer_names = filtered_layer_names\n    807 if len(layer_names) != len(filtered_layers):\n--> 808     raise ValueError(\n    809         ""Layer count mismatch when loading weights from file. ""\n    810         f""Model expected {len(filtered_layers)} layers, found ""\n    811         f""{len(layer_names)} saved layers.""\n    812     )\n    814 # We batch weight value assignments in a single backend call\n    815 # which provides a speedup in TensorFlow.\n    816 weight_value_tuples = []\n', 'ValueError: Layer count mismatch when loading weights from file. Model expected 13 layers, found 16 saved layers.']",ML model confusion,value error,model construction,ML bug,face_recog,train_data_imgs,Unknown,Unknown,https://www.kaggle.com/datasets/karn22/face-recog,https://www.kaggle.com/datasets/karn22/train-data-imgs,https://www.kaggle.com/code/karn22/face-recog-using-vgg16
tensorflow_15,75574f9a-08fa-3a46-9b73-29093aac6907,attributeerror,'Functional' object has no attribute 'predict_classes',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', 'Cell In[15], line 4\n      2 labels =  np.array([])\n      3 for x, y in test_ds:\n----> 4   predictions = np.concatenate([predictions, model.predict_classes(x)])\n      5   labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n      7 tf.math.confusion_matrix(labels=labels, predictions=predictions).numpy()\n', ""AttributeError: 'Functional' object has no attribute 'predict_classes'""]",library cause,attribute error,evaluation/prediction,ML bug,Eggs Type Dataset,,CDLA-Permissive-1.0,,https://www.kaggle.com/datasets/snatts/eggs-type-dataset,,https://www.kaggle.com/code/snatts/egg-type-classification
sklearn_1,2328d822-cd0a-36f9-91ab-ec042fff6bae,typeerror,compute_class_weight() takes 1 positional argument but 3 were given,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', ""Cell In[10], line 2\n      1 from sklearn.utils.class_weight import compute_class_weight\n----> 2 class_weights = compute_class_weight('balanced', np.unique(train_dataset.labels), train_dataset.labels)\n      3 class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n      5 # Compile the model with class weights\n"", 'TypeError: compute_class_weight() takes 1 positional argument but 3 were given']",API misuse,invalid argument,model construction,ML bug,FER-2013,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/msambare/fer2013,,https://www.kaggle.com/code/shahriarrafi1071/thetest6
sklearn_2,b9d3ff5e-47ce-3cd1-8850-e6fcd42a053d,notfittederror,This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.,"['---------------------------------------------------------------------------', 'NotFittedError                            Traceback (most recent call last)', 'Cell In[72], line 1\n----> 1 final_pred = DTRmodel.predict(dft_encoded)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:425, in BaseDecisionTree.predict(self, X, check_input)\n    402 def predict(self, X, check_input=True):\n    403     """"""Predict class or regression value for X.\n    404 \n    405     For a classification model, the predicted class for each sample in X is\n   (...)\n    423         The predicted classes, or the predict values.\n    424     """"""\n--> 425     check_is_fitted(self)\n    426     X = self._validate_X_predict(X, check_input)\n    427     proba = self.tree_.predict(X)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1390, in check_is_fitted(estimator, attributes, msg, all_or_any)\n   1385     fitted = [\n   1386         v for v in vars(estimator) if v.endswith(""_"") and not v.startswith(""__"")\n   1387     ]\n   1389 if not fitted:\n-> 1390     raise NotFittedError(msg % {""name"": type(estimator).__name__})\n', ""NotFittedError: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.""]",API misuse,model initialization error,evaluation/prediction,ML bug,Food Demand Forecasting,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/kannanaikkal/food-demand-forecasting,,https://www.kaggle.com/code/mustafakarsu/hungry-pandas-final-project
sklearn_3,4eeaed5d-9b9a-37b6-a945-66e467695cd6,valueerror,The feature names should match those that were passed during fit.,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[66], line 4\n      2 scaler = StandardScaler()\n      3 train_df = scaler.fit_transform(train_df)\n----> 4 test_df = scaler.transform(test_df)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140, in _wrap_method_output.<locals>.wrapped(self, X, *args, **kwargs)\n    138 @wraps(f)\n    139 def wrapped(self, X, *args, **kwargs):\n--> 140     data_to_wrap = f(self, X, *args, **kwargs)\n    141     if isinstance(data_to_wrap, tuple):\n    142         # only wrap the first output for cross decomposition\n    143         return (\n    144             _wrap_data_with_container(method, data_to_wrap[0], X, self),\n    145             *data_to_wrap[1:],\n    146         )\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:992, in StandardScaler.transform(self, X, copy)\n    989 check_is_fitted(self)\n    991 copy = copy if copy is not None else self.copy\n--> 992 X = self._validate_data(\n    993     X,\n    994     reset=False,\n    995     accept_sparse=""csr"",\n    996     copy=copy,\n    997     dtype=FLOAT_DTYPES,\n    998     force_all_finite=""allow-nan"",\n    999 )\n   1001 if sparse.issparse(X):\n   1002     if self.with_mean:\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/base.py:548, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)\n    483 def _validate_data(\n    484     self,\n    485     X=""no_validation"",\n   (...)\n    489     **check_params,\n    490 ):\n    491     """"""Validate input data and set or check the `n_features_in_` attribute.\n    492 \n    493     Parameters\n   (...)\n    546         validated.\n    547     """"""\n--> 548     self._check_feature_names(X, reset=reset)\n    550     if y is None and self._get_tags()[""requires_y""]:\n    551         raise ValueError(\n    552             f""This {self.__class__.__name__} estimator ""\n    553             ""requires y to be passed, but the target y is None.""\n    554         )\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/base.py:481, in BaseEstimator._check_feature_names(self, X, reset)\n    476 if not missing_names and not unexpected_names:\n    477     message += (\n    478         ""Feature names must be in the same order as they were in fit.\\n""\n    479     )\n--> 481 raise ValueError(message)\n', 'ValueError: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AB_0.0\n- AF_0.0\n- AH_0.0\n- AM_0.0\n- AR_0.0\n- ...\nFeature names seen at fit time, yet now missing:\n- AB_0.081187_0_0_0\n- AB_0.081187_0_0_1\n- AB_0.081187_0_1_0\n- AB_0.081187_0_1_1\n- AB_0.081187_1_0_0\n- ...\n']",implementation error,feature name mismatch,data preparation,ML bug,ICR - Identifying Age-Related Conditions,,No private sharing outside teams,,https://www.kaggle.com/competitions/icr-identify-age-related-conditions,,https://www.kaggle.com/code/debojitbasak02/icr-identifying-age-related-conditions
torch_1,2e16b192-e841-3c25-a28e-f43c9c33266c,runtimeerror,mat1 and mat2 shapes cannot be multiplied (64x27648 and 4500x500),"['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', '/tmp/ipykernel_23/2983194135.py in <module>\n     27 #set the device to cuda\n     28 device = torch.device(\'cuda\' if torch.cuda.is_available() else \'cpu\')\n---> 29 model = train()\n     30 torch.save(model.state_dict(), ""model.pt"")\n     31 print(""Model Saved Successfully"")\n', '/tmp/ipykernel_23/2983194135.py in train()\n     15             img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n     16             optimizer.zero_grad()\n---> 17             output1,output2 = net(img0,img1)\n     18             loss_contrastive = criterion(output1,output2,label)\n     19             loss_contrastive.backward()\n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1108         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1109                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1110             return forward_call(*input, **kwargs)\n   1111         # Do not call functions when jit is used\n   1112         full_backward_hooks, non_full_backward_hooks = [], []\n', '/tmp/ipykernel_23/139146338.py in forward(self, input1, input2)\n     43     def forward(self, input1, input2):\n     44         # forward pass of input 1\n---> 45         output1 = self.forward_once(input1)\n     46         # forward pass of input 2\n     47         output2 = self.forward_once(input2)\n', '/tmp/ipykernel_23/139146338.py in forward_once(self, x)\n     38         output = self.cnn1(x)\n     39         output = output.view(output.size()[0], -1)\n---> 40         output = self.fc1(output)\n     41         return output\n     42 \n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1108         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1109                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1110             return forward_call(*input, **kwargs)\n   1111         # Do not call functions when jit is used\n   1112         full_backward_hooks, non_full_backward_hooks = [], []\n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py in forward(self, input)\n    139     def forward(self, input):\n    140         for module in self:\n--> 141             input = module(input)\n    142         return input\n    143 \n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1108         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1109                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1110             return forward_call(*input, **kwargs)\n   1111         # Do not call functions when jit is used\n   1112         full_backward_hooks, non_full_backward_hooks = [], []\n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py in forward(self, input)\n    101 \n    102     def forward(self, input: Tensor) -> Tensor:\n--> 103         return F.linear(input, self.weight, self.bias)\n    104 \n    105     def extra_repr(self) -> str:\n', 'RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x27648 and 4500x500)']",implementation error,tensor shape mismatch,training,ML bug,CUHK03,,Unknown,,https://www.kaggle.com/datasets/priyanagda/cuhk03,,https://www.kaggle.com/code/ranjithbeast/siamese-nn-chuk
numpy_1,bf118e95-53d6-3590-a2f1-27af2f11890c,indexerror,index 16 is out of bounds for axis 0 with size 16,"['---------------------------------------------------------------------------', 'IndexError                                Traceback (most recent call last)', ""Cell In[40], line 18\n     16             plt.axis('off')\n     17             k+=1\n---> 18 visual()\n"", 'Cell In[40], line 13, in visual()\n     11 for j in range(n):\n     12     ax=plt.subplot(n,n,k+1)\n---> 13     img = (out[k]+1)/2\n     14     img = np.transpose(img,(1,2,0))\n     15     plt.imshow(img)\n', 'IndexError: index 16 is out of bounds for axis 0 with size 16']",implementation error,index error,evaluation/prediction,ML bug,CelebA-HQ resized (256x256),,GPL 2,,https://www.kaggle.com/datasets/badasstechie/celebahq-resized-256x256,,https://www.kaggle.com/code/whykartik/dcgan
torch_2,62b1ea91-a9e0-350d-a67f-552087ddef56,runtimeerror,"
method cannot be used as a value:
  File ""/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 1129
                self.in_proj_weight,
                self.in_proj_bias,
                self.out_proj.weight,
                ~~~~~~~~~~~~~~~~~~~~ <--- HERE
                self.out_proj.bias,
            )
","['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', 'Cell In[39], line 4\n      2 weights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\n      3 model = vit_b_16(weights=weights)\n----> 4 quantized_vit = model_quantization(model=model, save=True)\n      6 accuracy, duration = inference(model=model, dataloader=dataloader, class_dict=class_dict, device=device, image_num_stop=100)\n      8 print(""Inference took {} minutes"".format(duration))\n', 'Cell In[36], line 17, in model_quantization(model, backend, save)\n     14 torch.backends.quantized.engine = backend\n     16 quantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n---> 17 scripted_quantized_model = torch.jit.script(quantized_model)\n     18 if save:\n     19     scripted_quantized_model.save(""vit_scripted_quantized.pt"")\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_script.py:1284, in script(obj, optimize, _frames_up, _rcb, example_inputs)\n   1282 if isinstance(obj, torch.nn.Module):\n   1283     obj = call_prepare_scriptable_func(obj)\n-> 1284     return torch.jit._recursive.create_script_module(\n   1285         obj, torch.jit._recursive.infer_methods_to_compile\n   1286     )\n   1288 if isinstance(obj, dict):\n   1289     return create_script_dict(obj)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:480, in create_script_module(nn_module, stubs_fn, share_types, is_tracing)\n    478 if not is_tracing:\n    479     AttributeTypeIsSupportedChecker().check(nn_module)\n--> 480 return create_script_module_impl(nn_module, concrete_type, stubs_fn)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:542, in create_script_module_impl(nn_module, concrete_type, stubs_fn)\n    539     script_module._concrete_type = concrete_type\n    541 # Actually create the ScriptModule, initializing it with the function we just defined\n--> 542 script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\n    544 # Compile methods if necessary\n    545 if concrete_type not in concrete_type_store.methods_compiled:\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_script.py:614, in RecursiveScriptModule._construct(cpp_module, init_fn)\n    601 """"""\n    602 Construct a RecursiveScriptModule that\'s ready for use. PyTorch\n    603 code should use this to construct a RecursiveScriptModule instead\n   (...)\n    611     init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\n    612 """"""\n    613 script_module = RecursiveScriptModule(cpp_module)\n--> 614 init_fn(script_module)\n    616 # Finalize the ScriptModule: replace the nn.Module state with our\n    617 # custom implementations and flip the _initializing bit.\n    618 RecursiveScriptModule._finalize_scriptmodule(script_module)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:520, in create_script_module_impl.<locals>.init_fn(script_module)\n    517     scripted = orig_value\n    518 else:\n    519     # always reuse the provided stubs_fn to infer the methods to compile\n--> 520     scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\n    522 cpp_module.setattr(name, scripted)\n    523 script_module._modules[name] = scripted\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:542, in create_script_module_impl(nn_module, concrete_type, stubs_fn)\n    539     script_module._concrete_type = concrete_type\n    541 # Actually create the ScriptModule, initializing it with the function we just defined\n--> 542 script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\n    544 # Compile methods if necessary\n    545 if concrete_type not in concrete_type_store.methods_compiled:\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_script.py:614, in RecursiveScriptModule._construct(cpp_module, init_fn)\n    601 """"""\n    602 Construct a RecursiveScriptModule that\'s ready for use. PyTorch\n    603 code should use this to construct a RecursiveScriptModule instead\n   (...)\n    611     init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\n    612 """"""\n    613 script_module = RecursiveScriptModule(cpp_module)\n--> 614 init_fn(script_module)\n    616 # Finalize the ScriptModule: replace the nn.Module state with our\n    617 # custom implementations and flip the _initializing bit.\n    618 RecursiveScriptModule._finalize_scriptmodule(script_module)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:520, in create_script_module_impl.<locals>.init_fn(script_module)\n    517     scripted = orig_value\n    518 else:\n    519     # always reuse the provided stubs_fn to infer the methods to compile\n--> 520     scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\n    522 cpp_module.setattr(name, scripted)\n    523 script_module._modules[name] = scripted\n', '    [... skipping similar frames: RecursiveScriptModule._construct at line 614 (1 times), create_script_module_impl at line 542 (1 times), create_script_module_impl.<locals>.init_fn at line 520 (1 times)]\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:542, in create_script_module_impl(nn_module, concrete_type, stubs_fn)\n    539     script_module._concrete_type = concrete_type\n    541 # Actually create the ScriptModule, initializing it with the function we just defined\n--> 542 script_module = torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)\n    544 # Compile methods if necessary\n    545 if concrete_type not in concrete_type_store.methods_compiled:\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_script.py:614, in RecursiveScriptModule._construct(cpp_module, init_fn)\n    601 """"""\n    602 Construct a RecursiveScriptModule that\'s ready for use. PyTorch\n    603 code should use this to construct a RecursiveScriptModule instead\n   (...)\n    611     init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\n    612 """"""\n    613 script_module = RecursiveScriptModule(cpp_module)\n--> 614 init_fn(script_module)\n    616 # Finalize the ScriptModule: replace the nn.Module state with our\n    617 # custom implementations and flip the _initializing bit.\n    618 RecursiveScriptModule._finalize_scriptmodule(script_module)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:520, in create_script_module_impl.<locals>.init_fn(script_module)\n    517     scripted = orig_value\n    518 else:\n    519     # always reuse the provided stubs_fn to infer the methods to compile\n--> 520     scripted = create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\n    522 cpp_module.setattr(name, scripted)\n    523 script_module._modules[name] = scripted\n', ""File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:546, in create_script_module_impl(nn_module, concrete_type, stubs_fn)\n    544 # Compile methods if necessary\n    545 if concrete_type not in concrete_type_store.methods_compiled:\n--> 546     create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\n    547     # Create hooks after methods to ensure no name collisions between hooks and methods.\n    548     # If done before, hooks can overshadow methods that aren't exported.\n    549     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n"", 'File /opt/conda/lib/python3.10/site-packages/torch/jit/_recursive.py:397, in create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\n    394 property_defs = [p.def_ for p in property_stubs]\n    395 property_rcbs = [p.resolution_callback for p in property_stubs]\n--> 397 concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\n', 'RuntimeError: \nmethod cannot be used as a value:\n  File ""/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 1129\n                self.in_proj_weight,\n                self.in_proj_bias,\n                self.out_proj.weight,\n                ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                self.out_proj.bias,\n            )\n']",API misuse,runtime error,model construction,ML bug,imagenet_val,,Unknown,,https://www.kaggle.com/datasets/matanmillionshik/imagenet-val,,https://www.kaggle.com/code/matanmillionshik/vit-quantization
sklearn_4,615bd87e-83ab-3ae5-9ab6-16a1ac406b0e,valueerror,Classification metrics can't handle a mix of binary and continuous targets,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/1914514672.py in <module>\n----> 1 print(""Balenced Accuracy Score : {0}"".format(balanced_accuracy_score(y_test, preds)))\n', '/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py in balanced_accuracy_score(y_true, y_pred, sample_weight, adjusted)\n   1981     0.625\n   1982     """"""\n-> 1983     C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n   1984     with np.errstate(divide=""ignore"", invalid=""ignore""):\n   1985         per_class = np.diag(C) / C.sum(axis=1)\n', '/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py in confusion_matrix(y_true, y_pred, labels, sample_weight, normalize)\n    305     (0, 2, 1, 1)\n    306     """"""\n--> 307     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n    308     if y_type not in (""binary"", ""multiclass""):\n    309         raise ValueError(""%s is not supported"" % y_type)\n', '/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py in _check_targets(y_true, y_pred)\n     93         raise ValueError(\n     94             ""Classification metrics can\'t handle a mix of {0} and {1} targets"".format(\n---> 95                 type_true, type_pred\n     96             )\n     97         )\n', ""ValueError: Classification metrics can't handle a mix of binary and continuous targets""]",API misuse,data value violation,evaluation/prediction,ML bug,Credit Risk Dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/laotse/credit-risk-dataset,,https://www.kaggle.com/code/swapnilpatil205/credit-risk-analysis-complete-classification
numpy_2,58c74029-abf0-35c8-9de9-c0531b72c44a,attributeerror,'numpy.ndarray' object has no attribute 'join',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', 'Cell In[23], line 1\n----> 1 train_houseprice=X_train.join(Y_train)\n', ""AttributeError: 'numpy.ndarray' object has no attribute 'join'""]",API misuse,attribute error,data preparation,ML bug,House price prediction,,Unknown,,https://www.kaggle.com/datasets/shree1992/housedata,,https://www.kaggle.com/code/tarandeepkaur23/ba-project
numpy_3,aec42bcb-64cd-3155-ba7d-2ff17300b0f4,valueerror,"autodetected range of [nan, nan] is not finite","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""<ipython-input-14-ca0567e5d7f3> in <module>()\n     16 for col in cols:\n     17 \n---> 18     freq, edges = np.histogram(df[col].values)\n     19     dd[col] = hv.Histogram((edges, freq), label='ALL Loans').redim.label(x=' ')\n     20 \n"", '/opt/conda/lib/python3.6/site-packages/numpy/lib/histograms.py in histogram(a, bins, range, normed, weights, density)\n    778     a, weights = _ravel_and_check_weights(a, weights)\n    779 \n--> 780     bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)\n    781 \n    782     # Histogram is an integer or a float array depending on the weights.\n', ""/opt/conda/lib/python3.6/site-packages/numpy/lib/histograms.py in _get_bin_edges(a, bins, range, weights)\n    415             raise ValueError('`bins` must be positive, when an integer')\n    416 \n--> 417         first_edge, last_edge = _get_outer_edges(a, range)\n    418 \n    419     elif np.ndim(bins) == 1:\n"", '/opt/conda/lib/python3.6/site-packages/numpy/lib/histograms.py in _get_outer_edges(a, range)\n    313         if not (np.isfinite(first_edge) and np.isfinite(last_edge)):\n    314             raise ValueError(\n--> 315                 ""autodetected range of [{}, {}] is not finite"".format(first_edge, last_edge))\n    316 \n    317     # expand empty range to avoid divide by zero\n', 'ValueError: autodetected range of [nan, nan] is not finite']",API misuse,data value violation,data visualization,ML bug,HMEQ_Data,,CC0: Public Domain,,https://www.kaggle.com/datasets/ajay1735/hmeq-data,,https://www.kaggle.com/code/khaledyoung/scoring-project
torch_3,383dc0c1-0761-32fd-8ab1-db0a5aba780e,valueerror,Expected input batch_size (1) to match target batch_size (3).,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[69], line 1\n----> 1 out = CustomModel(**inputs,labels = target)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'Cell In[14], line 14, in CustomModelMultichoice.forward(self, input_ids, token_type_ids, attention_mask, labels)\n     12 if labels is not None:\n     13     loss_func = nn.NLLLoss()\n---> 14     loss = loss_func(logits.view(-1,self.num_choice),labels.view(-1))\n     15 return MultipleChoiceModelOutput(loss = loss,logits=logits,hidden_states= None,attentions =None)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:216, in NLLLoss.forward(self, input, target)\n    215 def forward(self, input: Tensor, target: Tensor) -> Tensor:\n--> 216     return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2704, in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)\n   2702 if size_average is not None or reduce is not None:\n   2703     reduction = _Reduction.legacy_get_string(size_average, reduce)\n-> 2704 return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\n', 'ValueError: Expected input batch_size (1) to match target batch_size (3).']",implementation error,tensor shape mismatch,model construction,ML bug,nodata,,nodata,,,,https://www.kaggle.com/code/quctngngvng/test-build-fine-tuning
torch_4,00b50e68-eadd-3518-96a3-a39daadbb8ba,typeerror,"empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:","['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[16], line 49\n     45         batch_outputs = self.out(doc_reps)\n     47         return batch_outputs\n---> 49 model = Model(vocab)\n', 'Cell In[16], line 9, in Model.__init__(self, vocab)\n      6 self.all_parameters = {}\n      8 parameters = []\n----> 9 self.word_encoder = WordLSTMEncoder(vocab)\n     10 self.word_attention = Attention(self.sent_rep_size)\n     11 # filter(判断函数, 可迭代对象)\n', 'Cell In[13], line 15, in WordLSTMEncoder.__init__(self, vocab)\n     12 self.dropout = nn.Dropout(dropout)\n     13 self.word_dims = 100\n---> 15 self.word_embed = nn.Embedding(vocab.word_size, self.word_dims, padding_idx=0)\n     17 extword_embed = vocab.load_pretrained_embs(word2vec_path)\n     18 extword_size, word_dims = extword_embed.shape\n', 'File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:142, in Embedding.__init__(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\n    140 self.scale_grad_by_freq = scale_grad_by_freq\n    141 if _weight is None:\n--> 142     self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs),\n    143                             requires_grad=not _freeze)\n    144     self.reset_parameters()\n    145 else:\n', 'TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n']",implementation error,invalid argument,model construction,ML bug,nlp_news_text,,Unknown,,https://www.kaggle.com/datasets/gareth11/nlp-news-text,,https://www.kaggle.com/code/littlebaikc/tianchi
numpy_4,1bf30d81-9479-3ddf-a67c-8a6326914d7a,attributeerror,'numpy.ndarray' object has no attribute 'nparray',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', '/tmp/ipykernel_23/3824881073.py in <module>\n      8   prediction_classes = np.concatenate([prediction_classes,\n      9                        np.argmax(model.predict(x), axis = -1)])\n---> 10   true_classes = np.concatenate([true_classes, np.argmax(y.nparray(), axis=-1)])\n     11 \n     12 \n', ""AttributeError: 'numpy.ndarray' object has no attribute 'nparray'""]",API misuse,attribute error,evaluation/prediction,ML bug,Chest X-Ray Images (Pneumonia),,Attribution 4.0 International (CC BY 4.0),,https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia,,https://www.kaggle.com/code/abdulazizadelaltayar/notebook7b12d653bf
torch_5,521b0219-1ec1-3d72-b873-e072e726afbf,typeerror,"conv2d() received an invalid combination of arguments - got (torch.device, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:","['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[130], line 4\n      1 if __name__ == ""__main__"":\n      2     \n      3     # Let\'s build our model\n----> 4     train(5)\n      5     print(\'Finished Training\')\n      7     # Test which classes performed well\n', 'Cell In[128], line 56, in train(num_epochs)\n     54 optimizer.zero_grad()\n     55 # predict classes using images from the training set\n---> 56 outputs = model(device)\n     57 # compute the loss based on model output and real labels\n     58 loss = loss_fn(outputs, class_names)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'Cell In[126], line 23, in Network.forward(self, input)\n     22 def forward(self, input):\n---> 23     output = F.relu(self.bn1(self.conv1(input)))      \n     24     output = F.relu(self.bn2(self.conv2(output)))     \n     25     output = self.pool(output)                        \n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463, in Conv2d.forward(self, input)\n    462 def forward(self, input: Tensor) -> Tensor:\n--> 463     return self._conv_forward(input, self.weight, self.bias)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459, in Conv2d._conv_forward(self, input, weight, bias)\n    455 if self.padding_mode != 'zeros':\n    456     return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n    457                     weight, bias, self.stride,\n    458                     _pair(0), self.dilation, self.groups)\n--> 459 return F.conv2d(input, weight, bias, self.stride,\n    460                 self.padding, self.dilation, self.groups)\n"", ""TypeError: conv2d() received an invalid combination of arguments - got (torch.device, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!torch.device!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!torch.device!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n""]",implementation error,invalid argument,training,ML bug,Stanford Dogs Dataset,,Allow academic research,,https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset,,https://www.kaggle.com/code/zezzeebka/notebookd1fa6aad97
numpy_5,21258b12-de8f-3085-8683-52138d5aa17c,valueerror,"Expected 1D or 2D array, got 5D array instead","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[6], line 1\n----> 1 np.savetxt('images.txt', images, delimiter=',', fmt='%d')\n"", 'File <__array_function__ internals>:180, in savetxt(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:1537, in savetxt(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\n   1535 # Handle 1-dimensional arrays\n   1536 if X.ndim == 0 or X.ndim > 2:\n-> 1537     raise ValueError(\n   1538         ""Expected 1D or 2D array, got %dD array instead"" % X.ndim)\n   1539 elif X.ndim == 1:\n   1540     # Common case -- 1d array of numbers\n   1541     if X.dtype.names is None:\n', 'ValueError: Expected 1D or 2D array, got 5D array instead']",API misuse,invalid argument,evaluation/prediction,ML bug,nodata,,nodata,,,,https://www.kaggle.com/code/saeedtahma/ac-gan-saving
numpy_6,d2d5322a-22d2-350a-a5e4-1618d73b3ab1,indexerror,"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices","['---------------------------------------------------------------------------', 'IndexError                                Traceback (most recent call last)', ""Cell In[39], line 13\n     11     x = np.expand_dims(img.copy(), axis=0)\n     12     X_data[i] = x / 255.0\n---> 13 X_data['id'] = train_labels['id']\n     15 # Printing train image and one hot encode shape & size\n     16 print('\\nTrain Images shape: ',X_data.shape,' size: {:,}'.format(X_data.size))\n"", 'IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices']",implementation error,index error,data preparation,ML bug,Dog Breeding,,Unknown,,https://www.kaggle.com/datasets/ahmedeko/dog-breeding,,https://www.kaggle.com/code/m7mdalien/notebook0e82b4517b
torch_6,3d372934-eff5-34fd-98a0-3fedf1531021,runtimeerror,The size of tensor a (64) must match the size of tensor b (6294) at non-singleton dimension 1,"['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', 'Cell In[55], line 7\n      4 scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=.1, threshold=1e-6)\n      6 for e in range(epoch):\n----> 7     pred,labels,loss = run_model(model,train_dataloader,optimizer)\n      8     #training accuracy\n      9     correct=0\n', 'Cell In[54], line 37, in run_model(model, dataloader, optimizer, train)\n     35 optimizer.step()\n     36 _, predicted_labels = torch.max(output, dim=1)\n---> 37 correct = (predicted_labels == label).sum().item()\n     38 total_correct += correct\n     39 total_samples += label.size(0)\n', 'RuntimeError: The size of tensor a (64) must match the size of tensor b (6294) at non-singleton dimension 1']",API misuse,tensor shape mismatch,training,ML bug,VizWiz-VQA,,Attribution 4.0 International (CC BY 4.0),,https://www.kaggle.com/datasets/lhanhsin/vizwiz,,https://www.kaggle.com/code/hazemabdelsalam/pattern-assignment-4
pandas_1,37d1aea2-cec3-319e-875b-54fddb1c3f02,attributeerror,'Categorical' object has no attribute 'cat',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', ""Cell In[23], line 4\n      1 #Average Trip Duration by Day of Week\n      2 # Convert the 'PDweek' column to a day of the week name\n      3 data1= pd.Categorical(data['PDweek'], categories=range(7), ordered=True)\n----> 4 data1.cat.rename_categories(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], inplace=True)\n      6 # Calculate the average trip duration for each day of the week\n      7 average_duration = data1.groupby('DayOfWeek')['Duration'].mean()\n"", ""AttributeError: 'Categorical' object has no attribute 'cat'""]",API misuse,attribute error,data visualization,ML bug,Seoul Bike Trip,,Attribution 4.0 International (CC BY 4.0),,https://www.kaggle.com/datasets/tagg27/seoul-bike-trip,,https://www.kaggle.com/code/tagg27/seoul-bike-trip-duration-prediction
torch_7,140f0858-cfee-3892-8def-d541e840a057,typeerror,"conv2d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:","['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[111], line 1\n----> 1 torch_googlenet_re(torch_img)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'Cell In[73], line 55, in GoogLeNet.forward(self, x)\n     53 x = self.inception3a(x)\n     54 # N x 256 x 28 x 28\n---> 55 x = self.inception3b(x)\n     56 # N x 480 x 28 x 28\n     57 x = self.maxpool3(x)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'Cell In[76], line 33, in Inception.forward(self, x)\n     32 def forward(self, x: Tensor) -> List[Tensor]:\n---> 33     branch1 = self.branch1(x)\n     34     branch2 = self.branch2(x)\n     35     branch3 = self.branch3(x)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'Cell In[108], line 8, in BasicConv2d.forward(self, x)\n      7 def forward(self, x: Tensor) -> Tensor:\n----> 8     x = self.conv(x)\n      9     x = self.bn(x)\n     10     return F.relu(x, inplace=True)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463, in Conv2d.forward(self, input)\n    462 def forward(self, input: Tensor) -> Tensor:\n--> 463     return self._conv_forward(input, self.weight, self.bias)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459, in Conv2d._conv_forward(self, input, weight, bias)\n    455 if self.padding_mode != 'zeros':\n    456     return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n    457                     weight, bias, self.stride,\n    458                     _pair(0), self.dilation, self.groups)\n--> 459 return F.conv2d(input, weight, bias, self.stride,\n    460                 self.padding, self.dilation, self.groups)\n"", ""TypeError: conv2d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list of [Tensor, Tensor, Tensor, Tensor]!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list of [Tensor, Tensor, Tensor, Tensor]!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n""]",implementation error,invalid argument,model construction,ML bug,A dog,,BSD 3-Clause,,https://github.com/pytorch/hub/raw/master/images/dog.jpg,,https://www.kaggle.com/code/sarvesh42kesharwani/ivy-incepition-v1-using-functional-api
numpy_7,127ce557-6d79-3486-bb70-0a08287a1e5c,typeerror,only integer scalar arrays can be converted to a scalar index,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', ""Cell In[16], line 168\n    166 print('\\n--- Predicting image from test set ---')\n    167 image_idx = 40                                                          # index of image to predict\n--> 168 predict(model, image_idx)\n    170 print('\\n--- Plotting weight distributions ---')\n    171 plot_weights(model)\n"", ""Cell In[16], line 71, in predict(model, image_idx)\n     68 image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n     69 pred = np.argmax(model.predict(image))\n---> 71 plot_sample(dataset['test_images'][image_idx], classes[dataset['test_labels'][image_idx]], classes[pred])\n     73 # extracting the output and appending to outputs\n     74 feature_maps = []\n"", 'TypeError: only integer scalar arrays can be converted to a scalar index']",data confusion,type error,evaluation/prediction,ML bug,MNIST_data,,Unknown,,https://www.kaggle.com/datasets/arushiburson/mnist-data,,https://www.kaggle.com/code/ghazouanihaythem/cnn-from-scratch
sklearn_5,eaa4e410-08a2-3b4d-8680-39335134a0fb,valueerror,"The number of FixedLocator locations (3), usually from a call to set_ticks, does not match the number of labels (2).","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[48], line 6\n      2 confusion_matrix = metrics.confusion_matrix(y_test , y_pred)\n      4 cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix , display_labels=[False,True])\n----> 6 cm_display.plot()\n      7 plt.show()\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py:181, in ConfusionMatrixDisplay.plot(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\n    179 if colorbar:\n    180     fig.colorbar(self.im_, ax=ax)\n--> 181 ax.set(\n    182     xticks=np.arange(n_classes),\n    183     yticks=np.arange(n_classes),\n    184     xticklabels=display_labels,\n    185     yticklabels=display_labels,\n    186     ylabel=""True label"",\n    187     xlabel=""Predicted label"",\n    188 )\n    190 ax.set_ylim((n_classes - 0.5, -0.5))\n    191 plt.setp(ax.get_xticklabels(), rotation=xticks_rotation)\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:147, in Artist.__init_subclass__.<locals>.<lambda>(self, **kwargs)\n    139 if not hasattr(cls.set, \'_autogenerated_signature\'):\n    140     # Don\'t overwrite cls.set if the subclass or one of its parents\n    141     # has defined a set method set itself.\n    142     # If there was no explicit definition, cls.set is inherited from\n    143     # the hierarchy of auto-generated set methods, which hold the\n    144     # flag _autogenerated_signature.\n    145     return\n--> 147 cls.set = lambda self, **kwargs: Artist.set(self, **kwargs)\n    148 cls.set.__name__ = ""set""\n    149 cls.set.__qualname__ = f""{cls.__qualname__}.set""\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:1231, in Artist.set(self, **kwargs)\n   1227 def set(self, **kwargs):\n   1228     # docstring and signature are auto-generated via\n   1229     # Artist._update_set_signature_and_docstring() at the end of the\n   1230     # module.\n-> 1231     return self._internal_update(cbook.normalize_kwargs(kwargs, self))\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:1223, in Artist._internal_update(self, kwargs)\n   1216 def _internal_update(self, kwargs):\n   1217     """"""\n   1218     Update artist properties without prenormalizing them, but generating\n   1219     errors as if calling `set`.\n   1220 \n   1221     The lack of prenormalization is to maintain backcompatibility.\n   1222     """"""\n-> 1223     return self._update_props(\n   1224         kwargs, ""{cls.__name__}.set() got an unexpected keyword argument ""\n   1225         ""{prop_name!r}"")\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:1199, in Artist._update_props(self, props, errfmt)\n   1196             if not callable(func):\n   1197                 raise AttributeError(\n   1198                     errfmt.format(cls=type(self), prop_name=k))\n-> 1199             ret.append(func(v))\n   1200 if ret:\n   1201     self.pchanged()\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:74, in _axis_method_wrapper.__set_name__.<locals>.wrapper(self, *args, **kwargs)\n     73 def wrapper(self, *args, **kwargs):\n---> 74     return get_method(self)(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:297, in rename_parameter.<locals>.wrapper(*args, **kwargs)\n    292     warn_deprecated(\n    293         since, message=f""The {old!r} parameter of {func.__name__}() ""\n    294         f""has been renamed {new!r} since Matplotlib {since}; support ""\n    295         f""for the old name will be dropped %(removal)s."")\n    296     kwargs[new] = kwargs.pop(old)\n--> 297 return func(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/axis.py:1969, in Axis.set_ticklabels(self, labels, minor, fontdict, **kwargs)\n   1965 if isinstance(locator, mticker.FixedLocator):\n   1966     # Passing [] as a list of labels is often used as a way to\n   1967     # remove all tick labels, so only error for > 0 labels\n   1968     if len(locator.locs) != len(labels) and len(labels) != 0:\n-> 1969         raise ValueError(\n   1970             ""The number of FixedLocator locations""\n   1971             f"" ({len(locator.locs)}), usually from a call to""\n   1972             "" set_ticks, does not match""\n   1973             f"" the number of labels ({len(labels)})."")\n   1974     tickd = {loc: lab for loc, lab in zip(locator.locs, labels)}\n   1975     func = functools.partial(self._format_with_dict, tickd)\n', 'ValueError: The number of FixedLocator locations (3), usually from a call to set_ticks, does not match the number of labels (2).']",data confusion,tensor shape mismatch,evaluation/prediction,ML bug,Iris dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/himanshunakrani/iris-dataset,,https://www.kaggle.com/code/simrahimran/python-hw4
numpy_8,c2016d3e-d640-3211-8465-401ae0df4a5e,typeerror,<lambda>() takes 2 positional arguments but 72 were given,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[104], line 11\n      8 for generation in range(num_generations):\n      9     # Оценка фитнеса\n     10     fitnesses = map(evaluate_fitness, population)\n---> 11     for individual, fitness in zip(population, fitnesses):\n     12         individual.fitness.values = fitness\n     14     # Выбор следующего поколения\n', 'Cell In[103], line 9, in evaluate_fitness(individual)\n      7 def evaluate_fitness(individual):\n      8     # Вычислите значения признаков на основе individual\n----> 9     X_train_gp = transform_gp_structure(individual, X_train)  # Вычисление новых признаков на обучающей выборке\n     10     rf_model_gp.fit(X_train_gp, y_train)  # Обучение модели случайного леса с новыми признаками\n     11     X_test_gp = transform_gp_structure(individual, X_test)  # Вычисление новых признаков на тестовой выборке\n', 'Cell In[103], line 4, in transform_gp_structure(individual, X)\n      2 def transform_gp_structure(individual, X):\n      3     expr = gp.compile(individual, pset)\n----> 4     return np.array([expr(*row) for row in X])\n', 'Cell In[103], line 4, in <listcomp>(.0)\n      2 def transform_gp_structure(individual, X):\n      3     expr = gp.compile(individual, pset)\n----> 4     return np.array([expr(*row) for row in X])\n', 'TypeError: <lambda>() takes 2 positional arguments but 72 were given']",implementation error,value error,data preparation,ML bug,Home Credit Default Risk,,Allow academic research,,https://www.kaggle.com/competitions/home-credit-default-risk/data,,https://www.kaggle.com/code/anastasiaspirova/notebook64b9b0c0cc
torch_8,73d9fc7d-49ff-3a19-a77e-86cd37e29978,runtimeerror,"Given groups=1, weight of size [40, 3, 3, 3], expected input[64, 196, 196, 3] to have 3 channels, but got 196 channels instead","['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', '/tmp/ipykernel_24/1699604028.py in <module>\n      3 \n      4 model_ft, train_acc_history, val_acc_history = train_model(\n----> 5     model_ft, train_loader, test_loader, criterion, optimizer, num_epochs=3\n      6 )\n', '/tmp/ipykernel_24/2233534305.py in train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs)\n     27             with torch.set_grad_enabled(True):\n     28                 with torch.cuda.amp.autocast():\n---> 29                     outputs = model(inputs)\n     30                     loss = criterion(outputs, labels)\n     31 \n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1188         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1189                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1190             return forward_call(*input, **kwargs)\n   1191         # Do not call functions when jit is used\n   1192         full_backward_hooks, non_full_backward_hooks = [], []\n', '/opt/conda/lib/python3.7/site-packages/timm/models/efficientnet.py in forward(self, x)\n    555 \n    556     def forward(self, x):\n--> 557         x = self.forward_features(x)\n    558         x = self.forward_head(x)\n    559         return x\n', '/opt/conda/lib/python3.7/site-packages/timm/models/efficientnet.py in forward_features(self, x)\n    538 \n    539     def forward_features(self, x):\n--> 540         x = self.conv_stem(x)\n    541         x = self.bn1(x)\n    542         if self.grad_checkpointing and not torch.jit.is_scripting():\n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1188         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1189                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1190             return forward_call(*input, **kwargs)\n   1191         # Do not call functions when jit is used\n   1192         full_backward_hooks, non_full_backward_hooks = [], []\n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py in forward(self, input)\n    461 \n    462     def forward(self, input: Tensor) -> Tensor:\n--> 463         return self._conv_forward(input, self.weight, self.bias)\n    464 \n    465 class Conv3d(_ConvNd):\n', '/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py in _conv_forward(self, input, weight, bias)\n    458                             _pair(0), self.dilation, self.groups)\n    459         return F.conv2d(input, weight, bias, self.stride,\n--> 460                         self.padding, self.dilation, self.groups)\n    461 \n    462     def forward(self, input: Tensor) -> Tensor:\n', 'RuntimeError: Given groups=1, weight of size [40, 3, 3, 3], expected input[64, 196, 196, 3] to have 3 channels, but got 196 channels instead']",implementation error,tensor shape mismatch,training,ML bug,Scenery Watermark Detection,,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),,https://www.kaggle.com/datasets/qwertyforce/scenery-watermarks,,https://www.kaggle.com/code/s0urabhmehta/waterdetection-classification
torch_9,386ee160-9a07-33f9-9d9c-2211c532f6c1,runtimeerror,"stack expects each tensor to be equal size, but got [3, 123, 123] at entry 0 and [3, 73, 73] at entry 1","['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', 'Cell In[6], line 1\n----> 1 show_batch(dataloader)\n', 'Cell In[5], line 7, in show_batch(dl)\n      6 def show_batch(dl):\n----> 7     for images, _ in dl:\n      8         show_images(images)\n      9         break\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634, in _BaseDataLoaderIter.__next__(self)\n    631 if self._sampler_iter is None:\n    632     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    633     self._reset()  # type: ignore[call-arg]\n--> 634 data = self._next_data()\n    635 self._num_yielded += 1\n    636 if self._dataset_kind == _DatasetKind.Iterable and \\\n    637         self._IterableDataset_len_called is not None and \\\n    638         self._num_yielded > self._IterableDataset_len_called:\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678, in _SingleProcessDataLoaderIter._next_data(self)\n    676 def _next_data(self):\n    677     index = self._next_index()  # may raise StopIteration\n--> 678     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    679     if self._pin_memory:\n    680         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54, in _MapDatasetFetcher.fetch(self, possibly_batched_index)\n     52 else:\n     53     data = self.dataset[possibly_batched_index]\n---> 54 return self.collate_fn(data)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:264, in default_collate(batch)\n    203 def default_collate(batch):\n    204     r""""""\n    205         Function that takes in a batch of data and puts the elements within the batch\n    206         into a tensor with an additional outer dimension - batch size. The exact output type can be\n   (...)\n    262             >>> default_collate(batch)  # Handle `CustomType` automatically\n    263     """"""\n--> 264     return collate(batch, collate_fn_map=default_collate_fn_map)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142, in collate(batch, collate_fn_map)\n    139 transposed = list(zip(*batch))  # It may be accessed twice, so we use a list.\n    141 if isinstance(elem, tuple):\n--> 142     return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n    143 else:\n    144     try:\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142, in <listcomp>(.0)\n    139 transposed = list(zip(*batch))  # It may be accessed twice, so we use a list.\n    141 if isinstance(elem, tuple):\n--> 142     return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n    143 else:\n    144     try:\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119, in collate(batch, collate_fn_map)\n    117 if collate_fn_map is not None:\n    118     if elem_type in collate_fn_map:\n--> 119         return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n    121     for collate_type in collate_fn_map:\n    122         if isinstance(elem, collate_type):\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162, in collate_tensor_fn(batch, collate_fn_map)\n    160     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n    161     out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n--> 162 return torch.stack(batch, 0, out=out)\n', 'RuntimeError: stack expects each tensor to be equal size, but got [3, 123, 123] at entry 0 and [3, 73, 73] at entry 1']",API misuse,tensor shape mismatch,data preparation,ML bug,Eyes Image Dataset For Machine Learning,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/brsdincer/eyes-image-dataset-for-machine-learning,,https://www.kaggle.com/code/chiragsethi50/dcgan
torch_10,1e5d4550-42a7-3470-9b10-06287b971037,typeerror,'module' object is not callable,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', '/tmp/ipykernel_23/2702201051.py in <module>\n      2 train_data=torchvision.datasets.ImageFolder(root = train_data_path,transform=transforms)\n      3 train_dataloader = DataLoader(dataset = train_data,batch_size=64,shuffle=True,drop_last=False)\n----> 4 for data in train_dataloader:#训练步骤\n      5     imgs,targets = data\n      6     if torch.cuda.is_available():\n', '/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)\n    626                 # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    627                 self._reset()  # type: ignore[call-arg]\n--> 628             data = self._next_data()\n    629             self._num_yielded += 1\n    630             if self._dataset_kind == _DatasetKind.Iterable and \\\n', '/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py in _next_data(self)\n    669     def _next_data(self):\n    670         index = self._next_index()  # may raise StopIteration\n--> 671         data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    672         if self._pin_memory:\n    673             data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n', '/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py in fetch(self, possibly_batched_index)\n     56                 data = self.dataset.__getitems__(possibly_batched_index)\n     57             else:\n---> 58                 data = [self.dataset[idx] for idx in possibly_batched_index]\n     59         else:\n     60             data = self.dataset[possibly_batched_index]\n', '/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py in <listcomp>(.0)\n     56                 data = self.dataset.__getitems__(possibly_batched_index)\n     57             else:\n---> 58                 data = [self.dataset[idx] for idx in possibly_batched_index]\n     59         else:\n     60             data = self.dataset[possibly_batched_index]\n', '/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py in __getitem__(self, index)\n    229         sample = self.loader(path)\n    230         if self.transform is not None:\n--> 231             sample = self.transform(sample)\n    232         if self.target_transform is not None:\n    233             target = self.target_transform(target)\n', ""TypeError: 'module' object is not callable""]",API misuse,invalid argument,training,ML bug,101deeplearn,,Unknown,,https://www.kaggle.com/datasets/yucindy/101deeplearn,,https://www.kaggle.com/code/lazydead/notebook012be9d8bc
numpy_9,1d03d99d-faf5-3477-b4a4-875c09c93683,valueerror,zero-dimensional arrays cannot be concatenated,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[14], line 20\n     17 regression_weights_directory = '/kaggle/input/adjusted-survival-2019'\n     19 # Load initial regression loss weights from the directory\n---> 20 regression_weight = load_loss_weights_from_directory(regression_weights_directory)\n     22 # Training loop for regression task\n     23 num_epochs_update_regression = 5  # Number of epochs to update the regression weight\n"", 'Cell In[14], line 9, in load_loss_weights_from_directory(directory_path)\n      7 weight_files = [filename for filename in os.listdir(directory_path) if filename.endswith("".npy"")]\n      8 weights = [np.load(os.path.join(directory_path, filename)) for filename in weight_files]\n----> 9 return np.concatenate(weights)\n', 'File <__array_function__ internals>:180, in concatenate(*args, **kwargs)\n', 'ValueError: zero-dimensional arrays cannot be concatenated']",API misuse,data value violation,model construction,ML bug,adjusted_survival_2019,,Unknown,,https://www.kaggle.com/datasets/haniyafahad/adjusted-survival-2019,,https://www.kaggle.com/code/maria2023/updated-weights-2019
sklearn_6,b79cc309-bf77-3d50-ae95-0ecd8ef17bb9,valueerror,The feature names should match those that were passed during fit.,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[46], line 1\n----> 1 predictions = FReg.predict(test_ds)\n      2 submissions_df = pd.DataFrame({\n      3     ""ID"" : test_data[\'ID\'],\n      4     ""Predictions"" : predictions\n      5 })\n      7 submissions_df.to_csv(\'submission_csv\', index = False)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:981, in ForestRegressor.predict(self, X)\n    979 check_is_fitted(self)\n    980 # Check data\n--> 981 X = self._validate_X_predict(X)\n    983 # Assign chunk of trees to jobs\n    984 n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:602, in BaseForest._validate_X_predict(self, X)\n    599 """"""\n    600 Validate X whenever one tries to predict, apply, predict_proba.""""""\n    601 check_is_fitted(self)\n--> 602 X = self._validate_data(X, dtype=DTYPE, accept_sparse=""csr"", reset=False)\n    603 if issparse(X) and (X.indices.dtype != np.intc or X.indptr.dtype != np.intc):\n    604     raise ValueError(""No support for np.int64 index based sparse matrices"")\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/base.py:548, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)\n    483 def _validate_data(\n    484     self,\n    485     X=""no_validation"",\n   (...)\n    489     **check_params,\n    490 ):\n    491     """"""Validate input data and set or check the `n_features_in_` attribute.\n    492 \n    493     Parameters\n   (...)\n    546         validated.\n    547     """"""\n--> 548     self._check_feature_names(X, reset=reset)\n    550     if y is None and self._get_tags()[""requires_y""]:\n    551         raise ValueError(\n    552             f""This {self.__class__.__name__} estimator ""\n    553             ""requires y to be passed, but the target y is None.""\n    554         )\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/base.py:481, in BaseEstimator._check_feature_names(self, X, reset)\n    476 if not missing_names and not unexpected_names:\n    477     message += (\n    478         ""Feature names must be in the same order as they were in fit.\\n""\n    479     )\n--> 481 raise ValueError(message)\n', 'ValueError: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- BsmtFullBath\n- BsmtHalfBath\n- Functional\n- MSZoning\n- Utilities\n']",API misuse,feature name mismatch,evaluation/prediction,ML bug,House Prices - Advanced Regression Techniques,,MIT,,https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data,,https://www.kaggle.com/code/neronasfloga/house-saleprice
torch_11,105af724-52f4-3631-832d-7b0de11d044b,runtimeerror,"stack expects each tensor to be equal size, but got [19] at entry 0 and [21] at entry 1","---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-24-db70380867c1> in <cell line: 1>()
----> 1 train(st_train,2)

<ipython-input-20-e67e75c40a2c> in train(traindata, epochs)
      8         bloss = []
      9         numb = 0
---> 10         for idx ,(cx, cy)  in enumerate(datal):
     11             optimizer.zero_grad()
     12 #             print(cx.shape,cy.shape)

/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py in __next__(self)
    628                 # TODO(https://github.com/pytorch/pytorch/issues/76750)
    629                 self._reset()  # type: ignore[call-arg]
--> 630             data = self._next_data()
    631             self._num_yielded += 1
    632             if self._dataset_kind == _DatasetKind.Iterable and \

/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py in _next_data(self)
    671     def _next_data(self):
    672         index = self._next_index()  # may raise StopIteration
--> 673         data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
    674         if self._pin_memory:
    675             data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)

/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py in fetch(self, possibly_batched_index)
     53         else:
     54             data = self.dataset[possibly_batched_index]
---> 55         return self.collate_fn(data)

/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py in default_collate(batch)
    315         >>> default_collate(batch)  # Handle `CustomType` automatically
    316     """"""
--> 317     return collate(batch, collate_fn_map=default_collate_fn_map)

/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py in collate(batch, collate_fn_map)
    172 
    173         if isinstance(elem, tuple):
--> 174             return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
    175         else:
    176             try:

/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py in <listcomp>(.0)
    172 
    173         if isinstance(elem, tuple):
--> 174             return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
    175         else:
    176             try:

/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py in collate(batch, collate_fn_map)
    140     if collate_fn_map is not None:
    141         if elem_type in collate_fn_map:
--> 142             return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
    143 
    144         for collate_type in collate_fn_map:

/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py in collate_tensor_fn(batch, collate_fn_map)
    212         storage = elem._typed_storage()._new_shared(numel, device=elem.device)
    213         out = elem.new(storage).resize_(len(batch), *list(elem.size()))
--> 214     return torch.stack(batch, 0, out=out)
    215 
    216 

RuntimeError: stack expects each tensor to be equal size, but got [19] at entry 0 and [21] at entry 1",implementation error,tensor shape mismatch,training,ML bug,Glove.6B.50d,,Open Data Commons Public Domain Dedication and License (PDDL),,http://nlp.stanford.edu/data/glove.6B.zip,,https://www.kaggle.com/code/sankalpthakur99/assignment4-nlp
sklearn_7,be156106-9540-36c1-8314-5e1815918005,valueerror,could not convert string to float: 'Male',"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_28/2403320104.py in <module>\n     11 # Train the model\n     12 rf = RandomForestRegressor(n_estimators=100, random_state=42)\n---> 13 rf.fit(X_train, y_train)\n     14 \n     15 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py in fit(self, X, y, sample_weight)\n    326             raise ValueError(""sparse multilabel-indicator for y is not supported."")\n    327         X, y = self._validate_data(\n--> 328             X, y, multi_output=True, accept_sparse=""csc"", dtype=DTYPE\n    329         )\n    330         if sample_weight is not None:\n', '/opt/conda/lib/python3.7/site-packages/sklearn/base.py in _validate_data(self, X, y, reset, validate_separately, **check_params)\n    579                 y = check_array(y, **check_y_params)\n    580             else:\n--> 581                 X, y = check_X_y(X, y, **check_params)\n    582             out = X, y\n    583 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\n    974         ensure_min_samples=ensure_min_samples,\n    975         ensure_min_features=ensure_min_features,\n--> 976         estimator=estimator,\n    977     )\n    978 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\n    744                     array = array.astype(dtype, casting=""unsafe"", copy=False)\n    745                 else:\n--> 746                     array = np.asarray(array, order=order, dtype=dtype)\n    747             except ComplexWarning as complex_warning:\n    748                 raise ValueError(\n', '/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py in __array__(self, dtype)\n   1991 \n   1992     def __array__(self, dtype: NpDtype | None = None) -> np.ndarray:\n-> 1993         return np.asarray(self._values, dtype=dtype)\n   1994 \n   1995     def __array_wrap__(\n', ""ValueError: could not convert string to float: 'Male'""]",implementation error,data value violation,training,ML bug,Shop Customer Data,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/datascientistanna/customers-dataset,,https://www.kaggle.com/code/sridharstreaks/customer-segmentation-and-spending-prediction
sklearn_8,c0f5d509-c3c3-3e26-b07f-056418c17830,valueerror,Classification metrics can't handle a mix of continuous-multioutput and multiclass targets,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[243], line 4\n      1 # y_pred = RF.predict(X_val)\n      2 \n      3 # Calculating the accuracy of the model\n----> 4 accuracy = accuracy_score(x, y)\n      6 print(""Accuracy: "", accuracy)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192, in validate_params.<locals>.decorator.<locals>.wrapper(*args, **kwargs)\n    187 validate_parameter_constraints(\n    188     parameter_constraints, params, caller_name=func.__qualname__\n    189 )\n    191 try:\n--> 192     return func(*args, **kwargs)\n    193 except InvalidParameterError as e:\n    194     # When the function is just a wrapper around an estimator, we allow\n    195     # the function to delegate validation to the estimator, but we replace\n    196     # the name of the estimator by the name of the function in the error\n    197     # message to avoid confusion.\n    198     msg = re.sub(\n    199         r""parameter of \\w+ must be"",\n    200         f""parameter of {func.__qualname__} must be"",\n    201         str(e),\n    202     )\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221, in accuracy_score(y_true, y_pred, normalize, sample_weight)\n    155 """"""Accuracy classification score.\n    156 \n    157 In multilabel classification, this function computes subset accuracy:\n   (...)\n    217 0.5\n    218 """"""\n    220 # Compute accuracy for each possible representation\n--> 221 y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n    222 check_consistent_length(y_true, y_pred, sample_weight)\n    223 if y_type.startswith(""multilabel""):\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:95, in _check_targets(y_true, y_pred)\n     92     y_type = {""multiclass""}\n     94 if len(y_type) > 1:\n---> 95     raise ValueError(\n     96         ""Classification metrics can\'t handle a mix of {0} and {1} targets"".format(\n     97             type_true, type_pred\n     98         )\n     99     )\n    101 # We can\'t have more than one value on y_type => The set is no more needed\n    102 y_type = y_type.pop()\n', ""ValueError: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets""]",implementation error,data value violation,evaluation/prediction,ML bug,Prudential Life Insurance Assessment,,No private sharing outside teams,,https://www.kaggle.com/competitions/prudential-life-insurance-assessment/data,,https://www.kaggle.com/code/kanishksaxena1812/prud-life
pandas_2,3d4c9485-1096-3c59-92b5-6df10382af18,keyerror,"""['LotFrontage', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'] not found in axis""","['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', ""Cell In[35], line 12\n      9     num.append(x[a])\n     10 a=a+1\n---> 12 data.drop(['LotFrontage','Alley','FireplaceQu','PoolQC','Fence', 'MiscFeature'], axis=1, inplace=True)\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n    325 if len(args) > num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--> 331 return func(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5399, in DataFrame.drop(self, labels, axis, index, columns, level, inplace, errors)\n   5251 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""])\n   5252 def drop(  # type: ignore[override]\n   5253     self,\n   (...)\n   5260     errors: IgnoreRaise = ""raise"",\n   5261 ) -> DataFrame | None:\n   5262     """"""\n   5263     Drop specified labels from rows or columns.\n   5264 \n   (...)\n   5397             weight  1.0     0.8\n   5398     """"""\n-> 5399     return super().drop(\n   5400         labels=labels,\n   5401         axis=axis,\n   5402         index=index,\n   5403         columns=columns,\n   5404         level=level,\n   5405         inplace=inplace,\n   5406         errors=errors,\n   5407     )\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n    325 if len(args) > num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--> 331 return func(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4505, in NDFrame.drop(self, labels, axis, index, columns, level, inplace, errors)\n   4503 for axis, labels in axes.items():\n   4504     if labels is not None:\n-> 4505         obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n   4507 if inplace:\n   4508     self._update_inplace(obj)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4546, in NDFrame._drop_axis(self, labels, axis, level, errors, only_slice)\n   4544         new_axis = axis.drop(labels, level=level, errors=errors)\n   4545     else:\n-> 4546         new_axis = axis.drop(labels, errors=errors)\n   4547     indexer = axis.get_indexer(new_axis)\n   4549 # Case for non-unique axis\n   4550 else:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6934, in Index.drop(self, labels, errors)\n   6932 if mask.any():\n   6933     if errors != ""ignore"":\n-> 6934         raise KeyError(f""{list(labels[mask])} not found in axis"")\n   6935     indexer = indexer[~mask]\n   6936 return self.delete(indexer)\n', 'KeyError: ""[\'LotFrontage\', \'Alley\', \'FireplaceQu\', \'PoolQC\', \'Fence\', \'MiscFeature\'] not found in axis""']",implementation error,key error,data preparation,ML bug,House Prices - Advanced Regression Techniques,,MIT,,https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data,,https://www.kaggle.com/code/thimote/final-assignment-krummenacker-timothe-house-prices
numpy_10,efef4f9c-d212-3462-bbd4-acaa7a5e4eba,valueerror,a must be 1-dimensional,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[48], line 9\n      6 model = load_checkpoint('checkpoint.pth')\n      8 # Testing with a random image from the test set\n----> 9 test_image_path = np.random.choice(test_ds.imgs)[0]\n     10 display_image(test_image_path)\n     12 probs, classes = predict(test_image_path, model)\n"", 'File mtrand.pyx:911, in numpy.random.mtrand.RandomState.choice()\n', 'ValueError: a must be 1-dimensional']",API misuse,invalid argument,evaluation/prediction,ML bug,Flower data,,Unknown,,https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz,,https://www.kaggle.com/code/ashioyajotham/pytorch-image-classifier
pandas_3,0632671a-dd6f-30b9-93b8-e2a121561569,valueerror,"columns overlap but no suffix specified: Index(['name_count'], dtype='object')","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[94], line 1\n----> 1 train = procData(train, name_count, RescuerID)\n      2 test = procData(test, name_count, RescuerID)\n', 'Cell In[93], line 14, in procData(data, name_count, RescuerID)\n     12 data[""NameLen""] = data[""Name""].fillna("""").str.len()\n     13 data[""SinNombre""] = data[""Name""].str.lower().replace("" "", """") == ""nonameyet""\n---> 14 data = data.join(name_count, on=""Name"")\n     15 data[""name_count""] = data[""name_count""].fillna(0)\n     17 data = data.drop([""Name"", ""RescuerID"", ""Description""], axis=1)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:9729, in DataFrame.join(self, other, on, how, lsuffix, rsuffix, sort, validate)\n   9566 def join(\n   9567     self,\n   9568     other: DataFrame | Series | Iterable[DataFrame | Series],\n   (...)\n   9574     validate: str | None = None,\n   9575 ) -> DataFrame:\n   9576     """"""\n   9577     Join columns of another DataFrame.\n   9578 \n   (...)\n   9727     5  K1  A5   B1\n   9728     """"""\n-> 9729     return self._join_compat(\n   9730         other,\n   9731         on=on,\n   9732         how=how,\n   9733         lsuffix=lsuffix,\n   9734         rsuffix=rsuffix,\n   9735         sort=sort,\n   9736         validate=validate,\n   9737     )\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:9768, in DataFrame._join_compat(self, other, on, how, lsuffix, rsuffix, sort, validate)\n   9758     if how == ""cross"":\n   9759         return merge(\n   9760             self,\n   9761             other,\n   (...)\n   9766             validate=validate,\n   9767         )\n-> 9768     return merge(\n   9769         self,\n   9770         other,\n   9771         left_on=on,\n   9772         how=how,\n   9773         left_index=on is None,\n   9774         right_index=True,\n   9775         suffixes=(lsuffix, rsuffix),\n   9776         sort=sort,\n   9777         validate=validate,\n   9778     )\n   9779 else:\n   9780     if on is not None:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/reshape/merge.py:162, in merge(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\n    131 @Substitution(""\\nleft : DataFrame or named Series"")\n    132 @Appender(_merge_doc, indents=0)\n    133 def merge(\n   (...)\n    146     validate: str | None = None,\n    147 ) -> DataFrame:\n    148     op = _MergeOperation(\n    149         left,\n    150         right,\n   (...)\n    160         validate=validate,\n    161     )\n--> 162     return op.get_result(copy=copy)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/reshape/merge.py:811, in _MergeOperation.get_result(self, copy)\n    807     self.left, self.right = self._indicator_pre_merge(self.left, self.right)\n    809 join_index, left_indexer, right_indexer = self._get_join_info()\n--> 811 result = self._reindex_and_concat(\n    812     join_index, left_indexer, right_indexer, copy=copy\n    813 )\n    814 result = result.__finalize__(self, method=self._merge_type)\n    816 if self.indicator:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/reshape/merge.py:763, in _MergeOperation._reindex_and_concat(self, join_index, left_indexer, right_indexer, copy)\n    760 left = self.left[:]\n    761 right = self.right[:]\n--> 763 llabels, rlabels = _items_overlap_with_suffix(\n    764     self.left._info_axis, self.right._info_axis, self.suffixes\n    765 )\n    767 if left_indexer is not None and not is_range_indexer(left_indexer, len(left)):\n    768     # Pinning the index here (and in the right code just below) is not\n    769     #  necessary, but makes the `.take` more performant if we have e.g.\n    770     #  a MultiIndex for left.index.\n    771     lmgr = left._mgr.reindex_indexer(\n    772         join_index,\n    773         left_indexer,\n   (...)\n    778         use_na_proxy=True,\n    779     )\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2604, in _items_overlap_with_suffix(left, right, suffixes)\n   2601 lsuffix, rsuffix = suffixes\n   2603 if not lsuffix and not rsuffix:\n-> 2604     raise ValueError(f""columns overlap but no suffix specified: {to_rename}"")\n   2606 def renamer(x, suffix):\n   2607     """"""\n   2608     Rename the left and right indices.\n   2609 \n   (...)\n   2620     x : renamed column name\n   2621     """"""\n', ""ValueError: columns overlap but no suffix specified: Index(['name_count'], dtype='object')""]",API misuse,data value violation,data preparation,ML bug,PetFinder.my Adoption Prediction,,Allow academic research,,https://www.kaggle.com/competitions/petfinder-adoption-prediction/data,,https://www.kaggle.com/code/bernaber/clase-1-modulo-4
torch_12,27304d3d-9c0f-35f4-ae23-1b6737dc9f5a,typeerror,"ne() received an invalid combination of arguments - got (NoneType), but expected one of:","['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[7], line 25\n     18 # Generate response\n     19 with torch.no_grad():\n     20     output = model.generate(\n     21         input_ids,\n     22         max_length=input_ids.size(1) + 50,  # Adjust the additional tokens as needed\n     23         num_return_sequences=1,\n     24         pad_token_id=tokenizer.eos_token_id,\n---> 25         attention_mask=input_ids.ne(tokenizer.pad_token_id)\n     26     )\n     28 # Pad the generated sequence\n     29 padded_output = output[:, input_ids.size(1):]\n', ""TypeError: ne() received an invalid combination of arguments - got (NoneType), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!NoneType!)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (!NoneType!)\n""]",API misuse,invalid argument,training,ML bug,Logical Reasoning Improvement Dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/thedevastator/logical-reasoning-improvement-dataset,,https://www.kaggle.com/code/mpwolke/logical-reasoning
sklearn_9,9cce2078-6201-38a6-b6b6-18a2aa3638bd,valueerror,"Logistic Regression supports only penalties in ['l1', 'l2'], got elasticnet.","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""<ipython-input-63-9903cc3cf9bb> in <module>()\n      1 #elasticnet\n      2 log_reg2 = LogisticRegression(max_iter=1000, solver='liblinear', penalty='elasticnet')\n----> 3 log_reg2.fit(X_train, y_train)\n      4 y_pred = log_reg2.predict(X_valid)\n      5 \n"", '/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self, X, y, sample_weight)\n   1278                              ""positive; got (tol=%r)"" % self.tol)\n   1279 \n-> 1280         solver = _check_solver(self.solver, self.penalty, self.dual)\n   1281 \n   1282         if solver in [\'newton-cg\']:\n', '/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in _check_solver(solver, penalty, dual)\n    441     if penalty not in all_penalties:\n    442         raise ValueError(""Logistic Regression supports only penalties in %s,""\n--> 443                          "" got %s."" % (all_penalties, penalty))\n    444 \n    445     if solver not in [\'liblinear\', \'saga\'] and penalty != \'l2\':\n', ""ValueError: Logistic Regression supports only penalties in ['l1', 'l2'], got elasticnet.""]",API misuse,invalid argument,training,ML bug,Bank Marketing,,Attribution 4.0 International (CC BY 4.0),,https://www.kaggle.com/datasets/henriqueyamahata/bank-marketing,,https://www.kaggle.com/code/emiliiaromanova/eda-bank-marketing-dataset-27abc8
pandas_4,5706cd60-4b1c-347a-a5c1-0ce967ee0ec6,indexerror,single positional indexer is out-of-bounds,"['---------------------------------------------------------------------------', 'IndexError                                Traceback (most recent call last)', ""<ipython-input-28-f6e807894ad0> in <module>\n     11 plt.figure(0, figsize=(16,10))\n     12 for i in range(1,8):\n---> 13     face = data[data['emotion'] == i-1].iloc[0]\n     14     img = row2image(face)\n     15     plt.subplot(2,4,i)\n"", '/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key)\n   1476 \n   1477             maybe_callable = com._apply_if_callable(key, self.obj)\n-> 1478             return self._getitem_axis(maybe_callable, axis=axis)\n   1479 \n   1480     def _is_scalar_access(self, key):\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis)\n   2100 \n   2101             # validate the location\n-> 2102             self._validate_integer(key, axis)\n   2103 \n   2104             return self._get_loc(key, axis=axis)\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py in _validate_integer(self, key, axis)\n   2007         l = len(ax)\n   2008         if key >= l or key < -l:\n-> 2009             raise IndexError(""single positional indexer is out-of-bounds"")\n   2010 \n   2011     def _getitem_tuple(self, tup):\n', 'IndexError: single positional indexer is out-of-bounds']",data confusion,index error,data visualization,ML bug,FER2013,,Unknown,,https://www.kaggle.com/datasets/nicolejyt/facialexpressionrecognition,,https://www.kaggle.com/code/asmaramedi/facial-expression-recognition-using-cnn
pandas_5,641e0062-b0cd-3cf6-a379-f2dad08f87ce,valueerror,invalid literal for int() with base 10: '46.0',"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[104], line 4\n      1 # didn't work in original one also\n      3 for column in cat_feat:\n----> 4     x_train[column] = x_train[column].astype('int')\n      5     x_test[column] = x_test[column].astype('int')\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:6324, in NDFrame.astype(self, dtype, copy, errors)\n   6317     results = [\n   6318         self.iloc[:, i].astype(dtype, copy=copy)\n   6319         for i in range(len(self.columns))\n   6320     ]\n   6322 else:\n   6323     # else, only a single dtype is given\n-> 6324     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n   6325     return self._constructor(new_data).__finalize__(self, method=""astype"")\n   6327 # GH 33113: handle empty frame or series\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:451, in BaseBlockManager.astype(self, dtype, copy, errors)\n    448 elif using_copy_on_write():\n    449     copy = False\n--> 451 return self.apply(\n    452     ""astype"",\n    453     dtype=dtype,\n    454     copy=copy,\n    455     errors=errors,\n    456     using_cow=using_copy_on_write(),\n    457 )\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:352, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n    350         applied = b.apply(f, **kwargs)\n    351     else:\n--> 352         applied = getattr(b, f)(**kwargs)\n    353     result_blocks = extend_blocks(applied, result_blocks)\n    355 out = type(self).from_blocks(result_blocks, self.axes)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/blocks.py:511, in Block.astype(self, dtype, copy, errors, using_cow)\n    491 """"""\n    492 Coerce to the new dtype.\n    493 \n   (...)\n    507 Block\n    508 """"""\n    509 values = self.values\n--> 511 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n    513 new_values = maybe_coerce_values(new_values)\n    515 refs = None\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:242, in astype_array_safe(values, dtype, copy, errors)\n    239     dtype = dtype.numpy_dtype\n    241 try:\n--> 242     new_values = astype_array(values, dtype, copy=copy)\n    243 except (ValueError, TypeError):\n    244     # e.g. _astype_nansafe can fail on object-dtype of strings\n    245     #  trying to convert to float\n    246     if errors == ""ignore"":\n', ""File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:187, in astype_array(values, dtype, copy)\n    184     values = values.astype(dtype, copy=copy)\n    186 else:\n--> 187     values = _astype_nansafe(values, dtype, copy=copy)\n    189 # in pandas we don't store numpy str dtypes, so convert to object\n    190 if isinstance(dtype, np.dtype) and issubclass(values.dtype.type, str):\n"", ""File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:138, in _astype_nansafe(arr, dtype, copy, skipna)\n    134     raise ValueError(msg)\n    136 if copy or is_object_dtype(arr.dtype) or is_object_dtype(dtype):\n    137     # Explicit copy, or required since NumPy can't view from / to object.\n--> 138     return arr.astype(dtype, copy=True)\n    140 return arr.astype(dtype, copy=copy)\n"", ""ValueError: invalid literal for int() with base 10: '46.0'""]",data confusion,value error,data preparation,ML bug,Health Insurance Cross Sell Prediction 🏠 🏥,,GPL 2,,https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction,,https://www.kaggle.com/code/shubhampatil7/dmproject
pandas_6,063245cc-f98f-3c7e-a4ff-c99205c50f96,valueerror,invalid literal for int() with base 10: 'Order ID',"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[10], line 1\n----> 1 df=df['Order ID'].astype('int')\n      2 df\n      3 #This Error is occuring due to some string values in Order ID Column\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:6240, in NDFrame.astype(self, dtype, copy, errors)\n   6233     results = [\n   6234         self.iloc[:, i].astype(dtype, copy=copy)\n   6235         for i in range(len(self.columns))\n   6236     ]\n   6238 else:\n   6239     # else, only a single dtype is given\n-> 6240     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n   6241     return self._constructor(new_data).__finalize__(self, method=""astype"")\n   6243 # GH 33113: handle empty frame or series\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:448, in BaseBlockManager.astype(self, dtype, copy, errors)\n    447 def astype(self: T, dtype, copy: bool = False, errors: str = ""raise"") -> T:\n--> 448     return self.apply(""astype"", dtype=dtype, copy=copy, errors=errors)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:352, in BaseBlockManager.apply(self, f, align_keys, ignore_failures, **kwargs)\n    350         applied = b.apply(f, **kwargs)\n    351     else:\n--> 352         applied = getattr(b, f)(**kwargs)\n    353 except (TypeError, NotImplementedError):\n    354     if not ignore_failures:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/blocks.py:526, in Block.astype(self, dtype, copy, errors)\n    508 """"""\n    509 Coerce to the new dtype.\n    510 \n   (...)\n    522 Block\n    523 """"""\n    524 values = self.values\n--> 526 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n    528 new_values = maybe_coerce_values(new_values)\n    529 newb = self.make_block(new_values)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:299, in astype_array_safe(values, dtype, copy, errors)\n    296     return values.copy()\n    298 try:\n--> 299     new_values = astype_array(values, dtype, copy=copy)\n    300 except (ValueError, TypeError):\n    301     # e.g. astype_nansafe can fail on object-dtype of strings\n    302     #  trying to convert to float\n    303     if errors == ""ignore"":\n', ""File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:230, in astype_array(values, dtype, copy)\n    227     values = values.astype(dtype, copy=copy)\n    229 else:\n--> 230     values = astype_nansafe(values, dtype, copy=copy)\n    232 # in pandas we don't store numpy str dtypes, so convert to object\n    233 if isinstance(dtype, np.dtype) and issubclass(values.dtype.type, str):\n"", ""File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:170, in astype_nansafe(arr, dtype, copy, skipna)\n    166     raise ValueError(msg)\n    168 if copy or is_object_dtype(arr.dtype) or is_object_dtype(dtype):\n    169     # Explicit copy, or required since NumPy can't view from / to object.\n--> 170     return arr.astype(dtype, copy=True)\n    172 return arr.astype(dtype, copy=copy)\n"", ""ValueError: invalid literal for int() with base 10: 'Order ID'""]",data confusion,value error,data preparation,ML bug,Retail Sales Analysis,,Unknown,,https://www.kaggle.com/datasets/rishabhsharma011/retail-sales-analysis,,https://www.kaggle.com/code/rishabhsharma011/retail-sales-analysis-project
sklearn_10,7a0b6a76-224c-3df5-b99f-2b252b90117f,keyerror,"""None of [Int64Index([      0,       1,       2,       3,       4,       5,       6,\n                  8,       9,      11,\n            ...\n            1064640, 1064642, 1064643, 1064644, 1064645, 1064646, 1064647,\n            1064648, 1064650, 1064651],\n           dtype='int64', length=958186)] are in the [columns]""","['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', '<ipython-input-105-43075d4b01ce> in <module>\n     11 for fold, (train_idx, valid_idx) in enumerate(KFold(n_splits=n_splits, shuffle=True).split(X_train,y_train)):\n     12     # Fetch the train-validation indices.\n---> 13     X_train, y_train = X_train[train_idx], y_train[train_idx]\n     14     X_valid, y_valid = X_train[valid_idx], y_train[valid_idx]\n     15 \n', '/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key)\n   2984             if is_iterator(key):\n   2985                 key = list(key)\n-> 2986             indexer = self.loc._convert_to_indexer(key, axis=1, raise_missing=True)\n   2987 \n   2988         # take() does not accept boolean indexers\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py in _convert_to_indexer(self, obj, axis, is_setter, raise_missing)\n   1283                 # When setting, missing keys are not allowed, even with .loc:\n   1284                 kwargs = {""raise_missing"": True if is_setter else raise_missing}\n-> 1285                 return self._get_listlike_indexer(obj, axis, **kwargs)[1]\n   1286         else:\n   1287             try:\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis, raise_missing)\n   1090 \n   1091         self._validate_read_indexer(\n-> 1092             keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing\n   1093         )\n   1094         return keyarr, indexer\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing)\n   1175                 raise KeyError(\n   1176                     ""None of [{key}] are in the [{axis}]"".format(\n-> 1177                         key=key, axis=self.obj._get_axis_name(axis)\n   1178                     )\n   1179                 )\n', 'KeyError: ""None of [Int64Index([      0,       1,       2,       3,       4,       5,       6,\\n                  8,       9,      11,\\n            ...\\n            1064640, 1064642, 1064643, 1064644, 1064645, 1064646, 1064647,\\n            1064648, 1064650, 1064651],\\n           dtype=\'int64\', length=958186)] are in the [columns]""']",data confusion,key error,training,ML bug,Electric Motor Temperature,,CC BY-SA 4.0,,https://www.kaggle.com/datasets/wkirgsn/electric-motor-temperature,,https://www.kaggle.com/code/yokeshkummar/test-rig-motor
pandas_7,1a123373-bbcd-36b9-ae19-8c46d0fcd622,valueerror,invalid literal for int() with base 10: 'nan',"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""<ipython-input-7-4958b6271f98> in <module>\n----> 1 game_df['released'] = game_df['released'].apply(lambda x: str(x).split('-')[0]).astype('int')\n"", '/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py in astype(self, dtype, copy, errors, **kwargs)\n   5880             # else, only a single dtype is given\n   5881             new_data = self._data.astype(\n-> 5882                 dtype=dtype, copy=copy, errors=errors, **kwargs\n   5883             )\n   5884             return self._constructor(new_data).__finalize__(self)\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/internals/managers.py in astype(self, dtype, **kwargs)\n    579 \n    580     def astype(self, dtype, **kwargs):\n--> 581         return self.apply(""astype"", dtype=dtype, **kwargs)\n    582 \n    583     def convert(self, **kwargs):\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\n    436                     kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy)\n    437 \n--> 438             applied = getattr(b, f)(**kwargs)\n    439             result_blocks = _extend_blocks(applied, result_blocks)\n    440 \n', '/opt/conda/lib/python3.6/site-packages/pandas/core/internals/blocks.py in astype(self, dtype, copy, errors, values, **kwargs)\n    557 \n    558     def astype(self, dtype, copy=False, errors=""raise"", values=None, **kwargs):\n--> 559         return self._astype(dtype, copy=copy, errors=errors, values=values, **kwargs)\n    560 \n    561     def _astype(self, dtype, copy=False, errors=""raise"", values=None, **kwargs):\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/internals/blocks.py in _astype(self, dtype, copy, errors, values, **kwargs)\n    641                     # _astype_nansafe works fine with 1-d only\n    642                     vals1d = values.ravel()\n--> 643                     values = astype_nansafe(vals1d, dtype, copy=True, **kwargs)\n    644 \n    645                 # TODO(extension)\n', '/opt/conda/lib/python3.6/site-packages/pandas/core/dtypes/cast.py in astype_nansafe(arr, dtype, copy, skipna)\n    705         # work around NumPy brokenness, #1987\n    706         if np.issubdtype(dtype.type, np.integer):\n--> 707             return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape)\n    708 \n    709         # if we have a datetime/timedelta array of objects\n', 'pandas/_libs/lib.pyx in pandas._libs.lib.astype_intsafe()\n', ""ValueError: invalid literal for int() with base 10: 'nan'""]",data confusion,value error,data preparation,ML bug,Video Game Dataset,,Unknown,,https://www.kaggle.com/datasets/jummyegg/rawg-game-dataset,,https://www.kaggle.com/code/gkhanelbistan/clustering-the-genres-of-a-video-game
torch_13,f3fcfa58-4438-3b6f-a471-b7ece7c3ee71,runtimeerror,"one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [256, 1024]], which is output 0 of AsStridedBackward0, is at version 3; expected version 2 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!","['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', '/tmp/ipykernel_27/460359927.py in <module>\n     20         loss = loss_function(pred, y.long())\n     21         optimizer.zero_grad()\n---> 22         loss.backward(retain_graph=True)\n     23         optimizer.step()\n     24 \n', '/opt/conda/lib/python3.7/site-packages/torch/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)\n    486             )\n    487         torch.autograd.backward(\n--> 488             self, gradient, retain_graph, create_graph, inputs=inputs\n    489         )\n    490 \n', '/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n    197     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n    198         tensors, grad_tensors_, retain_graph, create_graph, inputs,\n--> 199         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n    200 \n    201 def grad(\n', 'RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [256, 1024]], which is output 0 of AsStridedBackward0, is at version 3; expected version 2 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!']",implementation error,runtime error,training,ML bug,Machado de Assis,,GNU Lesser General Public License 3.0,,https://www.kaggle.com/datasets/luxedo/machado-de-assis,,https://www.kaggle.com/code/mpwolke/machado-dom-casmurro-pytorch
sklearn_11,2bcbc897-9ee4-368a-a498-7bd42a69b05b,valueerror,"With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/1111092727.py in <module>\n----> 1 x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n      2 \n      3 lr = LinearRegression()\n      4 lr.fit(x_train, y_train)\n      5 y_pred = lr.predict(x_test)\n', '/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py in train_test_split(test_size, train_size, random_state, shuffle, stratify, *arrays)\n   2419     n_samples = _num_samples(arrays[0])\n   2420     n_train, n_test = _validate_shuffle_split(\n-> 2421         n_samples, test_size, train_size, default_test_size=0.25\n   2422     )\n   2423 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py in _validate_shuffle_split(n_samples, test_size, train_size, default_test_size)\n   2099             ""With n_samples={}, test_size={} and train_size={}, the ""\n   2100             ""resulting train set will be empty. Adjust any of the ""\n-> 2101             ""aforementioned parameters."".format(n_samples, test_size, train_size)\n   2102         )\n   2103 \n', 'ValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.']",data confusion,invalid argument,data preparation,ML bug,Crowdedness at the Campus Gym,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/nsrose7224/crowdedness-at-the-campus-gym,,https://www.kaggle.com/code/mohamadzubi/polynomial-reg-crowdedness-dataset
pandas_8,b9825c16-c276-3eb3-bccd-a6461718d83f,valueerror,"Unable to parse string ""$36,945 "" at position 0","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/opt/conda/lib/python3.7/site-packages/pandas/_libs/lib.pyx in pandas._libs.lib.maybe_convert_numeric()\n', 'ValueError: Unable to parse string ""$36,945 ""', '\nDuring handling of the above exception, another exception occurred:\n', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/3879484352.py in <module>\n----> 1 df[""MSRP""]=pd.to_numeric(df[""MSRP""])\n', '/opt/conda/lib/python3.7/site-packages/pandas/core/tools/numeric.py in to_numeric(arg, errors, downcast)\n    182         try:\n    183             values, _ = lib.maybe_convert_numeric(\n--> 184                 values, set(), coerce_numeric=coerce_numeric\n    185             )\n    186         except (ValueError, TypeError):\n', '/opt/conda/lib/python3.7/site-packages/pandas/_libs/lib.pyx in pandas._libs.lib.maybe_convert_numeric()\n', 'ValueError: Unable to parse string ""$36,945 "" at position 0']",data confusion,value error,data preparation,ML bug,Cars dataset,,Unknown,,https://www.kaggle.com/datasets/vikrantkc/cars-dataset,,https://www.kaggle.com/code/varshajais123/car-dataset
torch_14,4e16c8a8-3972-3dc5-a091-d9b1bfddbeef,runtimeerror,Caught RuntimeError in DataLoader worker process 0.,"['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', 'Cell In[2], line 36\n     34 num_epochs = 10\n     35 for epoch in range(num_epochs):\n---> 36     for i, data in enumerate(trainloader, 0):\n     37         inputs, labels = data\n     38         optimizer.zero_grad()\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634, in _BaseDataLoaderIter.__next__(self)\n    631 if self._sampler_iter is None:\n    632     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    633     self._reset()  # type: ignore[call-arg]\n--> 634 data = self._next_data()\n    635 self._num_yielded += 1\n    636 if self._dataset_kind == _DatasetKind.Iterable and \\\n    637         self._IterableDataset_len_called is not None and \\\n    638         self._num_yielded > self._IterableDataset_len_called:\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346, in _MultiProcessingDataLoaderIter._next_data(self)\n   1344 else:\n   1345     del self._task_info[idx]\n-> 1346     return self._process_data(data)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372, in _MultiProcessingDataLoaderIter._process_data(self, data)\n   1370 self._try_put_index()\n   1371 if isinstance(data, ExceptionWrapper):\n-> 1372     data.reraise()\n   1373 return data\n', ""File /opt/conda/lib/python3.10/site-packages/torch/_utils.py:644, in ExceptionWrapper.reraise(self)\n    640 except TypeError:\n    641     # If the exception takes multiple arguments, don't try to\n    642     # instantiate since we don't know how to\n    643     raise RuntimeError(msg) from None\n--> 644 raise exception\n"", 'RuntimeError: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File ""/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py"", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File ""/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py"", line 54, in fetch\n    return self.collate_fn(data)\n  File ""/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py"", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File ""/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py"", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File ""/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py"", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File ""/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py"", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File ""/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py"", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 112, 500] at entry 0 and [3, 375, 500] at entry 1\n']",data confusion,runtime error,training,ML bug,PASCAL VOC 2012,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/huanghanchina/pascal-voc-2012,,https://www.kaggle.com/code/fymwin/faster-rcnn
torch_15,de99269e-82c7-399c-97aa-b1e92e4423b1,valueerror,"Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[25], line 10\n      7 optimizer.zero_grad()\n      9 outputs = model(sekil)\n---> 10 loss = loss_fn(outputs, netice)\n     12 loss.backward()\n     13 optimizer.step()\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:619, in BCELoss.forward(self, input, target)\n    618 def forward(self, input: Tensor, target: Tensor) -> Tensor:\n--> 619     return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n', 'File /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3089, in binary_cross_entropy(input, target, weight, size_average, reduce, reduction)\n   3087     reduction_enum = _Reduction.get_enum(reduction)\n   3088 if target.size() != input.size():\n-> 3089     raise ValueError(\n   3090         ""Using a target size ({}) that is different to the input size ({}) is deprecated. ""\n   3091         ""Please ensure they have the same size."".format(target.size(), input.size())\n   3092     )\n   3094 if weight is not None:\n   3095     new_size = _infer_size(target.size(), weight.size())\n', 'ValueError: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.']",API misuse,tensor shape mismatch,training,ML bug,Penguins vs Turtles,,Unknown,,https://www.kaggle.com/datasets/abbymorgan/penguins-vs-turtles,,https://www.kaggle.com/code/kenanzeynalli/penguin-vs-turtle-cv
sklearn_12,96cbdadd-6fa0-32cb-b20b-96d9604ef6bd,attributeerror,SVC' object has no attribute 'feature_importances_',"['---------------------------------------------------------------------------', 'AttributeError                            Traceback (most recent call last)', 'Cell In[73], line 3\n      1 from pandas import Series\n----> 3 feature_importance = model.feature_importances_\n      4 Series_feat_imp = Series(feature_importance, index=data.columns)\n', ""AttributeError: 'SVC' object has no attribute 'feature_importances_'""]",API misuse,attribute error,evaluation/prediction,ML bug,Titanic - Machine Learning from Disaster,,"Competition Use and Academic, Non-Commercial Use Only",,https://www.kaggle.com/competitions/titanic/data,,https://www.kaggle.com/code/subhanahmed09/titanic-submit
pandas_9,2b700a8a-d511-357f-8bb3-64f7e9ccfa15,keyerror,'Total Gross (millions USD)',"['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653, in Index.get_loc(self, key)\n   3652 try:\n-> 3653     return self._engine.get_loc(casted_key)\n   3654 except KeyError as err:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:147, in pandas._libs.index.IndexEngine.get_loc()\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:176, in pandas._libs.index.IndexEngine.get_loc()\n', 'File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n', 'File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n', ""KeyError: 'Total Gross (millions USD)'"", '\nThe above exception was the direct cause of the following exception:\n', 'KeyError                                  Traceback (most recent call last)', ""Cell In[139], line 1\n----> 1 clean_df = df.drop(df[(df['Total Gross (millions USD)'] == 'Gross Unkown') & (df['Total Gross (millions USD)'] == '$0.00M')].index).copy()\n      2 clean_df['Total Gross (millions USD)'] = clean_df['Total Gross (millions USD)'].str.replace('$', '').str.replace('M', '').astype(float)\n      3 clean_df.reset_index(drop=True, inplace=True)\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3761, in DataFrame.__getitem__(self, key)\n   3759 if self.columns.nlevels > 1:\n   3760     return self._getitem_multilevel(key)\n-> 3761 indexer = self.columns.get_loc(key)\n   3762 if is_integer(indexer):\n   3763     indexer = [indexer]\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655, in Index.get_loc(self, key)\n   3653     return self._engine.get_loc(casted_key)\n   3654 except KeyError as err:\n-> 3655     raise KeyError(key) from err\n   3656 except TypeError:\n   3657     # If we have a listlike key, _check_indexing_error will raise\n   3658     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3659     #  the TypeError.\n   3660     self._check_indexing_error(key)\n', ""KeyError: 'Total Gross (millions USD)'""]",data confusion,key error,data preparation,ML bug,IMDb 5000+ Movies & Multiple Genres Dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/rakkesharv/imdb-5000-movies-multiple-genres-dataset,,https://www.kaggle.com/code/fajar2k5/notebook497e8cf867
pandas_10,6682c9ad-fe58-3360-ae4c-f0192a174c0a,valueerror,"invalid literal for int() with base 10: '10,000+'","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[13], line 1\n----> 1 df['Installs']=df['Installs'].astype('int')\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:6324, in NDFrame.astype(self, dtype, copy, errors)\n   6317     results = [\n   6318         self.iloc[:, i].astype(dtype, copy=copy)\n   6319         for i in range(len(self.columns))\n   6320     ]\n   6322 else:\n   6323     # else, only a single dtype is given\n-> 6324     new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n   6325     return self._constructor(new_data).__finalize__(self, method=""astype"")\n   6327 # GH 33113: handle empty frame or series\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:451, in BaseBlockManager.astype(self, dtype, copy, errors)\n    448 elif using_copy_on_write():\n    449     copy = False\n--> 451 return self.apply(\n    452     ""astype"",\n    453     dtype=dtype,\n    454     copy=copy,\n    455     errors=errors,\n    456     using_cow=using_copy_on_write(),\n    457 )\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:352, in BaseBlockManager.apply(self, f, align_keys, **kwargs)\n    350         applied = b.apply(f, **kwargs)\n    351     else:\n--> 352         applied = getattr(b, f)(**kwargs)\n    353     result_blocks = extend_blocks(applied, result_blocks)\n    355 out = type(self).from_blocks(result_blocks, self.axes)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/blocks.py:511, in Block.astype(self, dtype, copy, errors, using_cow)\n    491 """"""\n    492 Coerce to the new dtype.\n    493 \n   (...)\n    507 Block\n    508 """"""\n    509 values = self.values\n--> 511 new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n    513 new_values = maybe_coerce_values(new_values)\n    515 refs = None\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:242, in astype_array_safe(values, dtype, copy, errors)\n    239     dtype = dtype.numpy_dtype\n    241 try:\n--> 242     new_values = astype_array(values, dtype, copy=copy)\n    243 except (ValueError, TypeError):\n    244     # e.g. _astype_nansafe can fail on object-dtype of strings\n    245     #  trying to convert to float\n    246     if errors == ""ignore"":\n', ""File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:187, in astype_array(values, dtype, copy)\n    184     values = values.astype(dtype, copy=copy)\n    186 else:\n--> 187     values = _astype_nansafe(values, dtype, copy=copy)\n    189 # in pandas we don't store numpy str dtypes, so convert to object\n    190 if isinstance(dtype, np.dtype) and issubclass(values.dtype.type, str):\n"", ""File /opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:138, in _astype_nansafe(arr, dtype, copy, skipna)\n    134     raise ValueError(msg)\n    136 if copy or is_object_dtype(arr.dtype) or is_object_dtype(dtype):\n    137     # Explicit copy, or required since NumPy can't view from / to object.\n--> 138     return arr.astype(dtype, copy=True)\n    140 return arr.astype(dtype, copy=copy)\n"", ""ValueError: invalid literal for int() with base 10: '10,000+'""]",data confusion,value error,data preparation,ML bug,LinearRegression,,CC0: Public Domain,,https://www.kaggle.com/datasets/shivrajguvi/linearregression,,https://www.kaggle.com/code/shivrajguvi/regression-linear-googleplaystore
pandas_11,ba41a161-f8dc-3650-87ba-65a3367e0ee8,keyerror,'Hour',"['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802, in Index.get_loc(self, key, method, tolerance)\n   3801 try:\n-> 3802     return self._engine.get_loc(casted_key)\n   3803 except KeyError as err:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138, in pandas._libs.index.IndexEngine.get_loc()\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165, in pandas._libs.index.IndexEngine.get_loc()\n', 'File pandas/_libs/hashtable_class_helper.pxi:5745, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n', 'File pandas/_libs/hashtable_class_helper.pxi:5753, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n', ""KeyError: 'Hour'"", '\nThe above exception was the direct cause of the following exception:\n', 'KeyError                                  Traceback (most recent call last)', 'Cell In[23], line 14\n     12 i += 1\n     13 plt.subplot(8,4,i)\n---> 14 sns.kdeplot(t0[feature], bw=0.5,label=""Class = 0"");\n     15 sns.kdeplot(t1[feature], bw=0.5,label=""Class = 1"");\n     16 plt.xlabel(feature, fontsize=12)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3807, in DataFrame.__getitem__(self, key)\n   3805 if self.columns.nlevels > 1:\n   3806     return self._getitem_multilevel(key)\n-> 3807 indexer = self.columns.get_loc(key)\n   3808 if is_integer(indexer):\n   3809     indexer = [indexer]\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804, in Index.get_loc(self, key, method, tolerance)\n   3802     return self._engine.get_loc(casted_key)\n   3803 except KeyError as err:\n-> 3804     raise KeyError(key) from err\n   3805 except TypeError:\n   3806     # If we have a listlike key, _check_indexing_error will raise\n   3807     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3808     #  the TypeError.\n   3809     self._check_indexing_error(key)\n', ""KeyError: 'Hour'""]",data confusion,key error,data visualization,ML bug,Credit Card Fraud Detection,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud,,https://www.kaggle.com/code/hinnguynminh/credit-card-fraud-detection
pandas_12,0f745de3-80f1-31b2-b520-9bd25b490a1e,keyerror,"'Column(s) [1, 2, 3, 4] do not exist'","['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', ""Cell In[35], line 1\n----> 1 df.groupby('kmeans_cluster').agg({1: ['count','mean', 'median', 'sum'],\n      2                                     2: ['count','mean', 'median', 'sum'],\n      3                                     3: ['count','mean', 'median', 'sum'],\n      4                                     4: ['count','mean','median', 'sum']})\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/groupby/generic.py:1269, in DataFrameGroupBy.aggregate(self, func, engine, engine_kwargs, *args, **kwargs)\n   1266 func = maybe_mangle_lambdas(func)\n   1268 op = GroupByApply(self, func, args, kwargs)\n-> 1269 result = op.agg()\n   1270 if not is_dict_like(func) and result is not None:\n   1271     return result\n', ""File /opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:163, in Apply.agg(self)\n    160     return self.apply_str()\n    162 if is_dict_like(arg):\n--> 163     return self.agg_dict_like()\n    164 elif is_list_like(arg):\n    165     # we require a list, but not a 'str'\n    166     return self.agg_list_like()\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:403, in Apply.agg_dict_like(self)\n    400     selected_obj = obj._selected_obj\n    401     selection = obj._selection\n--> 403 arg = self.normalize_dictlike_arg(""agg"", selected_obj, arg)\n    405 is_groupby = isinstance(obj, (DataFrameGroupBy, SeriesGroupBy))\n    406 context_manager: ContextManager\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:535, in Apply.normalize_dictlike_arg(self, how, obj, func)\n    533     if len(cols) > 0:\n    534         cols_sorted = list(safe_sort(list(cols)))\n--> 535         raise KeyError(f""Column(s) {cols_sorted} do not exist"")\n    537 aggregator_types = (list, tuple, dict)\n    539 # if we have a dict of any non-scalars\n    540 # eg. {\'A\' : [\'mean\']}, normalize all to\n    541 # be list-likes\n    542 # Cannot use func.values() because arg may be a Series\n', ""KeyError: 'Column(s) [1, 2, 3, 4] do not exist'""]",API misuse,key error,data preparation,ML bug,DıetDataset,,Apache 2.0,,https://www.kaggle.com/datasets/ahsensaglam/detdataset,,https://www.kaggle.com/code/ahsensaglam/dietrecommendationsystem
numpy_11,b24a89d0-92fd-3bc9-89ad-f9bd3d530c0a,valueerror,"could not broadcast input array from shape (64,64,3) into shape (64,64)","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_23/4116823265.py in <module>\n     16       training_data.append(np.asarray(image))\n     17   training_data = np.reshape(training_data,(-1,GENERATE_SQUARE,\n---> 18             GENERATE_SQUARE,3))\n     19   training_data = training_data.astype(np.float32)\n     20   training_data = training_data / 127.5 - 1.\n', '<__array_function__ internals> in reshape(*args, **kwargs)\n', '/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in reshape(a, newshape, order)\n    296            [5, 6]])\n    297     """"""\n--> 298     return _wrapfunc(a, \'reshape\', newshape, order=order)\n    299 \n    300 \n', '/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds)\n     52     bound = getattr(obj, method, None)\n     53     if bound is None:\n---> 54         return _wrapit(obj, method, *args, **kwds)\n     55 \n     56     try:\n', '/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds)\n     41     except AttributeError:\n     42         wrap = None\n---> 43     result = getattr(asarray(obj), method)(*args, **kwds)\n     44     if wrap:\n     45         if not isinstance(result, mu.ndarray):\n', 'ValueError: could not broadcast input array from shape (64,64,3) into shape (64,64)']",API misuse,unsupported broadcast,data preparation,ML bug,apple fruit disease,,Unknown,,https://www.kaggle.com/datasets/kaivalyashah/apple-disease-detection,,https://www.kaggle.com/code/pradhicsharavi/notebookbb5034ebf6
sklearn_13,155e67a6-4b0b-3429-91e6-f64cafdcc665,valueerror,could not convert string to float: ' Private',"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/3371469880.py in <module>\n      2 \n      3 linear_reg = LinearRegression()\n----> 4 linear_reg.fit(x,y)\n', '/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py in fit(self, X, y, sample_weight)\n    661 \n    662         X, y = self._validate_data(\n--> 663             X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True\n    664         )\n    665 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/base.py in _validate_data(self, X, y, reset, validate_separately, **check_params)\n    579                 y = check_array(y, **check_y_params)\n    580             else:\n--> 581                 X, y = check_X_y(X, y, **check_params)\n    582             out = X, y\n    583 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\n    974         ensure_min_samples=ensure_min_samples,\n    975         ensure_min_features=ensure_min_features,\n--> 976         estimator=estimator,\n    977     )\n    978 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\n    744                     array = array.astype(dtype, casting=""unsafe"", copy=False)\n    745                 else:\n--> 746                     array = np.asarray(array, order=order, dtype=dtype)\n    747             except ComplexWarning as complex_warning:\n    748                 raise ValueError(\n', ""ValueError: could not convert string to float: ' Private'""]",API misuse,value error,training,ML bug,SalaryData,,Unknown,,https://www.kaggle.com/datasets/srikarthadaka/salarydata,,https://www.kaggle.com/code/mohamadzubi/linear-reg-week6
numpy_12,918f02b2-4746-3c97-a709-6229558495c8,valueerror,"could not broadcast input array from shape (84,4) into shape (84,1)","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[23], line 33\n     31 trainPredictPlot = np.empty_like(dataset)\n     32 trainPredictPlot[:, :] = np.nan\n---> 33 trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n     34 # shift test predictions for plotting\n     35 testPredictPlot = np.empty_like(dataset)\n', 'ValueError: could not broadcast input array from shape (84,4) into shape (84,1)']",data confusion,unsupported broadcast,training,ML bug,International airline passengers,,Unknown,,https://www.kaggle.com/datasets/andreazzini/international-airline-passengers,,https://www.kaggle.com/code/ghazouanihaythem/lstm-for-time-series-prediction
sklearn_14,ac86a968-cfd4-3b7b-b722-dc23ed430c0a,valueerror,could not convert string to float: '9808 NE 204th Pl',"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_156/2078488702.py in ?()\n      1 # Fitting the model\n----> 2 model.fit(X_train,y_train)\n', '/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_base.py in ?(self, X, y, sample_weight)\n    644         n_jobs_ = self.n_jobs\n    645 \n    646         accept_sparse = False if self.positive else [""csr"", ""csc"", ""coo""]\n    647 \n--> 648         X, y = self._validate_data(\n    649             X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True\n    650         )\n    651 \n', '/opt/conda/lib/python3.10/site-packages/sklearn/base.py in ?(self, X, y, reset, validate_separately, **check_params)\n    580                 if ""estimator"" not in check_y_params:\n    581                     check_y_params = {**default_check_params, **check_y_params}\n    582                 y = check_array(y, input_name=""y"", **check_y_params)\n    583             else:\n--> 584                 X, y = check_X_y(X, y, **check_params)\n    585             out = X, y\n    586 \n    587         if not no_val_X and check_params.get(""ensure_2d"", True):\n', '/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py in ?(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\n   1102         raise ValueError(\n   1103             f""{estimator_name} requires y to be passed, but the target y is None""\n   1104         )\n   1105 \n-> 1106     X = check_array(\n   1107         X,\n   1108         accept_sparse=accept_sparse,\n   1109         accept_large_sparse=accept_large_sparse,\n', '/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py in ?(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\n    876                         )\n    877                     array = xp.astype(array, dtype, copy=False)\n    878                 else:\n    879                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n--> 880             except ComplexWarning as complex_warning:\n    881                 raise ValueError(\n    882                     ""Complex data not supported\\n{}\\n"".format(array)\n    883                 ) from complex_warning\n', '/opt/conda/lib/python3.10/site-packages/sklearn/utils/_array_api.py in ?(array, dtype, order, copy, xp)\n    181     if xp is None:\n    182         xp, _ = get_namespace(array)\n    183     if xp.__name__ in {""numpy"", ""numpy.array_api""}:\n    184         # Use NumPy API to support order\n--> 185         array = numpy.asarray(array, order=order, dtype=dtype)\n    186         return xp.asarray(array, copy=copy)\n    187     else:\n    188         return xp.asarray(array, dtype=dtype, copy=copy)\n', '/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py in ?(self, dtype)\n   1996     def __array__(self, dtype: npt.DTypeLike | None = None) -> np.ndarray:\n   1997         values = self._values\n-> 1998         arr = np.asarray(values, dtype=dtype)\n   1999         if (\n   2000             astype_is_view(values.dtype, arr.dtype)\n   2001             and using_copy_on_write()\n', ""ValueError: could not convert string to float: '9808 NE 204th Pl'""]",API misuse,value error,training,ML bug,House price prediction,,Unknown,,https://www.kaggle.com/datasets/shree1992/housedata,,https://www.kaggle.com/code/kshishagrawal/housepriceprediction
numpy_13,6b636360-3254-35af-b147-d251c78b54b2,valueerror,"could not broadcast input array from shape (10,100) into shape (10,)","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_17/4286230538.py in <module>\n----> 1 NX = FeatureExtractor(path, n_mels = 10)\n', '/tmp/ipykernel_17/2160383838.py in FeatureExtractor(path, n_mels, fmax, fmin)\n     16 \n     17 \n---> 18     data = np.array(data)\n     19     return data\n', 'ValueError: could not broadcast input array from shape (10,100) into shape (10,)']",data confusion,unsupported broadcast,data preparation,ML bug,Musical Instrument Chord Classification (Audio),,CC0: Public Domain,,https://www.kaggle.com/datasets/deepcontractor/musical-instrument-chord-classification,,https://www.kaggle.com/code/juansebm/mathematics-of-music-chord-classification-ee0463
pandas_13,bdd9a86e-c833-34a9-a07a-2521a55e2266,valueerror,"Shape of passed values is (4, 1), indices imply (4, 109)","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[61], line 14\n     11 fearture_names = X_train.columns.tolist() if key == 'X_train' else X_2_train.columns.tolist()\n     12 f_index = ['gbr', 'gbr_gs', 'rfr', 'rfr_gs'] if key == 'X_train' else ['gbr2','rfr2']\n---> 14 feature_df = pd.DataFrame(np.array(f_list), columns=fearture_names, index=f_index)\n     15 display(feature_df)\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy)\n    712         mgr = dict_to_mgr(\n    713             # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no\n    714             # attribute ""name""\n   (...)\n    719             typ=manager,\n    720         )\n    721     else:\n--> 722         mgr = ndarray_to_mgr(\n    723             data,\n    724             index,\n    725             columns,\n    726             dtype=dtype,\n    727             copy=copy,\n    728             typ=manager,\n    729         )\n    731 # For data is list-like, or Iterable (will consume into list)\n    732 elif is_list_like(data):\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ)\n    344 # _prep_ndarraylike ensures that values.ndim == 2 at this point\n    345 index, columns = _get_axes(\n    346     values.shape[0], values.shape[1], index=index, columns=columns\n    347 )\n--> 349 _check_values_indices_shape_match(values, index, columns)\n    351 if typ == ""array"":\n    353     if issubclass(values.dtype.type, str):\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns)\n    418 passed = values.shape\n    419 implied = (len(index), len(columns))\n--> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}"")\n', 'ValueError: Shape of passed values is (4, 1), indices imply (4, 109)']",data confusion,tensor shape mismatch,data preparation,ML bug,Car price prediction(used cars),,CC0: Public Domain,,https://www.kaggle.com/datasets/vijayaadithyanvg/car-price-predictionused-cars,,https://www.kaggle.com/code/zdongs/zdsfirstcar
sklearn_15,5137f0d4-b6b8-36a2-92de-bc5269e4f503,valueerror,could not convert string to float: 'No',"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', 'Cell In[9], line 7\n      4 X_train = scaler.fit_transform(X_train)\n      5 X_test = scaler.transform(X_test)\n----> 7 y_train = scaler.fit_transform(y_train)\n      8 y_test = scaler.transform(y_test)\n     10 logreg.fit(X_train, y_train)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140, in _wrap_method_output.<locals>.wrapped(self, X, *args, **kwargs)\n    138 @wraps(f)\n    139 def wrapped(self, X, *args, **kwargs):\n--> 140     data_to_wrap = f(self, X, *args, **kwargs)\n    141     if isinstance(data_to_wrap, tuple):\n    142         # only wrap the first output for cross decomposition\n    143         return (\n    144             _wrap_data_with_container(method, data_to_wrap[0], X, self),\n    145             *data_to_wrap[1:],\n    146         )\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/base.py:878, in TransformerMixin.fit_transform(self, X, y, **fit_params)\n    874 # non-optimized default implementation; override when a better\n    875 # method is possible for a given clustering algorithm\n    876 if y is None:\n    877     # fit method of arity 1 (unsupervised transformation)\n--> 878     return self.fit(X, **fit_params).transform(X)\n    879 else:\n    880     # fit method of arity 2 (supervised transformation)\n    881     return self.fit(X, y, **fit_params).transform(X)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:824, in StandardScaler.fit(self, X, y, sample_weight)\n    822 # Reset internal state before fitting\n    823 self._reset()\n--> 824 return self.partial_fit(X, y, sample_weight)\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:861, in StandardScaler.partial_fit(self, X, y, sample_weight)\n    858 self._validate_params()\n    860 first_call = not hasattr(self, ""n_samples_seen_"")\n--> 861 X = self._validate_data(\n    862     X,\n    863     accept_sparse=(""csr"", ""csc""),\n    864     dtype=FLOAT_DTYPES,\n    865     force_all_finite=""allow-nan"",\n    866     reset=first_call,\n    867 )\n    868 n_features = X.shape[1]\n    870 if sample_weight is not None:\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/base.py:565, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)\n    563     raise ValueError(""Validation should be done on X, y or both."")\n    564 elif not no_val_X and no_val_y:\n--> 565     X = check_array(X, input_name=""X"", **check_params)\n    566     out = X\n    567 elif no_val_X and not no_val_y:\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:879, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\n    877         array = xp.astype(array, dtype, copy=False)\n    878     else:\n--> 879         array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n    880 except ComplexWarning as complex_warning:\n    881     raise ValueError(\n    882         ""Complex data not supported\\n{}\\n"".format(array)\n    883     ) from complex_warning\n', 'File /opt/conda/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185, in _asarray_with_order(array, dtype, order, copy, xp)\n    182     xp, _ = get_namespace(array)\n    183 if xp.__name__ in {""numpy"", ""numpy.array_api""}:\n    184     # Use NumPy API to support order\n--> 185     array = numpy.asarray(array, order=order, dtype=dtype)\n    186     return xp.asarray(array, copy=copy)\n    187 else:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/series.py:893, in Series.__array__(self, dtype)\n    846 def __array__(self, dtype: npt.DTypeLike | None = None) -> np.ndarray:\n    847     """"""\n    848     Return the values as a NumPy array.\n    849 \n   (...)\n    891           dtype=\'datetime64[ns]\')\n    892     """"""\n--> 893     return np.asarray(self._values, dtype)\n', ""ValueError: could not convert string to float: 'No'""]",data confusion,value error,data preparation,ML bug,weatherAUS,,Unknown,,https://raw.githubusercontent.com/gchoi/Dataset/master/weatherAUS.csv,,https://www.kaggle.com/code/alexmouse/notebookd5a789a5b2
pandas_14,72ddb204-b59c-38dc-b378-a9c67a15dc4f,indexerror,index 6 is out of bounds for axis 0 with size 6,"['---------------------------------------------------------------------------', 'IndexError                                Traceback (most recent call last)', '/tmp/ipykernel_28/509017699.py in <module>\n     14         n = i * col + j\n     15         if n < len(nombres_col):\n---> 16             axs[i, j].set_title(nombres_col.columns[n])\n     17             axs[i, j].scatter(df[nombres_col.columns[n]][:N], y[:N])\n     18 \n', '/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py in __getitem__(self, key)\n   4602         if is_scalar(key):\n   4603             key = com.cast_scalar_indexer(key, warn_float=True)\n-> 4604             return getitem(key)\n   4605 \n   4606         if isinstance(key, slice):\n', 'IndexError: index 6 is out of bounds for axis 0 with size 6']",API misuse,index error,data visualization,ML bug,Spaceship Titanic,,Attribution 4.0 International (CC BY 4.0),,https://www.kaggle.com/competitions/spaceship-titanic/data,,https://www.kaggle.com/code/diegofagu/spaceship-titanic-test
numpy_14,96a23bf1-6168-3827-8739-99b9cbfc36f2,axiserror,axis 1 is out of bounds for array of dimension 1,"['---------------------------------------------------------------------------', 'AxisError                                 Traceback (most recent call last)', '/tmp/ipykernel_23/2965731218.py in <module>\n     11 # Convert one-hot encoded labels to integer labels\n     12 y_true_onehot = test_generator.classes\n---> 13 y_true_classes = np.argmax(y_true_onehot, axis=1)\n', '<__array_function__ internals> in argmax(*args, **kwargs)\n', '/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out)\n   1193 \n   1194     """"""\n-> 1195     return _wrapfunc(a, \'argmax\', axis=axis, out=out)\n   1196 \n   1197 \n', '/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds)\n     55 \n     56     try:\n---> 57         return bound(*args, **kwds)\n     58     except TypeError:\n     59         # A TypeError occurs if the object does have such a method in its\n', 'AxisError: axis 1 is out of bounds for array of dimension 1']",data confusion,index error,evaluation/prediction,ML bug,CovidDataset_70_30,,Unknown,,https://www.kaggle.com/datasets/mrtejas/coviddataset-70-30,,https://www.kaggle.com/code/mrtejas/fork-of-ensemble-vgg19-mobilenetv2
pandas_15,c7221a95-ffc7-3173-beee-76efdc0892c5,keyerror,"""['Alley', 'PoolQC', 'Fence', 'MiscFeature'] not found in axis""","['---------------------------------------------------------------------------', 'KeyError                                  Traceback (most recent call last)', ""Cell In[37], line 1\n----> 1 test=test.drop(['Alley','PoolQC','Fence','MiscFeature','Id'],axis=1)\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n    325 if len(args) > num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--> 331 return func(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5399, in DataFrame.drop(self, labels, axis, index, columns, level, inplace, errors)\n   5251 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""])\n   5252 def drop(  # type: ignore[override]\n   5253     self,\n   (...)\n   5260     errors: IgnoreRaise = ""raise"",\n   5261 ) -> DataFrame | None:\n   5262     """"""\n   5263     Drop specified labels from rows or columns.\n   5264 \n   (...)\n   5397             weight  1.0     0.8\n   5398     """"""\n-> 5399     return super().drop(\n   5400         labels=labels,\n   5401         axis=axis,\n   5402         index=index,\n   5403         columns=columns,\n   5404         level=level,\n   5405         inplace=inplace,\n   5406         errors=errors,\n   5407     )\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n    325 if len(args) > num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--> 331 return func(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4505, in NDFrame.drop(self, labels, axis, index, columns, level, inplace, errors)\n   4503 for axis, labels in axes.items():\n   4504     if labels is not None:\n-> 4505         obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n   4507 if inplace:\n   4508     self._update_inplace(obj)\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4546, in NDFrame._drop_axis(self, labels, axis, level, errors, only_slice)\n   4544         new_axis = axis.drop(labels, level=level, errors=errors)\n   4545     else:\n-> 4546         new_axis = axis.drop(labels, errors=errors)\n   4547     indexer = axis.get_indexer(new_axis)\n   4549 # Case for non-unique axis\n   4550 else:\n', 'File /opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6934, in Index.drop(self, labels, errors)\n   6932 if mask.any():\n   6933     if errors != ""ignore"":\n-> 6934         raise KeyError(f""{list(labels[mask])} not found in axis"")\n   6935     indexer = indexer[~mask]\n   6936 return self.delete(indexer)\n', 'KeyError: ""[\'Alley\', \'PoolQC\', \'Fence\', \'MiscFeature\'] not found in axis""']",data confusion,key error,data preparation,ML bug,House Prices - Advanced Regression Techniques,,MIT,,https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data,,https://www.kaggle.com/code/sujan0999/notebook17f0cabc6b
numpy_15,65328e01-47ef-32f9-af6d-3ba8a7897a46,valueerror,"shapes (75,4) and (1,4) not aligned: 4 (dim 1) != 1 (dim 0)","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/3395597747.py in <module>\n      4 w, b = weightInitialization(n_features)\n      5 #Gradient Descent\n----> 6 coeff, gradient, costs = model_predict(w, b, X_tr_arr, y_tr_arr, learning_rate=0.0001,no_iterations=4500)\n      7 #Final prediction\n      8 w = coeff[""w""]\n', '/tmp/ipykernel_27/2662648926.py in model_predict(w, b, X, Y, learning_rate, no_iterations)\n      3     for i in range(no_iterations):\n      4         #\n----> 5         grads, cost = model_optimize(w,b,X,Y)\n      6         #\n      7         dw = grads[""dw""]\n', '/tmp/ipykernel_27/1118609748.py in model_optimize(w, b, X, Y)\n     11 \n     12     # Prediction\n---> 13     final_result = sigmoid(np.dot(X, w) + b)\n     14     cost = (-1/m) * np.sum(Y * np.log(final_result) + (1 - Y) * np.log(1 - final_result))\n     15 \n', '<__array_function__ internals> in dot(*args, **kwargs)\n', 'ValueError: shapes (75,4) and (1,4) not aligned: 4 (dim 1) != 1 (dim 0)']",implementation error,tensor shape mismatch,training,ML bug,Iris dataset,,Unknown,,https://github.com/SSaishruthi/LogisticRegression_Vectorized_Implementation,,https://www.kaggle.com/code/hassaanhaq/logistic-regression-optimization
seaborn_1,0d0ca672-ad75-3a91-828e-c20cb13c8847,typeerror,Neither the `x` nor `y` variable appears to be numeric.,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', ""Cell In[11], line 6\n      2 valid_agg = np.asarray([[label, (y_valid == index).sum()] for index, label in enumerate(CLASSES)])\n      4 fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 64))\n----> 6 ax1 = sns.barplot(x=train_agg[...,1], y=train_agg[...,0], order=CLASSES, ax=ax1)\n      7 ax1.set_title('Train', fontsize=30)\n      8 ax1.tick_params(labelsize=16)\n"", 'File /opt/conda/lib/python3.10/site-packages/seaborn/categorical.py:2755, in barplot(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge, ci, ax, **kwargs)\n   2752 if estimator is len:\n   2753     estimator = ""size""\n-> 2755 plotter = _BarPlotter(x, y, hue, data, order, hue_order,\n   2756                       estimator, errorbar, n_boot, units, seed,\n   2757                       orient, color, palette, saturation,\n   2758                       width, errcolor, errwidth, capsize, dodge)\n   2760 if ax is None:\n   2761     ax = plt.gca()\n', 'File /opt/conda/lib/python3.10/site-packages/seaborn/categorical.py:1530, in _BarPlotter.__init__(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\n   1525 def __init__(self, x, y, hue, data, order, hue_order,\n   1526              estimator, errorbar, n_boot, units, seed,\n   1527              orient, color, palette, saturation, width,\n   1528              errcolor, errwidth, capsize, dodge):\n   1529     """"""Initialize the plotter.""""""\n-> 1530     self.establish_variables(x, y, hue, data, orient,\n   1531                              order, hue_order, units)\n   1532     self.establish_colors(color, palette, saturation)\n   1533     self.estimate_statistic(estimator, errorbar, n_boot, seed)\n', 'File /opt/conda/lib/python3.10/site-packages/seaborn/categorical.py:544, in _CategoricalPlotter.establish_variables(self, x, y, hue, data, orient, order, hue_order, units)\n    541         raise ValueError(err)\n    543 # Figure out the plotting orientation\n--> 544 orient = infer_orient(\n    545     x, y, orient, require_numeric=self.require_numeric\n    546 )\n    548 # Option 2a:\n    549 # We are plotting a single set of data\n    550 # ------------------------------------\n    551 if x is None or y is None:\n    552 \n    553     # Determine where the data are\n', 'File /opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1632, in infer_orient(x, y, orient, require_numeric)\n   1630 elif require_numeric and ""numeric"" not in (x_type, y_type):\n   1631     err = ""Neither the `x` nor `y` variable appears to be numeric.""\n-> 1632     raise TypeError(err)\n   1634 else:\n   1635     return ""v""\n', 'TypeError: Neither the `x` nor `y` variable appears to be numeric.']",data confusion,invalid argument,data visualization,ML bug,Petals to the Metal - Flower Classification on TPU,,Allow academic research,,https://www.kaggle.com/competitions/tpu-getting-started/data,,https://www.kaggle.com/code/jiahuilee12138/flower-classification-with-tpus-eda-and-baseline
matplotlib_1,c95bb4af-7523-3ed1-8586-c53a1a20d807,typeerror,only integer scalar arrays can be converted to a scalar index,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', '/tmp/ipykernel_24/2178739758.py in <module>\n      7     plt.subplot(5, 5, i+1)\n      8     plt.imshow(train_images[i].astype(""uint8""))\n----> 9     plt.title(class_names[train_labels[i]])\n     10     plt.axis(""off"")\n', 'TypeError: only integer scalar arrays can be converted to a scalar index']",data confusion,value error,data visualization,ML bug,The CIFAR-10 dataset,,MIT,,https://www.cs.toronto.edu/~kriz/cifar.html,,https://www.kaggle.com/code/theanhle/lesson-3-cnn
matplotlib_2,47e3694b-16e6-351a-9a12-7139ed9449ad,typeerror,Invalid shape () for image data,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[9], line 2\n      1 plt.imshow(custom_dataset.images[1][0, :, :])  # Displaying the first channel of the image\n----> 2 plt.imshow(custom_dataset.labels[0])  # Displaying the first channel of the image\n      4 plt.title(f""Label: {labels_array[1]}"")\n      5 plt.show()\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:2695, in imshow(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\n   2689 @_copy_docstring_and_deprecators(Axes.imshow)\n   2690 def imshow(\n   2691         X, cmap=None, norm=None, *, aspect=None, interpolation=None,\n   2692         alpha=None, vmin=None, vmax=None, origin=None, extent=None,\n   2693         interpolation_stage=None, filternorm=True, filterrad=4.0,\n   2694         resample=None, url=None, data=None, **kwargs):\n-> 2695     __ret = gca().imshow(\n   2696         X, cmap=cmap, norm=norm, aspect=aspect,\n   2697         interpolation=interpolation, alpha=alpha, vmin=vmin,\n   2698         vmax=vmax, origin=origin, extent=extent,\n   2699         interpolation_stage=interpolation_stage,\n   2700         filternorm=filternorm, filterrad=filterrad, resample=resample,\n   2701         url=url, **({""data"": data} if data is not None else {}),\n   2702         **kwargs)\n   2703     sci(__ret)\n   2704     return __ret\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py:1446, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs)\n   1443 @functools.wraps(func)\n   1444 def inner(ax, *args, data=None, **kwargs):\n   1445     if data is None:\n-> 1446         return func(ax, *map(sanitize_sequence, args), **kwargs)\n   1448     bound = new_sig.bind(ax, *args, **kwargs)\n   1449     auto_label = (bound.arguments.get(label_namer)\n   1450                   or bound.kwargs.get(label_namer))\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5663, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\n   5655 self.set_aspect(aspect)\n   5656 im = mimage.AxesImage(self, cmap=cmap, norm=norm,\n   5657                       interpolation=interpolation, origin=origin,\n   5658                       extent=extent, filternorm=filternorm,\n   5659                       filterrad=filterrad, resample=resample,\n   5660                       interpolation_stage=interpolation_stage,\n   5661                       **kwargs)\n-> 5663 im.set_data(X)\n   5664 im.set_alpha(alpha)\n   5665 if im.get_clip_path() is None:\n   5666     # image does not already have clipping set, clip to axes patch\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/image.py:710, in _ImageBase.set_data(self, A)\n    706     self._A = self._A[:, :, 0]\n    708 if not (self._A.ndim == 2\n    709         or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n--> 710     raise TypeError(""Invalid shape {} for image data""\n    711                     .format(self._A.shape))\n    713 if self._A.ndim == 3:\n    714     # If the input data has values outside the valid range (after\n    715     # normalisation), we issue a warning and then clip X to the bounds\n    716     # - otherwise casting wraps extreme values, hiding outliers and\n    717     # making reliable interpretation impossible.\n    718     high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1\n', 'TypeError: Invalid shape () for image data']",data confusion,invalid argument,data visualization,ML bug,Quarks and Gluons Classifier-ML4SCI,,Unknown,,https://www.kaggle.com/datasets/vishakkbhat/ml4sci,,https://www.kaggle.com/code/sadouaa/notebookf9c2ef8ba8
matplotlib_3,0b400994-9ace-3c61-949c-7153cadfaf86,typeerror,"float() argument must be a string or a real number, not 'MetricObservation'","['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', ""Cell In[83], line 12\n     10 for trial in best_trials:\n     11     val_accuracy_history = trial.metrics.get_history(name='val_accuracy')\n---> 12     plt.plot(val_accuracy_history, label=f'Trial {trial.trial_id}')\n     14 plt.title('Validation Accuracy of Best Trials')\n     15 plt.xlabel('Epochs')\n"", 'File /opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:2812, in plot(scalex, scaley, data, *args, **kwargs)\n   2810 @_copy_docstring_and_deprecators(Axes.plot)\n   2811 def plot(*args, scalex=True, scaley=True, data=None, **kwargs):\n-> 2812     return gca().plot(\n   2813         *args, scalex=scalex, scaley=scaley,\n   2814         **({""data"": data} if data is not None else {}), **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1690, in Axes.plot(self, scalex, scaley, data, *args, **kwargs)\n   1688 lines = [*self._get_lines(*args, data=data, **kwargs)]\n   1689 for line in lines:\n-> 1690     self.add_line(line)\n   1691 if scalex:\n   1692     self._request_autoscale_view(""x"")\n', ""File /opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:2304, in _AxesBase.add_line(self, line)\n   2301 if line.get_clip_path() is None:\n   2302     line.set_clip_path(self.patch)\n-> 2304 self._update_line_limits(line)\n   2305 if not line.get_label():\n   2306     line.set_label(f'_child{len(self._children)}')\n"", 'File /opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:2327, in _AxesBase._update_line_limits(self, line)\n   2323 def _update_line_limits(self, line):\n   2324     """"""\n   2325     Figures out the data limit of the given line, updating self.dataLim.\n   2326     """"""\n-> 2327     path = line.get_path()\n   2328     if path.vertices.size == 0:\n   2329         return\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/lines.py:1028, in Line2D.get_path(self)\n   1026 """"""Return the `~matplotlib.path.Path` associated with this line.""""""\n   1027 if self._invalidy or self._invalidx:\n-> 1028     self.recache()\n   1029 return self._path\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/lines.py:664, in Line2D.recache(self, always)\n    662 if always or self._invalidy:\n    663     yconv = self.convert_yunits(self._yorig)\n--> 664     y = _to_unmasked_float_array(yconv).ravel()\n    665 else:\n    666     y = self._y\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1345, in _to_unmasked_float_array(x)\n   1343     return np.ma.asarray(x, float).filled(np.nan)\n   1344 else:\n-> 1345     return np.asarray(x, float)\n', ""TypeError: float() argument must be a string or a real number, not 'MetricObservation'""]",API misuse,invalid argument,training,ML bug,Brain Tumor MRI Dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset,,https://www.kaggle.com/code/mithunhossain/braintumor-detection
seaborn_2,cfe1996a-785a-385e-87d9-62039731a35e,typeerror,countplot() got multiple values for argument 'data',"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[13], line 7\n      5 dev_train[\'SeriousDlqin2yrs\'].value_counts().plot.pie(explode=[0,0.1],autopct=""%1.1f%%"",ax=axes[0])\n      6 axes[0].set_title(""SeriousDlqin2yrs"")\n----> 7 sns.countplot(""SeriousDlqin2yrs"",data=dev_train,ax=axes[1])\n      8 axes[1].set_title(""SeriousDlqin2yrs"")\n      9 plt.show()\n', ""TypeError: countplot() got multiple values for argument 'data'""]",API misuse,invalid argument,data visualization,ML bug,Give Me Some Credit,,No private sharing outside teams,,https://www.kaggle.com/competitions/GiveMeSomeCredit/data,,https://www.kaggle.com/code/lingling9973/notebook2b91407fd2
seaborn_3,12880de0-a70b-3adf-a0a9-90284cdd75b6,typeerror,barplot() takes from 0 to 1 positional arguments but 2 were given,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[22], line 18\n     15     num_summary(df, col, True)\n     17 for col in num_cols:\n---> 18     sns.barplot(col,df)\n     20 for col in num_cols:\n     21     sns.boxplot(data=df, x=col)\n', 'TypeError: barplot() takes from 0 to 1 positional arguments but 2 were given']",API misuse,invalid argument,data visualization,ML bug,House Prices - Advanced Regression Techniques,,MIT,,https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data,,https://www.kaggle.com/code/besimgurpinar/house-prices-advanced-regression-tec
seaborn_4,9c322458-628d-3376-91e0-b1ce34d408d6,indexerror,index 14 is out of bounds for axis 0 with size 14,"['---------------------------------------------------------------------------', 'IndexError                                Traceback (most recent call last)', '/tmp/ipykernel_28/1417668694.py in <module>\n      5 \n      6 for col, value in df.items():\n----> 7     sns.boxplot(y=col, data=df, ax=ax[index])\n      8     index += 1\n      9 plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n', 'IndexError: index 14 is out of bounds for axis 0 with size 14']",data confusion,index error,data visualization,ML bug,Paris Housing Price Prediction,,Data files © Original Authors,,https://www.kaggle.com/datasets/mssmartypants/paris-housing-price-prediction,,https://www.kaggle.com/code/mathyseizaecrepin/paris-house-price-regression-analysis
seaborn_5,a812b4ff-7fff-342e-b7d5-d5fdbd448635,typeerror,barplot() takes from 0 to 1 positional arguments but 2 were given,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', '/tmp/ipykernel_27/2388215574.py in <module>\n      1 plt.figure(figsize=(15,12))\n----> 2 labels = sns.barplot(df_train.labels.value_counts().index,df_train.labels.value_counts())\n      3 for item in labels.get_xticklabels():\n      4     item.set_rotation(45)\n', 'TypeError: barplot() takes from 0 to 1 positional arguments but 2 were given']",API misuse,invalid argument,data visualization,ML bug,Plant Pathology 2021 - FGVC8,,Allow academic research,,https://www.kaggle.com/competitions/plant-pathology-2021-fgvc8/data,,https://www.kaggle.com/code/aravmathur23/arav-s-plant-pathology
matplotlib_4,742aa349-be15-3da6-be0e-026b70dc146f,typeerror,only integer scalar arrays can be converted to a scalar index,"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', '/tmp/ipykernel_23/922550585.py in <module>\n      6     ax = plt.subplot(3, 3, i + 1)\n      7     plt.imshow(images[i].numpy().astype(""uint8""))\n----> 8     plt.title(class_names[labels[i]])\n      9     plt.axis(""off"")\n', '/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in __index__(self)\n   1061 \n   1062   def __index__(self):\n-> 1063     return self._numpy().__index__()\n   1064 \n   1065   def __bool__(self):\n', 'TypeError: only integer scalar arrays can be converted to a scalar index']",data confusion,type error,data visualization,ML bug,Training_Handwritten_marathi_Character_Fusion,Handwritten Marathi Character Dataset of 4 People,Unknown,Unknown,https://www.kaggle.com/datasets/akkulkarni/training-handwritten-marathi-character-fusion,https://www.kaggle.com/datasets/akkulkarni/handwritten-marathi-character-dataset-of-4-people,https://www.kaggle.com/code/tasmiyapathan/trial1-resnet50
seaborn_6,df4bfa4d-0bf7-3002-90e0-0a4cf24be4d2,typeerror,Horizontal orientation requires numeric `x` variable.,"---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-8-57b3549bae71> in <cell line: 1>()
----> 1 sns.violinplot(df, x='species')

/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py in violinplot(data, x, y, hue, order, hue_order, bw, cut, scale, scale_hue, gridsize, width, inner, split, dodge, orient, linewidth, color, palette, saturation, ax, **kwargs)
   2303 ):
   2304 
-> 2305     plotter = _ViolinPlotter(x, y, hue, data, order, hue_order,
   2306                              bw, cut, scale, scale_hue, gridsize,
   2307                              width, inner, split, dodge, orient, linewidth,

/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py in __init__(self, x, y, hue, data, order, hue_order, bw, cut, scale, scale_hue, gridsize, width, inner, split, dodge, orient, linewidth, color, palette, saturation)
    899                  color, palette, saturation):
    900 
--> 901         self.establish_variables(x, y, hue, data, orient, order, hue_order)
    902         self.establish_colors(color, palette, saturation)
    903         self.estimate_densities(bw, cut, scale, scale_hue, gridsize)

/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py in establish_variables(self, x, y, hue, data, orient, order, hue_order, units)
    542 
    543             # Figure out the plotting orientation
--> 544             orient = infer_orient(
    545                 x, y, orient, require_numeric=self.require_numeric
    546             )

/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py in infer_orient(x, y, orient, require_numeric)
   1599             warnings.warn(single_var_warning.format(""Vertical"", ""x""))
   1600         if require_numeric and x_type != ""numeric"":
-> 1601             raise TypeError(nonnumeric_dv_error.format(""Horizontal"", ""x""))
   1602         return ""h""
   1603 

TypeError: Horizontal orientation requires numeric `x` variable.",API misuse,type error,data visualization,ML bug,Palmer Penguins Dataset-Alternative Iris Dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/ashkhagan/palmer-penguins-datasetalternative-iris-dataset,,https://www.kaggle.com/code/mymi26/penguins-mb
matplotlib_5,f5df1487-4dc0-3e41-9c8c-a2765ab6e590,typeerror,scatter() got multiple values for argument 's',"['---------------------------------------------------------------------------', 'TypeError                                 Traceback (most recent call last)', 'Cell In[15], line 2\n      1 plt.scatter(X[:,0], X[:,1], X[:,2], c = labels, cmap = \'viridis\')\n----> 2 plt.scatter(centriods[:,0], centriods[:,1], centriods[:,2], marker = \'X\', s = 200, c = \'red\')\n      3 plt.title(""K-Means Clustering"")\n      4 plt.xlabel(""Gluscose"")\n', ""TypeError: scatter() got multiple values for argument 's'""]",API misuse,invalid argument,data visualization,ML bug,Diabetes Dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset,,https://www.kaggle.com/code/saniyarawat/saniya-51-exp5
matplotlib_6,5db514d7-6a8a-3063-b9b7-2c8a8e96fc87,indexerror,index 6 is out of bounds for axis 0 with size 6,"['---------------------------------------------------------------------------', 'IndexError                                Traceback (most recent call last)', ""/tmp/ipykernel_27/3966309574.py in <module>\n      3 \n      4 for i, col in enumerate(list(df.columns.values)):\n----> 5     axes_box  = ax[i]\n      6     sns.boxplot(data=df, x=col, ax=axes_box,color='#a5c687')\n      7     ax[i].set_title(col,fontsize=15,color='magenta')\n"", 'IndexError: index 6 is out of bounds for axis 0 with size 6']",implementation error,index error,data visualization,ML bug,experiment,,Unknown,,https://www.kaggle.com/datasets/yicheng03/experiment,,https://www.kaggle.com/code/mpwolke/exp-kaleido-kmeans-kneed-yellowbrick
statsmodels_1,83bbc720-ecc2-3a8a-bd68-0d0058651035,valueerror,45 option for line not understood,"['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""/tmp/ipykernel_28/1803351197.py in <module>\n----> 1 fig = sm.qqplot(train['urea'],line=45,fit=True)\n"", '/opt/conda/lib/python3.7/site-packages/statsmodels/graphics/gofplots.py in qqplot(data, dist, distargs, a, loc, scale, fit, line, ax, **plotkwargs)\n    689         data, dist=dist, distargs=distargs, fit=fit, a=a, loc=loc, scale=scale\n    690     )\n--> 691     fig = probplot.qqplot(ax=ax, line=line, **plotkwargs)\n    692     return fig\n    693 \n', '/opt/conda/lib/python3.7/site-packages/statsmodels/graphics/gofplots.py in qqplot(self, xlabel, ylabel, line, other, ax, swap, **plotkwargs)\n    481                 ax=ax,\n    482                 line=line,\n--> 483                 **plotkwargs,\n    484             )\n    485             if xlabel is None:\n', '/opt/conda/lib/python3.7/site-packages/statsmodels/graphics/gofplots.py in _do_plot(x, y, dist, line, ax, fmt, step, **kwargs)\n   1047         if line not in [""r"", ""q"", ""45"", ""s""]:\n   1048             msg = ""%s option for line not understood"" % line\n-> 1049             raise ValueError(msg)\n   1050 \n   1051         qqline(ax, line, x=x, y=y, dist=dist)\n', 'ValueError: 45 option for line not understood']",API misuse,invalid argument,data visualization,ML bug,Binary Classification with a Tabular Kidney Stone Prediction Dataset,,Attribution 4.0 International (CC BY 4.0),,https://www.kaggle.com/competitions/playground-series-s3e12/data,,https://www.kaggle.com/code/madhvendrasingh21/kidneystoneprediction
statsmodels_2,a92d34a3-1c75-3575-bfbc-08543c41a9b1,valueerror,"could not broadcast input array from shape (92,) into shape (181,)","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', ""Cell In[17], line 4\n      1 from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n      3 plt.figure(figsize=(12, 6))\n----> 4 plot_acf(residuals, lags=180, title='ACF of Residuals')\n      5 plt.show()\n      7 plt.figure(figsize=(12, 6))\n"", 'File /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:210, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\n    208         raise TypeError(msg)\n    209     kwargs[new_arg_name] = new_arg_value\n--> 210 return func(*args, **kwargs)\n', 'File /opt/conda/lib/python3.10/site-packages/statsmodels/graphics/tsaplots.py:227, in plot_acf(x, ax, lags, alpha, use_vlines, adjusted, fft, missing, title, zero, auto_ylims, bartlett_confint, vlines_kwargs, **kwargs)\n    224 if alpha is not None:\n    225     acf_x, confint = acf_x[:2]\n--> 227 _plot_corr(\n    228     ax,\n    229     title,\n    230     acf_x,\n    231     confint,\n    232     lags,\n    233     irregular,\n    234     use_vlines,\n    235     vlines_kwargs,\n    236     auto_ylims=auto_ylims,\n    237     **kwargs,\n    238 )\n    240 return fig\n', 'File /opt/conda/lib/python3.10/site-packages/statsmodels/graphics/tsaplots.py:49, in _plot_corr(ax, title, acf_x, confint, lags, irregular, use_vlines, vlines_kwargs, auto_ylims, **kwargs)\n     46         confint = confint[lags]\n     48 if use_vlines:\n---> 49     ax.vlines(lags, [0], acf_x, **vlines_kwargs)\n     50     ax.axhline(**kwargs)\n     52 kwargs.setdefault(""marker"", ""o"")\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py:1446, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs)\n   1443 @functools.wraps(func)\n   1444 def inner(ax, *args, data=None, **kwargs):\n   1445     if data is None:\n-> 1446         return func(ax, *map(sanitize_sequence, args), **kwargs)\n   1448     bound = new_sig.bind(ax, *args, **kwargs)\n   1449     auto_label = (bound.arguments.get(label_namer)\n   1450                   or bound.kwargs.get(label_namer))\n', 'File /opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1172, in Axes.vlines(self, x, ymin, ymax, colors, linestyles, label, **kwargs)\n   1170 masked_verts[:, 0, 1] = ymin\n   1171 masked_verts[:, 1, 0] = x\n-> 1172 masked_verts[:, 1, 1] = ymax\n   1174 lines = mcoll.LineCollection(masked_verts, colors=colors,\n   1175                              linestyles=linestyles, label=label)\n   1176 self.add_collection(lines, autolim=False)\n', 'File /opt/conda/lib/python3.10/site-packages/numpy/ma/core.py:3377, in MaskedArray.__setitem__(self, indx, value)\n   3374     mval = tuple([False] * len(_dtype.names))\n   3375 if _mask is nomask:\n   3376     # Set the data, then the mask\n-> 3377     _data[indx] = dval\n   3378     if mval is not nomask:\n   3379         _mask = self._mask = make_mask_none(self.shape, _dtype)\n', 'ValueError: could not broadcast input array from shape (92,) into shape (181,)']",API misuse,unsupported broadcast,evaluation/prediction,ML bug,Store Item Demand Forecasting Challenge,,Allow academic research,,https://www.kaggle.com/competitions/demand-forecasting-kernels-only/data,,https://www.kaggle.com/code/yiqwantang/item-demand-sarima
torchvision_1,4e2518d8-4c04-38c4-98f4-6d402cc01c9f,runtimeerror,"Given groups=1, weight of size [64, 3, 7, 7], expected input[3, 256, 256, 1] to have 3 channels, but got 256 channels instead","['---------------------------------------------------------------------------', 'RuntimeError                              Traceback (most recent call last)', ""Cell In[36], line 63\n     59         print(f'Test Accuracy: {accuracy:.4f}')\n     62 # Usage\n---> 63 evaluate(resnet_model,val_ds)\n"", 'Cell In[36], line 52, in evaluate(model, test_dl)\n     49 for inputs, labels in test_dl:\n     50     # Ensure the batch dimension is added at the beginning\n     51     inputs = inputs.unsqueeze(-1)  # Assuming the channels dimension is 1 (grayscale), change to 0 for RGB\n---> 52     outputs = model(inputs)\n     54     _, predicted = torch.max(outputs.data, 1)\n     55     total += labels.size(0)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'File /opt/conda/lib/python3.10/site-packages/torchvision/models/resnet.py:285, in ResNet.forward(self, x)\n    284 def forward(self, x: Tensor) -> Tensor:\n--> 285     return self._forward_impl(x)\n', 'File /opt/conda/lib/python3.10/site-packages/torchvision/models/resnet.py:268, in ResNet._forward_impl(self, x)\n    266 def _forward_impl(self, x: Tensor) -> Tensor:\n    267     # See note [TorchScript super()]\n--> 268     x = self.conv1(x)\n    269     x = self.bn1(x)\n    270     x = self.relu(x)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n"", 'File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463, in Conv2d.forward(self, input)\n    462 def forward(self, input: Tensor) -> Tensor:\n--> 463     return self._conv_forward(input, self.weight, self.bias)\n', ""File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459, in Conv2d._conv_forward(self, input, weight, bias)\n    455 if self.padding_mode != 'zeros':\n    456     return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n    457                     weight, bias, self.stride,\n    458                     _pair(0), self.dilation, self.groups)\n--> 459 return F.conv2d(input, weight, bias, self.stride,\n    460                 self.padding, self.dilation, self.groups)\n"", 'RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[3, 256, 256, 1] to have 3 channels, but got 256 channels instead']",implementation error,tensor shape mismatch,evaluation/prediction,ML bug,MIT Indoor Scenes,,"Database: Open Database, Contents: Database Contents (DbCL)",,https://www.kaggle.com/datasets/itsahmad/indoor-scenes-cvpr-2019,,https://www.kaggle.com/code/ismaelamell/amell
lightgbm_1,3e0645e7-6fed-3afe-ac64-83f9ec38f16b,valueerror,"Input contains NaN, infinity or a value too large for dtype('float64').","['---------------------------------------------------------------------------', 'ValueError                                Traceback (most recent call last)', '/tmp/ipykernel_27/2908357616.py in <module>\n      1 study = optuna.create_study(direction=""maximize"")\n----> 2 study.optimize(find_out_params_model, n_trials=2)\n', '/opt/conda/lib/python3.7/site-packages/optuna/study/study.py in optimize(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\n    432             callbacks=callbacks,\n    433             gc_after_trial=gc_after_trial,\n--> 434             show_progress_bar=show_progress_bar,\n    435         )\n    436 \n', '/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py in _optimize(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\n     74                 reseed_sampler_rng=False,\n     75                 time_start=None,\n---> 76                 progress_bar=progress_bar,\n     77             )\n     78         else:\n', '/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py in _optimize_sequential(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\n    161 \n    162         try:\n--> 163             frozen_trial = _run_trial(study, func, catch)\n    164         finally:\n    165             # The following line mitigates memory problems that can be occurred in some\n', '/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py in _run_trial(study, func, catch)\n    249         and not isinstance(func_err, catch)\n    250     ):\n--> 251         raise func_err\n    252     return frozen_trial\n    253 \n', '/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py in _run_trial(study, func, catch)\n    198     with get_heartbeat_thread(trial._trial_id, study._storage):\n    199         try:\n--> 200             value_or_values = func(trial)\n    201         except exceptions.TrialPruned as e:\n    202             # TODO(mamu): Handle multi-objective cases.\n', ""/tmp/ipykernel_27/2150223056.py in find_out_params_model(trial)\n      8         random_state = random_state\n      9     )\n---> 10     for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n     11         #print(fold, end=' ')\n     12         X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n"", '/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py in split(self, X, y, groups)\n    745         to an integer.\n    746         """"""\n--> 747         y = check_array(y, ensure_2d=False, dtype=None)\n    748         return super().split(X, y, groups)\n    749 \n', '/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\n    798 \n    799         if force_all_finite:\n--> 800             _assert_all_finite(array, allow_nan=force_all_finite == ""allow-nan"")\n    801 \n    802     if ensure_min_samples > 0:\n', '/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py in _assert_all_finite(X, allow_nan, msg_dtype)\n    114             raise ValueError(\n    115                 msg_err.format(\n--> 116                     type_err, msg_dtype if msg_dtype is not None else X.dtype\n    117                 )\n    118             )\n', ""ValueError: Input contains NaN, infinity or a value too large for dtype('float64').""]",data confusion,data value violation,training,ML bug,Wine Quality Dataset,,CC0: Public Domain,,https://www.kaggle.com/datasets/yasserh/wine-quality-dataset,,https://www.kaggle.com/code/davidhguerrero/23205-pss3e5
NBspecific_20,a76bd0b0-49b4-3932-84de-e1b3d286c942,nameerror,name 'multiplicative_model' is not defined,"['---------------------------------------------------------------------------', 'NameError                                 Traceback (most recent call last)', '<ipython-input-14-8b0de103d72d> in <cell line: 1>()\n----> 1 multiplicative_model\n', ""NameError: name 'multiplicative_model' is not defined""]",NB specific,variable not found,training,python bug,Yahoo_Stock.csv,,MIT,,https://www.kaggle.com/datasets/joepox/yahoo-stock-csv,,https://www.kaggle.com/code/slyveinweeb/seasonal-decomposition-on-stock-data